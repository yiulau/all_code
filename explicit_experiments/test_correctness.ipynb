{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiulau/miniconda2/envs/py36/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "current_H 573.6314086914062,propsed_H572.0967407226562\n",
      "accept_rate 1.0\n",
      "round 1\n",
      "current_H 522.0743408203125,propsed_H517.2216796875\n",
      "accept_rate 1.0\n",
      "round 2\n",
      "current_H 487.1334533691406,propsed_H484.5430603027344\n",
      "accept_rate 1.0\n",
      "round 3\n",
      "current_H 469.40386962890625,propsed_H469.80078125\n",
      "accept_rate 0.6723934484042985\n",
      "round 4\n",
      "current_H 444.7113952636719,propsed_H434.0852355957031\n",
      "accept_rate 1.0\n",
      "round 5\n",
      "current_H 404.3750305175781,propsed_H391.6889343261719\n",
      "accept_rate 1.0\n",
      "round 6\n",
      "current_H 344.6509704589844,propsed_H336.7529602050781\n",
      "accept_rate 1.0\n",
      "round 7\n",
      "current_H 294.3924255371094,propsed_H292.54901123046875\n",
      "accept_rate 1.0\n",
      "round 8\n",
      "current_H 282.4012756347656,propsed_H282.2352294921875\n",
      "accept_rate 1.0\n",
      "round 9\n",
      "current_H 282.4919128417969,propsed_H282.64483642578125\n",
      "accept_rate 0.8581952991711724\n",
      "round 10\n",
      "current_H 281.0400390625,propsed_H281.4682922363281\n",
      "accept_rate 0.651646414095443\n",
      "round 11\n",
      "current_H 282.15374755859375,propsed_H281.7619934082031\n",
      "accept_rate 1.0\n",
      "round 12\n",
      "current_H 282.152099609375,propsed_H282.00439453125\n",
      "accept_rate 1.0\n",
      "round 13\n",
      "current_H 279.6663818359375,propsed_H279.5860290527344\n",
      "accept_rate 1.0\n",
      "round 14\n",
      "current_H 283.3446044921875,propsed_H283.3009948730469\n",
      "accept_rate 1.0\n",
      "round 15\n",
      "current_H 282.25634765625,propsed_H281.8984375\n",
      "accept_rate 1.0\n",
      "round 16\n",
      "current_H 276.8954772949219,propsed_H276.4237976074219\n",
      "accept_rate 1.0\n",
      "round 17\n",
      "current_H 278.86505126953125,propsed_H279.059814453125\n",
      "accept_rate 0.8230295418776095\n",
      "round 18\n",
      "current_H 278.54815673828125,propsed_H278.5149841308594\n",
      "accept_rate 1.0\n",
      "round 19\n",
      "current_H 278.215576171875,propsed_H278.4332275390625\n",
      "accept_rate 0.8044058350552185\n",
      "round 20\n",
      "current_H 279.1168212890625,propsed_H278.82562255859375\n",
      "accept_rate 1.0\n",
      "round 21\n",
      "current_H 279.9614562988281,propsed_H281.4256591796875\n",
      "accept_rate 0.23126226160017785\n",
      "round 22\n",
      "current_H 278.1349792480469,propsed_H278.3509521484375\n",
      "accept_rate 0.8057571372812843\n",
      "round 23\n",
      "current_H 281.9230041503906,propsed_H284.6222839355469\n",
      "accept_rate 0.06725393258185829\n",
      "round 24\n",
      "current_H 283.7430419921875,propsed_H280.8193054199219\n",
      "accept_rate 1.0\n",
      "round 25\n",
      "current_H 276.2141418457031,propsed_H276.05511474609375\n",
      "accept_rate 1.0\n",
      "round 26\n",
      "current_H 277.09832763671875,propsed_H277.14404296875\n",
      "accept_rate 0.9553138707461544\n",
      "round 27\n",
      "current_H 276.7218017578125,propsed_H276.9134216308594\n",
      "accept_rate 0.8256206495115285\n",
      "round 28\n",
      "current_H 278.9171142578125,propsed_H278.9564208984375\n",
      "accept_rate 0.9614558425191738\n",
      "round 29\n",
      "current_H 277.67779541015625,propsed_H277.4849548339844\n",
      "accept_rate 1.0\n",
      "round 30\n",
      "current_H 276.1797180175781,propsed_H275.9629211425781\n",
      "accept_rate 1.0\n",
      "round 31\n",
      "current_H 276.8662414550781,propsed_H277.2709045410156\n",
      "accept_rate 0.6672015625842965\n",
      "round 32\n",
      "current_H 276.7889099121094,propsed_H276.3152770996094\n",
      "accept_rate 1.0\n",
      "round 33\n",
      "current_H 277.7725524902344,propsed_H278.6333312988281\n",
      "accept_rate 0.42283264835114404\n",
      "round 34\n",
      "current_H 277.64349365234375,propsed_H278.13116455078125\n",
      "accept_rate 0.6140549262286664\n",
      "round 35\n",
      "current_H 276.5813903808594,propsed_H276.2742919921875\n",
      "accept_rate 1.0\n",
      "round 36\n",
      "current_H 275.63275146484375,propsed_H275.78179931640625\n",
      "accept_rate 0.8615278884569914\n",
      "round 37\n",
      "current_H 277.43890380859375,propsed_H277.6222839355469\n",
      "accept_rate 0.8324516582738103\n",
      "round 38\n",
      "current_H 277.9648742675781,propsed_H277.7778015136719\n",
      "accept_rate 1.0\n",
      "round 39\n",
      "current_H 277.5975341796875,propsed_H277.5922546386719\n",
      "accept_rate 1.0\n",
      "round 40\n",
      "current_H 275.7727966308594,propsed_H276.1184997558594\n",
      "accept_rate 0.7077225610574206\n",
      "round 41\n",
      "current_H 279.38323974609375,propsed_H279.0344543457031\n",
      "accept_rate 1.0\n",
      "round 42\n",
      "current_H 276.9077453613281,propsed_H276.6083984375\n",
      "accept_rate 1.0\n",
      "round 43\n",
      "current_H 275.8611755371094,propsed_H275.9646911621094\n",
      "accept_rate 0.9016619341640674\n",
      "round 44\n",
      "current_H 276.57373046875,propsed_H276.47442626953125\n",
      "accept_rate 1.0\n",
      "round 45\n",
      "current_H 277.6295471191406,propsed_H278.1510925292969\n",
      "accept_rate 0.5936024794561827\n",
      "round 46\n",
      "current_H 279.9879455566406,propsed_H280.7563171386719\n",
      "accept_rate 0.4637676613411076\n",
      "round 47\n",
      "current_H 276.7870788574219,propsed_H276.5609436035156\n",
      "accept_rate 1.0\n",
      "round 48\n",
      "current_H 275.18206787109375,propsed_H275.23870849609375\n",
      "accept_rate 0.9449335938648561\n",
      "round 49\n",
      "current_H 277.32452392578125,propsed_H277.17132568359375\n",
      "accept_rate 1.0\n",
      "round 50\n",
      "current_H 277.98529052734375,propsed_H278.69598388671875\n",
      "accept_rate 0.4913034294984739\n",
      "round 51\n",
      "current_H 278.97235107421875,propsed_H279.7146911621094\n",
      "accept_rate 0.4759987323470918\n",
      "round 52\n",
      "current_H 285.31353759765625,propsed_H286.4366760253906\n",
      "accept_rate 0.3252573942704365\n",
      "round 53\n",
      "current_H 279.58416748046875,propsed_H279.3175964355469\n",
      "accept_rate 1.0\n",
      "round 54\n",
      "current_H 281.7502136230469,propsed_H282.121337890625\n",
      "accept_rate 0.689958196797129\n",
      "round 55\n",
      "current_H 277.2386779785156,propsed_H276.8083190917969\n",
      "accept_rate 1.0\n",
      "round 56\n",
      "current_H 277.0755310058594,propsed_H277.0814514160156\n",
      "accept_rate 0.9940970809367874\n",
      "round 57\n",
      "current_H 276.2143859863281,propsed_H276.28350830078125\n",
      "accept_rate 0.9332125277171254\n",
      "round 58\n",
      "current_H 276.70556640625,propsed_H276.5740966796875\n",
      "accept_rate 1.0\n",
      "round 59\n",
      "current_H 280.0087890625,propsed_H280.8775939941406\n",
      "accept_rate 0.41945252427833607\n",
      "round 60\n",
      "current_H 282.1826171875,propsed_H282.4731750488281\n",
      "accept_rate 0.7478462566825962\n",
      "round 61\n",
      "current_H 281.2066955566406,propsed_H281.547607421875\n",
      "accept_rate 0.7111215799783704\n",
      "round 62\n",
      "current_H 284.1028747558594,propsed_H283.89471435546875\n",
      "accept_rate 1.0\n",
      "round 63\n",
      "current_H 285.31817626953125,propsed_H285.1338195800781\n",
      "accept_rate 1.0\n",
      "round 64\n",
      "current_H 287.40234375,propsed_H286.8986511230469\n",
      "accept_rate 1.0\n",
      "round 65\n",
      "current_H 283.49383544921875,propsed_H283.02899169921875\n",
      "accept_rate 1.0\n",
      "round 66\n",
      "current_H 281.7128601074219,propsed_H281.99786376953125\n",
      "accept_rate 0.7520115003659744\n",
      "round 67\n",
      "current_H 278.7071228027344,propsed_H278.3321838378906\n",
      "accept_rate 1.0\n",
      "round 68\n",
      "current_H 276.24151611328125,propsed_H276.28509521484375\n",
      "accept_rate 0.9573568226752261\n",
      "round 69\n",
      "current_H 276.1435241699219,propsed_H276.28643798828125\n",
      "accept_rate 0.8668287704020677\n",
      "round 70\n",
      "current_H 285.8846130371094,propsed_H286.3816833496094\n",
      "accept_rate 0.608310210495769\n",
      "round 71\n",
      "current_H 283.7439270019531,propsed_H284.05743408203125\n",
      "accept_rate 0.7308792043034191\n",
      "round 72\n",
      "current_H 278.9074401855469,propsed_H278.9452209472656\n",
      "accept_rate 0.9629240275599914\n",
      "round 73\n",
      "current_H 282.16693115234375,propsed_H281.8768005371094\n",
      "accept_rate 1.0\n",
      "round 74\n",
      "current_H 278.0469970703125,propsed_H278.25567626953125\n",
      "accept_rate 0.8116555736249896\n",
      "round 75\n",
      "current_H 279.648193359375,propsed_H279.0757751464844\n",
      "accept_rate 1.0\n",
      "round 76\n",
      "current_H 279.3795166015625,propsed_H279.2605895996094\n",
      "accept_rate 1.0\n",
      "round 77\n",
      "current_H 277.1927490234375,propsed_H277.5335998535156\n",
      "accept_rate 0.7111649847197113\n",
      "round 78\n",
      "current_H 279.0636901855469,propsed_H279.0880432128906\n",
      "accept_rate 0.9759411150363109\n",
      "round 79\n",
      "current_H 279.1151428222656,propsed_H279.90740966796875\n",
      "accept_rate 0.4528171643387266\n",
      "round 80\n",
      "current_H 281.0154724121094,propsed_H280.2889709472656\n",
      "accept_rate 1.0\n",
      "round 81\n",
      "current_H 274.9557189941406,propsed_H274.84942626953125\n",
      "accept_rate 1.0\n",
      "round 82\n",
      "current_H 277.5624084472656,propsed_H277.9292297363281\n",
      "accept_rate 0.6929334687695641\n",
      "round 83\n",
      "current_H 279.9749755859375,propsed_H279.89935302734375\n",
      "accept_rate 1.0\n",
      "round 84\n",
      "current_H 277.1532287597656,propsed_H277.10064697265625\n",
      "accept_rate 1.0\n",
      "round 85\n",
      "current_H 279.5362854003906,propsed_H279.3253479003906\n",
      "accept_rate 1.0\n",
      "round 86\n",
      "current_H 278.70458984375,propsed_H278.76483154296875\n",
      "accept_rate 0.9415369373382604\n",
      "round 87\n",
      "current_H 280.13983154296875,propsed_H281.18084716796875\n",
      "accept_rate 0.3530958867789343\n",
      "round 88\n",
      "current_H 277.93756103515625,propsed_H278.0517883300781\n",
      "accept_rate 0.8920551732266406\n",
      "round 89\n",
      "current_H 277.1221618652344,propsed_H279.1302490234375\n",
      "accept_rate 0.1342452190922434\n",
      "round 90\n",
      "current_H 278.5856628417969,propsed_H279.1051940917969\n",
      "accept_rate 0.5947992948032403\n",
      "round 91\n",
      "current_H 275.3544006347656,propsed_H274.6944274902344\n",
      "accept_rate 1.0\n",
      "round 92\n",
      "current_H 278.2452392578125,propsed_H278.7069396972656\n",
      "accept_rate 0.6302110980494382\n",
      "round 93\n",
      "current_H 281.1095886230469,propsed_H280.62060546875\n",
      "accept_rate 1.0\n",
      "round 94\n",
      "current_H 277.9930114746094,propsed_H279.02020263671875\n",
      "accept_rate 0.35801114488246993\n",
      "round 95\n",
      "current_H 283.6272277832031,propsed_H283.757568359375\n",
      "accept_rate 0.8777964234604557\n",
      "round 96\n",
      "current_H 289.5670471191406,propsed_H289.6330261230469\n",
      "accept_rate 0.9361505195893493\n",
      "round 97\n",
      "current_H 281.3958740234375,propsed_H280.8096618652344\n",
      "accept_rate 1.0\n",
      "round 98\n",
      "current_H 277.9006042480469,propsed_H277.7677001953125\n",
      "accept_rate 1.0\n",
      "round 99\n",
      "current_H 277.19580078125,propsed_H276.8252258300781\n",
      "accept_rate 1.0\n",
      "round 100\n",
      "current_H 274.29449462890625,propsed_H274.4965515136719\n",
      "accept_rate 0.8170484490107514\n",
      "round 101\n",
      "current_H 277.6635437011719,propsed_H277.94183349609375\n",
      "accept_rate 0.7570773925373459\n",
      "round 102\n",
      "current_H 278.2192687988281,propsed_H278.52728271484375\n",
      "accept_rate 0.7349050909871802\n",
      "round 103\n",
      "current_H 279.2401428222656,propsed_H278.85382080078125\n",
      "accept_rate 1.0\n",
      "round 104\n",
      "current_H 278.957763671875,propsed_H279.9367370605469\n",
      "accept_rate 0.37569659532071537\n",
      "round 105\n",
      "current_H 276.6341552734375,propsed_H276.5206604003906\n",
      "accept_rate 1.0\n",
      "round 106\n",
      "current_H 275.84130859375,propsed_H275.96514892578125\n",
      "accept_rate 0.8835208996085597\n",
      "round 107\n",
      "current_H 277.31988525390625,propsed_H277.5842590332031\n",
      "accept_rate 0.7676865406875125\n",
      "round 108\n",
      "current_H 277.7008056640625,propsed_H278.4017028808594\n",
      "accept_rate 0.49613995893108626\n",
      "round 109\n",
      "current_H 279.2516784667969,propsed_H278.2992858886719\n",
      "accept_rate 1.0\n",
      "round 110\n",
      "current_H 280.8545227050781,propsed_H281.19134521484375\n",
      "accept_rate 0.7140355629957599\n",
      "round 111\n",
      "current_H 278.0869140625,propsed_H277.6905212402344\n",
      "accept_rate 1.0\n",
      "round 112\n",
      "current_H 277.9835510253906,propsed_H278.6551208496094\n",
      "accept_rate 0.5109059154524135\n",
      "round 113\n",
      "current_H 279.2179870605469,propsed_H279.6951904296875\n",
      "accept_rate 0.6205163225893291\n",
      "round 114\n",
      "current_H 280.2091979980469,propsed_H280.6656494140625\n",
      "accept_rate 0.633527787949999\n",
      "round 115\n",
      "current_H 278.60003662109375,propsed_H277.966796875\n",
      "accept_rate 1.0\n",
      "round 116\n",
      "current_H 279.0516662597656,propsed_H280.650634765625\n",
      "accept_rate 0.20210488051386385\n",
      "round 117\n",
      "current_H 277.1546630859375,propsed_H277.48541259765625\n",
      "accept_rate 0.7183850935524982\n",
      "round 118\n",
      "current_H 280.4036865234375,propsed_H281.9727478027344\n",
      "accept_rate 0.2082405703699229\n",
      "round 119\n",
      "current_H 276.241943359375,propsed_H276.2229309082031\n",
      "accept_rate 1.0\n",
      "round 120\n",
      "current_H 279.1964416503906,propsed_H279.55047607421875\n",
      "accept_rate 0.7018508065480087\n",
      "round 121\n",
      "current_H 279.83740234375,propsed_H280.3660888671875\n",
      "accept_rate 0.5893785964697049\n",
      "round 122\n",
      "current_H 281.25958251953125,propsed_H280.6063537597656\n",
      "accept_rate 1.0\n",
      "round 123\n",
      "current_H 282.1999206542969,propsed_H282.6147155761719\n",
      "accept_rate 0.660475715938539\n",
      "round 124\n",
      "current_H 278.3983459472656,propsed_H278.180419921875\n",
      "accept_rate 1.0\n",
      "round 125\n",
      "current_H 278.634033203125,propsed_H279.3252258300781\n",
      "accept_rate 0.50097823249591\n",
      "round 126\n",
      "current_H 280.25494384765625,propsed_H279.8182067871094\n",
      "accept_rate 1.0\n",
      "round 127\n",
      "current_H 279.8778076171875,propsed_H280.2607116699219\n",
      "accept_rate 0.6818783205077884\n",
      "round 128\n",
      "current_H 278.4147644042969,propsed_H278.10015869140625\n",
      "accept_rate 1.0\n",
      "round 129\n",
      "current_H 277.77130126953125,propsed_H277.32318115234375\n",
      "accept_rate 1.0\n",
      "round 130\n",
      "current_H 282.18572998046875,propsed_H283.4603576660156\n",
      "accept_rate 0.2795350237790189\n",
      "round 131\n",
      "current_H 277.1259765625,propsed_H277.53192138671875\n",
      "accept_rate 0.6663469326231938\n",
      "round 132\n",
      "current_H 279.93988037109375,propsed_H280.4020080566406\n",
      "accept_rate 0.6299419003304905\n",
      "round 133\n",
      "current_H 281.31610107421875,propsed_H280.7751770019531\n",
      "accept_rate 1.0\n",
      "round 134\n",
      "current_H 278.0313415527344,propsed_H278.7076416015625\n",
      "accept_rate 0.508494922482705\n",
      "round 135\n",
      "current_H 277.9787292480469,propsed_H278.2834167480469\n",
      "accept_rate 0.7373537614422269\n",
      "round 136\n",
      "current_H 277.16973876953125,propsed_H277.62445068359375\n",
      "accept_rate 0.6346307698159289\n",
      "round 137\n",
      "current_H 282.6910400390625,propsed_H283.46435546875\n",
      "accept_rate 0.4614805229658371\n",
      "round 138\n",
      "current_H 277.71490478515625,propsed_H277.7102966308594\n",
      "accept_rate 1.0\n",
      "round 139\n",
      "current_H 282.9239807128906,propsed_H284.8918151855469\n",
      "accept_rate 0.13975918107869126\n",
      "round 140\n",
      "current_H 275.4652404785156,propsed_H275.50372314453125\n",
      "accept_rate 0.962248384193713\n",
      "round 141\n",
      "current_H 277.65936279296875,propsed_H278.0897521972656\n",
      "accept_rate 0.6502558330004768\n",
      "round 142\n",
      "current_H 278.7476806640625,propsed_H279.2124938964844\n",
      "accept_rate 0.6282524314179991\n",
      "round 143\n",
      "current_H 279.0201721191406,propsed_H278.9128723144531\n",
      "accept_rate 1.0\n",
      "round 144\n",
      "current_H 279.9301452636719,propsed_H280.3705749511719\n",
      "accept_rate 0.6437597461295986\n",
      "round 145\n",
      "current_H 281.920166015625,propsed_H282.036865234375\n",
      "accept_rate 0.889852803953929\n",
      "round 146\n",
      "current_H 279.321044921875,propsed_H278.3731384277344\n",
      "accept_rate 1.0\n",
      "round 147\n",
      "current_H 276.3370056152344,propsed_H276.5791931152344\n",
      "accept_rate 0.7849089933174918\n",
      "round 148\n",
      "current_H 277.24969482421875,propsed_H277.58502197265625\n",
      "accept_rate 0.7151041028910742\n",
      "round 149\n",
      "current_H 279.4063415527344,propsed_H279.489990234375\n",
      "accept_rate 0.919754325922432\n",
      "round 150\n",
      "current_H 283.8777160644531,propsed_H283.8905334472656\n",
      "accept_rate 0.9872644100090056\n",
      "round 151\n",
      "current_H 279.3722229003906,propsed_H279.239013671875\n",
      "accept_rate 1.0\n",
      "round 152\n",
      "current_H 279.54962158203125,propsed_H279.4327087402344\n",
      "accept_rate 1.0\n",
      "round 153\n",
      "current_H 282.29833984375,propsed_H285.3258361816406\n",
      "accept_rate 0.04843675571402514\n",
      "round 154\n",
      "current_H 280.2610778808594,propsed_H280.88507080078125\n",
      "accept_rate 0.5358007511652045\n",
      "round 155\n",
      "current_H 281.2649230957031,propsed_H281.84161376953125\n",
      "accept_rate 0.5617543221708837\n",
      "round 156\n",
      "current_H 278.4883117675781,propsed_H278.509521484375\n",
      "accept_rate 0.9790136274368463\n",
      "round 157\n",
      "current_H 282.2640686035156,propsed_H282.4691162109375\n",
      "accept_rate 0.8146085340761137\n",
      "round 158\n",
      "current_H 281.5470275878906,propsed_H281.94110107421875\n",
      "accept_rate 0.6743045022577873\n",
      "round 159\n",
      "current_H 280.49786376953125,propsed_H280.18035888671875\n",
      "accept_rate 1.0\n",
      "round 160\n",
      "current_H 280.3677978515625,propsed_H281.0778503417969\n",
      "accept_rate 0.49161839161909454\n",
      "round 161\n",
      "current_H 279.45294189453125,propsed_H279.51116943359375\n",
      "accept_rate 0.9434352546388558\n",
      "round 162\n",
      "current_H 283.03619384765625,propsed_H283.46856689453125\n",
      "accept_rate 0.648967236323615\n",
      "round 163\n",
      "current_H 281.5278015136719,propsed_H281.23480224609375\n",
      "accept_rate 1.0\n",
      "round 164\n",
      "current_H 281.0464782714844,propsed_H282.0214538574219\n",
      "accept_rate 0.3772015624732643\n",
      "round 165\n",
      "current_H 287.11651611328125,propsed_H287.1157531738281\n",
      "accept_rate 1.0\n",
      "round 166\n",
      "current_H 289.35284423828125,propsed_H288.41876220703125\n",
      "accept_rate 1.0\n",
      "round 167\n",
      "current_H 283.35894775390625,propsed_H282.92822265625\n",
      "accept_rate 1.0\n",
      "round 168\n",
      "current_H 279.34552001953125,propsed_H279.13134765625\n",
      "accept_rate 1.0\n",
      "round 169\n",
      "current_H 281.83197021484375,propsed_H283.07403564453125\n",
      "accept_rate 0.2887871320159851\n",
      "round 170\n",
      "current_H 278.5694885253906,propsed_H278.3006591796875\n",
      "accept_rate 1.0\n",
      "round 171\n",
      "current_H 276.79241943359375,propsed_H276.57342529296875\n",
      "accept_rate 1.0\n",
      "round 172\n",
      "current_H 278.36614990234375,propsed_H279.156982421875\n",
      "accept_rate 0.45346711785985616\n",
      "round 173\n",
      "current_H 276.4745178222656,propsed_H276.1919250488281\n",
      "accept_rate 1.0\n",
      "round 174\n",
      "current_H 276.4751892089844,propsed_H276.8875732421875\n",
      "accept_rate 0.6620699703729203\n",
      "round 175\n",
      "current_H 279.4079895019531,propsed_H279.56597900390625\n",
      "accept_rate 0.8538587457705682\n",
      "round 176\n",
      "current_H 282.3998718261719,propsed_H282.8580017089844\n",
      "accept_rate 0.6324653244972769\n",
      "round 177\n",
      "current_H 277.92962646484375,propsed_H276.8905944824219\n",
      "accept_rate 1.0\n",
      "round 178\n",
      "current_H 276.3719482421875,propsed_H276.3513488769531\n",
      "accept_rate 1.0\n",
      "round 179\n",
      "current_H 276.3873596191406,propsed_H276.65093994140625\n",
      "accept_rate 0.768295908692711\n",
      "round 180\n",
      "current_H 278.0802307128906,propsed_H278.3669128417969\n",
      "accept_rate 0.7507503327418186\n",
      "round 181\n",
      "current_H 280.6973571777344,propsed_H281.044921875\n",
      "accept_rate 0.7064063098944459\n",
      "round 182\n",
      "current_H 276.6700744628906,propsed_H276.6347961425781\n",
      "accept_rate 1.0\n",
      "round 183\n",
      "current_H 282.5969543457031,propsed_H282.25518798828125\n",
      "accept_rate 1.0\n",
      "round 184\n",
      "current_H 276.0171813964844,propsed_H276.229248046875\n",
      "accept_rate 0.8089107815501869\n",
      "round 185\n",
      "current_H 279.7703857421875,propsed_H280.0418395996094\n",
      "accept_rate 0.7622704557806205\n",
      "round 186\n",
      "current_H 276.3231506347656,propsed_H276.1754455566406\n",
      "accept_rate 1.0\n",
      "round 187\n",
      "current_H 279.3177490234375,propsed_H280.8138122558594\n",
      "accept_rate 0.22401030305091085\n",
      "round 188\n",
      "current_H 276.56585693359375,propsed_H277.01171875\n",
      "accept_rate 0.6402722410682729\n",
      "round 189\n",
      "current_H 278.70404052734375,propsed_H279.5749816894531\n",
      "accept_rate 0.41855743341635854\n",
      "round 190\n",
      "current_H 281.6683044433594,propsed_H282.8155822753906\n",
      "accept_rate 0.31749988208628155\n",
      "round 191\n",
      "current_H 279.3645935058594,propsed_H279.156005859375\n",
      "accept_rate 1.0\n",
      "round 192\n",
      "current_H 278.6567687988281,propsed_H277.9977722167969\n",
      "accept_rate 1.0\n",
      "round 193\n",
      "current_H 276.8734436035156,propsed_H276.91473388671875\n",
      "accept_rate 0.9595505481092754\n",
      "round 194\n",
      "current_H 277.1644592285156,propsed_H277.48297119140625\n",
      "accept_rate 0.72723037812607\n",
      "round 195\n",
      "current_H 280.0153503417969,propsed_H280.0472106933594\n",
      "accept_rate 0.9686418419542887\n",
      "round 196\n",
      "current_H 282.10650634765625,propsed_H281.9912109375\n",
      "accept_rate 1.0\n",
      "round 197\n",
      "current_H 281.69403076171875,propsed_H281.5545959472656\n",
      "accept_rate 1.0\n",
      "round 198\n",
      "current_H 277.9869384765625,propsed_H277.4250183105469\n",
      "accept_rate 1.0\n",
      "round 199\n",
      "current_H 276.28662109375,propsed_H276.8400573730469\n",
      "accept_rate 0.57497065210953\n",
      "round 200\n",
      "current_H 277.3526306152344,propsed_H277.67254638671875\n",
      "accept_rate 0.7262102021050899\n",
      "round 201\n",
      "current_H 277.3380126953125,propsed_H276.5953369140625\n",
      "accept_rate 1.0\n",
      "round 202\n",
      "current_H 277.5685119628906,propsed_H277.3706359863281\n",
      "accept_rate 1.0\n",
      "round 203\n",
      "current_H 277.8230285644531,propsed_H278.0076599121094\n",
      "accept_rate 0.831410728876636\n",
      "round 204\n",
      "current_H 276.22076416015625,propsed_H276.16015625\n",
      "accept_rate 1.0\n",
      "round 205\n",
      "current_H 275.4296875,propsed_H275.4364929199219\n",
      "accept_rate 0.9932176845067916\n",
      "round 206\n",
      "current_H 277.26031494140625,propsed_H277.2446594238281\n",
      "accept_rate 1.0\n",
      "round 207\n",
      "current_H 277.54510498046875,propsed_H277.47802734375\n",
      "accept_rate 1.0\n",
      "round 208\n",
      "current_H 281.0091857910156,propsed_H282.35211181640625\n",
      "accept_rate 0.26108062132531856\n",
      "round 209\n",
      "current_H 277.7604064941406,propsed_H279.1341857910156\n",
      "accept_rate 0.25314842634632323\n",
      "round 210\n",
      "current_H 276.68878173828125,propsed_H277.6166076660156\n",
      "accept_rate 0.3954124317735761\n",
      "round 211\n",
      "current_H 277.3492431640625,propsed_H276.99395751953125\n",
      "accept_rate 1.0\n",
      "round 212\n",
      "current_H 277.1395263671875,propsed_H277.1806640625\n",
      "accept_rate 0.9596969750745662\n",
      "round 213\n",
      "current_H 276.78204345703125,propsed_H276.71343994140625\n",
      "accept_rate 1.0\n",
      "round 214\n",
      "current_H 277.4410095214844,propsed_H277.23992919921875\n",
      "accept_rate 1.0\n",
      "round 215\n",
      "current_H 282.7898254394531,propsed_H283.79779052734375\n",
      "accept_rate 0.36496088778651103\n",
      "round 216\n",
      "current_H 281.8226623535156,propsed_H281.3880920410156\n",
      "accept_rate 1.0\n",
      "round 217\n",
      "current_H 278.59271240234375,propsed_H278.8633728027344\n",
      "accept_rate 0.7628755246498035\n",
      "round 218\n",
      "current_H 279.0758972167969,propsed_H278.89337158203125\n",
      "accept_rate 1.0\n",
      "round 219\n",
      "current_H 282.33905029296875,propsed_H282.798828125\n",
      "accept_rate 0.6314239120929477\n",
      "round 220\n",
      "current_H 281.0676574707031,propsed_H280.7904357910156\n",
      "accept_rate 1.0\n",
      "round 221\n",
      "current_H 282.3247375488281,propsed_H281.75787353515625\n",
      "accept_rate 1.0\n",
      "round 222\n",
      "current_H 281.2640686035156,propsed_H281.6407775878906\n",
      "accept_rate 0.6861157152389287\n",
      "round 223\n",
      "current_H 280.3048095703125,propsed_H279.7809143066406\n",
      "accept_rate 1.0\n",
      "round 224\n",
      "current_H 276.9752197265625,propsed_H277.1338806152344\n",
      "accept_rate 0.8532856687486466\n",
      "round 225\n",
      "current_H 279.095947265625,propsed_H279.3314208984375\n",
      "accept_rate 0.7901964979933525\n",
      "round 226\n",
      "current_H 280.16778564453125,propsed_H280.31817626953125\n",
      "accept_rate 0.8603718280300245\n",
      "round 227\n",
      "current_H 279.8262023925781,propsed_H279.8737487792969\n",
      "accept_rate 0.9535662392977512\n",
      "round 228\n",
      "current_H 278.34063720703125,propsed_H277.4096374511719\n",
      "accept_rate 1.0\n",
      "round 229\n",
      "current_H 277.4807434082031,propsed_H277.6946105957031\n",
      "accept_rate 0.8074556181008563\n",
      "round 230\n",
      "current_H 280.9771728515625,propsed_H281.3282775878906\n",
      "accept_rate 0.7039100250432924\n",
      "round 231\n",
      "current_H 283.38494873046875,propsed_H284.8658752441406\n",
      "accept_rate 0.22742687662835848\n",
      "round 232\n",
      "current_H 280.11187744140625,propsed_H279.93157958984375\n",
      "accept_rate 1.0\n",
      "round 233\n",
      "current_H 279.9047546386719,propsed_H279.9660949707031\n",
      "accept_rate 0.9405031019714343\n",
      "round 234\n",
      "current_H 280.2490234375,propsed_H280.45135498046875\n",
      "accept_rate 0.8168240707669532\n",
      "round 235\n",
      "current_H 280.1723327636719,propsed_H280.1896667480469\n",
      "accept_rate 0.9828153848324155\n",
      "round 236\n",
      "current_H 281.0737609863281,propsed_H280.9058837890625\n",
      "accept_rate 1.0\n",
      "round 237\n",
      "current_H 281.5761413574219,propsed_H282.1729736328125\n",
      "accept_rate 0.5505528766488343\n",
      "round 238\n",
      "current_H 283.62078857421875,propsed_H283.8173828125\n",
      "accept_rate 0.8215239086460657\n",
      "round 239\n",
      "current_H 281.55242919921875,propsed_H281.9839782714844\n",
      "accept_rate 0.6495021892121942\n",
      "round 240\n",
      "current_H 282.6762390136719,propsed_H282.84100341796875\n",
      "accept_rate 0.8480934877344659\n",
      "round 241\n",
      "current_H 282.7942199707031,propsed_H282.0660705566406\n",
      "accept_rate 1.0\n",
      "round 242\n",
      "current_H 281.9126892089844,propsed_H281.3299255371094\n",
      "accept_rate 1.0\n",
      "round 243\n",
      "current_H 277.3551330566406,propsed_H277.5240173339844\n",
      "accept_rate 0.844606637854498\n",
      "round 244\n",
      "current_H 279.8253173828125,propsed_H280.31781005859375\n",
      "accept_rate 0.6111012168846521\n",
      "round 245\n",
      "current_H 284.1201171875,propsed_H284.5506591796875\n",
      "accept_rate 0.6501566194041419\n",
      "round 246\n",
      "current_H 282.21142578125,propsed_H282.5813903808594\n",
      "accept_rate 0.6907587833352923\n",
      "round 247\n",
      "current_H 284.17724609375,propsed_H284.0389099121094\n",
      "accept_rate 1.0\n",
      "round 248\n",
      "current_H 283.16534423828125,propsed_H282.6060791015625\n",
      "accept_rate 1.0\n",
      "round 249\n",
      "current_H 281.82818603515625,propsed_H281.9422912597656\n",
      "accept_rate 0.8921640733270031\n",
      "round 250\n",
      "current_H 280.5556640625,propsed_H279.95086669921875\n",
      "accept_rate 1.0\n",
      "round 251\n",
      "current_H 277.7842712402344,propsed_H277.9299621582031\n",
      "accept_rate 0.8644248400843445\n",
      "round 252\n",
      "current_H 283.8924865722656,propsed_H284.9338073730469\n",
      "accept_rate 0.3529881469064664\n",
      "round 253\n",
      "current_H 279.0265197753906,propsed_H278.7314453125\n",
      "accept_rate 1.0\n",
      "round 254\n",
      "current_H 276.40692138671875,propsed_H276.50140380859375\n",
      "accept_rate 0.9098437278322425\n",
      "round 255\n",
      "current_H 278.294189453125,propsed_H278.87005615234375\n",
      "accept_rate 0.5622173842185451\n",
      "round 256\n",
      "current_H 276.5845031738281,propsed_H276.79010009765625\n",
      "accept_rate 0.8141611791246306\n",
      "round 257\n",
      "current_H 278.001953125,propsed_H277.3984680175781\n",
      "accept_rate 1.0\n",
      "round 258\n",
      "current_H 281.9470520019531,propsed_H283.5187072753906\n",
      "accept_rate 0.2077010955503052\n",
      "round 259\n",
      "current_H 278.07696533203125,propsed_H278.1026611328125\n",
      "accept_rate 0.9746315266674839\n",
      "round 260\n",
      "current_H 276.5957946777344,propsed_H276.58203125\n",
      "accept_rate 1.0\n",
      "round 261\n",
      "current_H 274.77783203125,propsed_H274.7640380859375\n",
      "accept_rate 1.0\n",
      "round 262\n",
      "current_H 276.4193420410156,propsed_H276.6627502441406\n",
      "accept_rate 0.7839514370213958\n",
      "round 263\n",
      "current_H 277.2091979980469,propsed_H277.1493225097656\n",
      "accept_rate 1.0\n",
      "round 264\n",
      "current_H 278.4823913574219,propsed_H278.5354919433594\n",
      "accept_rate 0.9482846235871075\n",
      "round 265\n",
      "current_H 278.0374755859375,propsed_H277.99395751953125\n",
      "accept_rate 1.0\n",
      "round 266\n",
      "current_H 277.9098205566406,propsed_H278.17474365234375\n",
      "accept_rate 0.767264953678787\n",
      "round 267\n",
      "current_H 276.1444091796875,propsed_H276.08770751953125\n",
      "accept_rate 1.0\n",
      "round 268\n",
      "current_H 277.27325439453125,propsed_H277.23443603515625\n",
      "accept_rate 1.0\n",
      "round 269\n",
      "current_H 277.6966552734375,propsed_H277.8277893066406\n",
      "accept_rate 0.8771002059621164\n",
      "round 270\n",
      "current_H 278.6771240234375,propsed_H278.9332580566406\n",
      "accept_rate 0.7740382150178783\n",
      "round 271\n",
      "current_H 277.8547668457031,propsed_H277.32305908203125\n",
      "accept_rate 1.0\n",
      "round 272\n",
      "current_H 277.67596435546875,propsed_H277.7743835449219\n",
      "accept_rate 0.9062689257427314\n",
      "round 273\n",
      "current_H 275.25665283203125,propsed_H275.24346923828125\n",
      "accept_rate 1.0\n",
      "round 274\n",
      "current_H 277.9876403808594,propsed_H278.68035888671875\n",
      "accept_rate 0.5002143832973501\n",
      "round 275\n",
      "current_H 279.4308166503906,propsed_H278.9974365234375\n",
      "accept_rate 1.0\n",
      "round 276\n",
      "current_H 283.0597839355469,propsed_H283.20794677734375\n",
      "accept_rate 0.8622906865437241\n",
      "round 277\n",
      "current_H 280.9875183105469,propsed_H281.2206726074219\n",
      "accept_rate 0.7920313561325224\n",
      "round 278\n",
      "current_H 282.55694580078125,propsed_H283.1007995605469\n",
      "accept_rate 0.5805068023844628\n",
      "round 279\n",
      "current_H 281.6565246582031,propsed_H281.523193359375\n",
      "accept_rate 1.0\n",
      "round 280\n",
      "current_H 280.19219970703125,propsed_H279.7249450683594\n",
      "accept_rate 1.0\n",
      "round 281\n",
      "current_H 283.34088134765625,propsed_H283.16961669921875\n",
      "accept_rate 1.0\n",
      "round 282\n",
      "current_H 282.5201416015625,propsed_H282.96209716796875\n",
      "accept_rate 0.64277819576623\n",
      "round 283\n",
      "current_H 282.94091796875,propsed_H282.1347351074219\n",
      "accept_rate 1.0\n",
      "round 284\n",
      "current_H 278.0506591796875,propsed_H278.50390625\n",
      "accept_rate 0.6355610859501855\n",
      "round 285\n",
      "current_H 278.5130615234375,propsed_H278.99029541015625\n",
      "accept_rate 0.620497386222924\n",
      "round 286\n",
      "current_H 278.4941711425781,propsed_H277.9873352050781\n",
      "accept_rate 1.0\n",
      "round 287\n",
      "current_H 278.5434265136719,propsed_H278.6699523925781\n",
      "accept_rate 0.881151346015376\n",
      "round 288\n",
      "current_H 280.9590148925781,propsed_H280.7449645996094\n",
      "accept_rate 1.0\n",
      "round 289\n",
      "current_H 280.0611572265625,propsed_H281.2112731933594\n",
      "accept_rate 0.316600052156166\n",
      "round 290\n",
      "current_H 281.0043640136719,propsed_H279.69122314453125\n",
      "accept_rate 1.0\n",
      "round 291\n",
      "current_H 280.1609802246094,propsed_H280.127685546875\n",
      "accept_rate 1.0\n",
      "round 292\n",
      "current_H 281.0296936035156,propsed_H282.6549987792969\n",
      "accept_rate 0.19685159169835809\n",
      "round 293\n",
      "current_H 276.9562072753906,propsed_H277.4308166503906\n",
      "accept_rate 0.6221280277674447\n",
      "round 294\n",
      "current_H 281.1557922363281,propsed_H281.2748718261719\n",
      "accept_rate 0.8877371430896612\n",
      "round 295\n",
      "current_H 281.43682861328125,propsed_H281.0461120605469\n",
      "accept_rate 1.0\n",
      "round 296\n",
      "current_H 281.8981628417969,propsed_H283.06695556640625\n",
      "accept_rate 0.31074186590884784\n",
      "round 297\n",
      "current_H 279.2775573730469,propsed_H279.6969299316406\n",
      "accept_rate 0.6574592075566967\n",
      "round 298\n",
      "current_H 277.9708557128906,propsed_H277.8164367675781\n",
      "accept_rate 1.0\n",
      "round 299\n",
      "current_H 280.8609619140625,propsed_H281.9501647949219\n",
      "accept_rate 0.3364846051534473\n",
      "round 300\n",
      "current_H 282.96063232421875,propsed_H282.6455383300781\n",
      "accept_rate 1.0\n",
      "round 301\n",
      "current_H 282.328369140625,propsed_H281.5010681152344\n",
      "accept_rate 1.0\n",
      "round 302\n",
      "current_H 281.2503356933594,propsed_H281.0806579589844\n",
      "accept_rate 1.0\n",
      "round 303\n",
      "current_H 281.4698181152344,propsed_H281.1781311035156\n",
      "accept_rate 1.0\n",
      "round 304\n",
      "current_H 278.545166015625,propsed_H278.537353515625\n",
      "accept_rate 1.0\n",
      "round 305\n",
      "current_H 280.864013671875,propsed_H281.0653991699219\n",
      "accept_rate 0.8175971886756415\n",
      "round 306\n",
      "current_H 277.1838684082031,propsed_H277.17572021484375\n",
      "accept_rate 1.0\n",
      "round 307\n",
      "current_H 278.1419677734375,propsed_H278.3193054199219\n",
      "accept_rate 0.8374969588742992\n",
      "round 308\n",
      "current_H 281.8774719238281,propsed_H282.8458557128906\n",
      "accept_rate 0.3796962116312089\n",
      "round 309\n",
      "current_H 279.73736572265625,propsed_H279.8424072265625\n",
      "accept_rate 0.9002871563771128\n",
      "round 310\n",
      "current_H 278.0387878417969,propsed_H277.6920166015625\n",
      "accept_rate 1.0\n",
      "round 311\n",
      "current_H 276.048583984375,propsed_H275.8974914550781\n",
      "accept_rate 1.0\n",
      "round 312\n",
      "current_H 275.1288146972656,propsed_H274.9595947265625\n",
      "accept_rate 1.0\n",
      "round 313\n",
      "current_H 275.4282531738281,propsed_H275.56744384765625\n",
      "accept_rate 0.8700621145669448\n",
      "round 314\n",
      "current_H 280.4168395996094,propsed_H280.83770751953125\n",
      "accept_rate 0.6564768031907088\n",
      "round 315\n",
      "current_H 281.500244140625,propsed_H281.67315673828125\n",
      "accept_rate 0.841211135456467\n",
      "round 316\n",
      "current_H 281.5318298339844,propsed_H281.25982666015625\n",
      "accept_rate 1.0\n",
      "round 317\n",
      "current_H 281.8376159667969,propsed_H282.22979736328125\n",
      "accept_rate 0.675581554726119\n",
      "round 318\n",
      "current_H 280.2200622558594,propsed_H279.3131103515625\n",
      "accept_rate 1.0\n",
      "round 319\n",
      "current_H 277.3891906738281,propsed_H277.5744934082031\n",
      "accept_rate 0.830852718096916\n",
      "round 320\n",
      "current_H 277.41021728515625,propsed_H277.45806884765625\n",
      "accept_rate 0.9532752783750715\n",
      "round 321\n",
      "current_H 278.1809997558594,propsed_H278.1402587890625\n",
      "accept_rate 1.0\n",
      "round 322\n",
      "current_H 279.6445617675781,propsed_H280.7267761230469\n",
      "accept_rate 0.3388443724026411\n",
      "round 323\n",
      "current_H 279.60626220703125,propsed_H279.78033447265625\n",
      "accept_rate 0.8402361752720336\n",
      "round 324\n",
      "current_H 278.0809631347656,propsed_H277.84405517578125\n",
      "accept_rate 1.0\n",
      "round 325\n",
      "current_H 280.30194091796875,propsed_H280.61456298828125\n",
      "accept_rate 0.7315263258489259\n",
      "round 326\n",
      "current_H 279.44677734375,propsed_H280.2321472167969\n",
      "accept_rate 0.45595102659792586\n",
      "round 327\n",
      "current_H 280.50677490234375,propsed_H280.3700256347656\n",
      "accept_rate 1.0\n",
      "round 328\n",
      "current_H 280.3119812011719,propsed_H280.0833435058594\n",
      "accept_rate 1.0\n",
      "round 329\n",
      "current_H 281.409912109375,propsed_H281.4619140625\n",
      "accept_rate 0.9493270126867572\n",
      "round 330\n",
      "current_H 281.4415283203125,propsed_H280.9459533691406\n",
      "accept_rate 1.0\n",
      "round 331\n",
      "current_H 275.23846435546875,propsed_H275.4369812011719\n",
      "accept_rate 0.819945958057875\n",
      "round 332\n",
      "current_H 276.7079772949219,propsed_H276.8359069824219\n",
      "accept_rate 0.8799152460103464\n",
      "round 333\n",
      "current_H 278.4205627441406,propsed_H279.2990417480469\n",
      "accept_rate 0.415414274898779\n",
      "round 334\n",
      "current_H 277.58331298828125,propsed_H278.21002197265625\n",
      "accept_rate 0.5343474563056747\n",
      "round 335\n",
      "current_H 276.3923645019531,propsed_H276.33026123046875\n",
      "accept_rate 1.0\n",
      "round 336\n",
      "current_H 284.5265197753906,propsed_H284.7942199707031\n",
      "accept_rate 0.7651371384206255\n",
      "round 337\n",
      "current_H 284.20074462890625,propsed_H283.85589599609375\n",
      "accept_rate 1.0\n",
      "round 338\n",
      "current_H 281.7337951660156,propsed_H281.23956298828125\n",
      "accept_rate 1.0\n",
      "round 339\n",
      "current_H 276.54547119140625,propsed_H276.8022766113281\n",
      "accept_rate 0.7735187104542569\n",
      "round 340\n",
      "current_H 279.44140625,propsed_H279.5210266113281\n",
      "accept_rate 0.9234668635810953\n",
      "round 341\n",
      "current_H 278.2157897949219,propsed_H278.68035888671875\n",
      "accept_rate 0.6284058320841686\n",
      "round 342\n",
      "current_H 277.8835144042969,propsed_H277.5801696777344\n",
      "accept_rate 1.0\n",
      "round 343\n",
      "current_H 278.5638427734375,propsed_H277.90521240234375\n",
      "accept_rate 1.0\n",
      "round 344\n",
      "current_H 275.80145263671875,propsed_H275.73046875\n",
      "accept_rate 1.0\n",
      "round 345\n",
      "current_H 275.03765869140625,propsed_H275.0870666503906\n",
      "accept_rate 0.9517927580771245\n",
      "round 346\n",
      "current_H 276.0722961425781,propsed_H276.0704345703125\n",
      "accept_rate 1.0\n",
      "round 347\n",
      "current_H 282.4452819824219,propsed_H283.515625\n",
      "accept_rate 0.34289087964485104\n",
      "round 348\n",
      "current_H 282.61077880859375,propsed_H283.07220458984375\n",
      "accept_rate 0.6303842144700521\n",
      "round 349\n",
      "current_H 282.1598815917969,propsed_H281.720458984375\n",
      "accept_rate 1.0\n",
      "round 350\n",
      "current_H 279.0555725097656,propsed_H278.8989562988281\n",
      "accept_rate 1.0\n",
      "round 351\n",
      "current_H 284.56622314453125,propsed_H285.18865966796875\n",
      "accept_rate 0.5366353188612883\n",
      "round 352\n",
      "current_H 278.3774108886719,propsed_H278.4322509765625\n",
      "accept_rate 0.9466365144923339\n",
      "round 353\n",
      "current_H 277.5064697265625,propsed_H277.45947265625\n",
      "accept_rate 1.0\n",
      "round 354\n",
      "current_H 281.60308837890625,propsed_H282.412109375\n",
      "accept_rate 0.4452937972638936\n",
      "round 355\n",
      "current_H 281.0073547363281,propsed_H282.82470703125\n",
      "accept_rate 0.1624553157669607\n",
      "round 356\n",
      "current_H 280.724365234375,propsed_H281.0567932128906\n",
      "accept_rate 0.7171803193951567\n",
      "round 357\n",
      "current_H 277.9695129394531,propsed_H277.56011962890625\n",
      "accept_rate 1.0\n",
      "round 358\n",
      "current_H 278.9848327636719,propsed_H279.4085998535156\n",
      "accept_rate 0.6545763216291381\n",
      "round 359\n",
      "current_H 275.7743835449219,propsed_H275.9707946777344\n",
      "accept_rate 0.821674347939156\n",
      "round 360\n",
      "current_H 287.1062316894531,propsed_H288.6018981933594\n",
      "accept_rate 0.22409919195714098\n",
      "round 361\n",
      "current_H 280.83282470703125,propsed_H279.2423095703125\n",
      "accept_rate 1.0\n",
      "round 362\n",
      "current_H 280.5986022949219,propsed_H281.5858459472656\n",
      "accept_rate 0.37260229837934566\n",
      "round 363\n",
      "current_H 284.4603271484375,propsed_H284.3978271484375\n",
      "accept_rate 1.0\n",
      "round 364\n",
      "current_H 282.5146484375,propsed_H281.93609619140625\n",
      "accept_rate 1.0\n",
      "round 365\n",
      "current_H 278.9383239746094,propsed_H278.0732116699219\n",
      "accept_rate 1.0\n",
      "round 366\n",
      "current_H 274.0706787109375,propsed_H273.97088623046875\n",
      "accept_rate 1.0\n",
      "round 367\n",
      "current_H 275.568359375,propsed_H275.836181640625\n",
      "accept_rate 0.7650437435915171\n",
      "round 368\n",
      "current_H 275.79742431640625,propsed_H275.5609436035156\n",
      "accept_rate 1.0\n",
      "round 369\n",
      "current_H 276.7508850097656,propsed_H276.6568298339844\n",
      "accept_rate 1.0\n",
      "round 370\n",
      "current_H 273.6637268066406,propsed_H273.89215087890625\n",
      "accept_rate 0.7957867171931614\n",
      "round 371\n",
      "current_H 276.52264404296875,propsed_H276.71038818359375\n",
      "accept_rate 0.828826743198327\n",
      "round 372\n",
      "current_H 276.4300537109375,propsed_H277.85894775390625\n",
      "accept_rate 0.23957373403719148\n",
      "round 373\n",
      "current_H 276.75469970703125,propsed_H276.96844482421875\n",
      "accept_rate 0.8075541904767457\n",
      "round 374\n",
      "current_H 278.71014404296875,propsed_H278.5852966308594\n",
      "accept_rate 1.0\n",
      "round 375\n",
      "current_H 280.5091857910156,propsed_H280.92608642578125\n",
      "accept_rate 0.6590864069658017\n",
      "round 376\n",
      "current_H 276.9768981933594,propsed_H277.14410400390625\n",
      "accept_rate 0.8460254724528378\n",
      "round 377\n",
      "current_H 278.1873779296875,propsed_H278.36151123046875\n",
      "accept_rate 0.840184892890819\n",
      "round 378\n",
      "current_H 279.1029052734375,propsed_H278.8748474121094\n",
      "accept_rate 1.0\n",
      "round 379\n",
      "current_H 278.7853698730469,propsed_H278.4462585449219\n",
      "accept_rate 1.0\n",
      "round 380\n",
      "current_H 279.383056640625,propsed_H279.6047668457031\n",
      "accept_rate 0.8011474991742193\n",
      "round 381\n",
      "current_H 278.6780700683594,propsed_H279.0930480957031\n",
      "accept_rate 0.6603547902943854\n",
      "round 382\n",
      "current_H 278.4239501953125,propsed_H278.0060729980469\n",
      "accept_rate 1.0\n",
      "round 383\n",
      "current_H 278.71142578125,propsed_H278.9842834472656\n",
      "accept_rate 0.7612011247077177\n",
      "round 384\n",
      "current_H 277.76678466796875,propsed_H277.50067138671875\n",
      "accept_rate 1.0\n",
      "round 385\n",
      "current_H 281.3730163574219,propsed_H282.82037353515625\n",
      "accept_rate 0.23519103557535745\n",
      "round 386\n",
      "current_H 281.3060607910156,propsed_H282.2226867675781\n",
      "accept_rate 0.3998659245999506\n",
      "round 387\n",
      "current_H 277.1288757324219,propsed_H277.12188720703125\n",
      "accept_rate 1.0\n",
      "round 388\n",
      "current_H 276.4974670410156,propsed_H276.4688415527344\n",
      "accept_rate 1.0\n",
      "round 389\n",
      "current_H 278.74688720703125,propsed_H278.8611145019531\n",
      "accept_rate 0.8920551732266406\n",
      "round 390\n",
      "current_H 277.36578369140625,propsed_H277.4259338378906\n",
      "accept_rate 0.9416231415654449\n",
      "round 391\n",
      "current_H 279.1246643066406,propsed_H278.9565734863281\n",
      "accept_rate 1.0\n",
      "round 392\n",
      "current_H 275.07440185546875,propsed_H274.8711242675781\n",
      "accept_rate 1.0\n",
      "round 393\n",
      "current_H 276.7225646972656,propsed_H277.0540771484375\n",
      "accept_rate 0.7178372182465087\n",
      "round 394\n",
      "current_H 280.6423645019531,propsed_H281.3507995605469\n",
      "accept_rate 0.4924141941654309\n",
      "round 395\n",
      "current_H 279.3014831542969,propsed_H279.068359375\n",
      "accept_rate 1.0\n",
      "round 396\n",
      "current_H 277.0912170410156,propsed_H277.18145751953125\n",
      "accept_rate 0.9137114308805746\n",
      "round 397\n",
      "current_H 277.6484680175781,propsed_H277.6289978027344\n",
      "accept_rate 1.0\n",
      "round 398\n",
      "current_H 281.0867004394531,propsed_H281.7608947753906\n",
      "accept_rate 0.5095667949275471\n",
      "round 399\n",
      "current_H 277.36822509765625,propsed_H277.79315185546875\n",
      "accept_rate 0.6538176704126216\n",
      "round 400\n",
      "current_H 279.1490783691406,propsed_H279.6076965332031\n",
      "accept_rate 0.6321565789215218\n",
      "round 401\n",
      "current_H 279.8154602050781,propsed_H279.6634521484375\n",
      "accept_rate 1.0\n",
      "round 402\n",
      "current_H 280.81463623046875,propsed_H280.8268127441406\n",
      "accept_rate 0.9878973200876248\n",
      "round 403\n",
      "current_H 278.12615966796875,propsed_H277.6666564941406\n",
      "accept_rate 1.0\n",
      "round 404\n",
      "current_H 278.7453308105469,propsed_H278.6746826171875\n",
      "accept_rate 1.0\n",
      "round 405\n",
      "current_H 277.0994873046875,propsed_H276.84063720703125\n",
      "accept_rate 1.0\n",
      "round 406\n",
      "current_H 275.3971252441406,propsed_H275.54412841796875\n",
      "accept_rate 0.8632912374739619\n",
      "round 407\n",
      "current_H 277.6097412109375,propsed_H277.35107421875\n",
      "accept_rate 1.0\n",
      "round 408\n",
      "current_H 282.55511474609375,propsed_H283.8632507324219\n",
      "accept_rate 0.2703234737013522\n",
      "round 409\n",
      "current_H 280.1602783203125,propsed_H280.5848693847656\n",
      "accept_rate 0.6540371895063107\n",
      "round 410\n",
      "current_H 277.4260559082031,propsed_H277.42999267578125\n",
      "accept_rate 0.9960709713325954\n",
      "round 411\n",
      "current_H 278.3171691894531,propsed_H279.36749267578125\n",
      "accept_rate 0.34982456734098766\n",
      "round 412\n",
      "current_H 278.02850341796875,propsed_H278.1351318359375\n",
      "accept_rate 0.8988596110238496\n",
      "round 413\n",
      "current_H 278.6253356933594,propsed_H278.7706604003906\n",
      "accept_rate 0.8647414598867089\n",
      "round 414\n",
      "current_H 275.8548583984375,propsed_H275.967041015625\n",
      "accept_rate 0.8938810045594022\n",
      "round 415\n",
      "current_H 280.6965637207031,propsed_H280.7398986816406\n",
      "accept_rate 0.9575905809020407\n",
      "round 416\n",
      "current_H 277.4874572753906,propsed_H276.89404296875\n",
      "accept_rate 1.0\n",
      "round 417\n",
      "current_H 276.0638122558594,propsed_H276.3181457519531\n",
      "accept_rate 0.7754331549918281\n",
      "round 418\n",
      "current_H 276.228271484375,propsed_H276.0496826171875\n",
      "accept_rate 1.0\n",
      "round 419\n",
      "current_H 278.4669494628906,propsed_H278.537109375\n",
      "accept_rate 0.9322447307643361\n",
      "round 420\n",
      "current_H 280.530517578125,propsed_H280.7459716796875\n",
      "accept_rate 0.8061752715942765\n",
      "round 421\n",
      "current_H 278.8976135253906,propsed_H279.404296875\n",
      "accept_rate 0.6024905191393867\n",
      "round 422\n",
      "current_H 280.820068359375,propsed_H280.2370910644531\n",
      "accept_rate 1.0\n",
      "round 423\n",
      "current_H 277.4742431640625,propsed_H277.6178894042969\n",
      "accept_rate 0.8661941184935874\n",
      "round 424\n",
      "current_H 278.416259765625,propsed_H278.4179992675781\n",
      "accept_rate 0.9982620101035286\n",
      "round 425\n",
      "current_H 282.57550048828125,propsed_H283.3368225097656\n",
      "accept_rate 0.4670485704456951\n",
      "round 426\n",
      "current_H 285.9792175292969,propsed_H285.5260925292969\n",
      "accept_rate 1.0\n",
      "round 427\n",
      "current_H 282.2525939941406,propsed_H282.3512268066406\n",
      "accept_rate 0.906075346490757\n",
      "round 428\n",
      "current_H 279.9762878417969,propsed_H279.0584716796875\n",
      "accept_rate 1.0\n",
      "round 429\n",
      "current_H 277.5852355957031,propsed_H277.694580078125\n",
      "accept_rate 0.8964215628328025\n",
      "round 430\n",
      "current_H 279.9048767089844,propsed_H280.027587890625\n",
      "accept_rate 0.884519091025536\n",
      "round 431\n",
      "current_H 278.2781066894531,propsed_H278.2956848144531\n",
      "accept_rate 0.9825754689579004\n",
      "round 432\n",
      "current_H 277.3711853027344,propsed_H277.7455139160156\n",
      "accept_rate 0.6877508706206648\n",
      "round 433\n",
      "current_H 279.751708984375,propsed_H280.5302734375\n",
      "accept_rate 0.4590645471887065\n",
      "round 434\n",
      "current_H 279.0317687988281,propsed_H279.47198486328125\n",
      "accept_rate 0.643897282737994\n",
      "round 435\n",
      "current_H 281.36199951171875,propsed_H281.9405212402344\n",
      "accept_rate 0.5607266604256026\n",
      "round 436\n",
      "current_H 282.18902587890625,propsed_H281.5360107421875\n",
      "accept_rate 1.0\n",
      "round 437\n",
      "current_H 280.5268249511719,propsed_H280.866455078125\n",
      "accept_rate 0.712033636113819\n",
      "round 438\n",
      "current_H 283.71612548828125,propsed_H284.2894592285156\n",
      "accept_rate 0.5636432628767967\n",
      "round 439\n",
      "current_H 285.556640625,propsed_H286.3831787109375\n",
      "accept_rate 0.43756146748814645\n",
      "round 440\n",
      "current_H 281.80804443359375,propsed_H281.2105712890625\n",
      "accept_rate 1.0\n",
      "round 441\n",
      "current_H 285.0700378417969,propsed_H285.5235900878906\n",
      "accept_rate 0.6353671576918575\n",
      "round 442\n",
      "current_H 288.6238098144531,propsed_H289.1409606933594\n",
      "accept_rate 0.5962168243049684\n",
      "round 443\n",
      "current_H 283.167724609375,propsed_H282.3957824707031\n",
      "accept_rate 1.0\n",
      "round 444\n",
      "current_H 279.88116455078125,propsed_H279.3353576660156\n",
      "accept_rate 1.0\n",
      "round 445\n",
      "current_H 278.4035339355469,propsed_H278.8899230957031\n",
      "accept_rate 0.6148424885509718\n",
      "round 446\n",
      "current_H 279.3178405761719,propsed_H279.8811340332031\n",
      "accept_rate 0.5693309058551692\n",
      "round 447\n",
      "current_H 279.8592529296875,propsed_H279.99517822265625\n",
      "accept_rate 0.8729078424063303\n",
      "round 448\n",
      "current_H 279.38250732421875,propsed_H278.9079895019531\n",
      "accept_rate 1.0\n",
      "round 449\n",
      "current_H 279.6736755371094,propsed_H279.9257507324219\n",
      "accept_rate 0.7771862951053241\n",
      "round 450\n",
      "current_H 280.15765380859375,propsed_H280.2265625\n",
      "accept_rate 0.9334119047156809\n",
      "round 451\n",
      "current_H 281.5486145019531,propsed_H282.4550476074219\n",
      "accept_rate 0.40396254913906127\n",
      "round 452\n",
      "current_H 282.56817626953125,propsed_H282.0619201660156\n",
      "accept_rate 1.0\n",
      "round 453\n",
      "current_H 283.32867431640625,propsed_H282.69061279296875\n",
      "accept_rate 1.0\n",
      "round 454\n",
      "current_H 280.2230529785156,propsed_H280.89031982421875\n",
      "accept_rate 0.513109069292535\n",
      "round 455\n",
      "current_H 282.6533508300781,propsed_H282.3089904785156\n",
      "accept_rate 1.0\n",
      "round 456\n",
      "current_H 280.5807800292969,propsed_H281.5990295410156\n",
      "accept_rate 0.36122671018180474\n",
      "round 457\n",
      "current_H 286.03656005859375,propsed_H286.8004455566406\n",
      "accept_rate 0.46585283565566843\n",
      "round 458\n",
      "current_H 285.0666198730469,propsed_H283.6177978515625\n",
      "accept_rate 1.0\n",
      "round 459\n",
      "current_H 279.3417053222656,propsed_H279.2024841308594\n",
      "accept_rate 1.0\n",
      "round 460\n",
      "current_H 278.7662353515625,propsed_H278.4438171386719\n",
      "accept_rate 1.0\n",
      "round 461\n",
      "current_H 275.68011474609375,propsed_H276.0941162109375\n",
      "accept_rate 0.6609999830035094\n",
      "round 462\n",
      "current_H 275.9261474609375,propsed_H275.5754699707031\n",
      "accept_rate 1.0\n",
      "round 463\n",
      "current_H 274.1421203613281,propsed_H274.1409912109375\n",
      "accept_rate 1.0\n",
      "round 464\n",
      "current_H 279.11505126953125,propsed_H279.8681640625\n",
      "accept_rate 0.47089845957742976\n",
      "round 465\n",
      "current_H 277.7953796386719,propsed_H276.9458312988281\n",
      "accept_rate 1.0\n",
      "round 466\n",
      "current_H 275.6966552734375,propsed_H275.658447265625\n",
      "accept_rate 1.0\n",
      "round 467\n",
      "current_H 278.9486999511719,propsed_H279.1890869140625\n",
      "accept_rate 0.7863235241629305\n",
      "round 468\n",
      "current_H 279.9369812011719,propsed_H280.06988525390625\n",
      "accept_rate 0.8755490946203504\n",
      "round 469\n",
      "current_H 278.02081298828125,propsed_H278.4206237792969\n",
      "accept_rate 0.6704468886102548\n",
      "round 470\n",
      "current_H 280.9934387207031,propsed_H280.5128173828125\n",
      "accept_rate 1.0\n",
      "round 471\n",
      "current_H 281.2022399902344,propsed_H282.10760498046875\n",
      "accept_rate 0.40439425820838687\n",
      "round 472\n",
      "current_H 279.37213134765625,propsed_H279.47296142578125\n",
      "accept_rate 0.9040866439322554\n",
      "round 473\n",
      "current_H 282.55377197265625,propsed_H283.8880615234375\n",
      "accept_rate 0.26334520240489734\n",
      "round 474\n",
      "current_H 277.884765625,propsed_H277.830322265625\n",
      "accept_rate 1.0\n",
      "round 475\n",
      "current_H 278.0107421875,propsed_H278.1463928222656\n",
      "accept_rate 0.8731476266336645\n",
      "round 476\n",
      "current_H 280.3040771484375,propsed_H280.8713684082031\n",
      "accept_rate 0.5670593767909075\n",
      "round 477\n",
      "current_H 277.55816650390625,propsed_H277.4080810546875\n",
      "accept_rate 1.0\n",
      "round 478\n",
      "current_H 278.1322937011719,propsed_H278.1848449707031\n",
      "accept_rate 0.9488056749865774\n",
      "round 479\n",
      "current_H 275.9832458496094,propsed_H276.0654296875\n",
      "accept_rate 0.9211026095696401\n",
      "round 480\n",
      "current_H 278.1477355957031,propsed_H278.1239929199219\n",
      "accept_rate 1.0\n",
      "round 481\n",
      "current_H 279.99957275390625,propsed_H280.1614990234375\n",
      "accept_rate 0.8505039102805215\n",
      "round 482\n",
      "current_H 283.85791015625,propsed_H283.951904296875\n",
      "accept_rate 0.910288095944453\n",
      "round 483\n",
      "current_H 277.3046875,propsed_H276.9822692871094\n",
      "accept_rate 1.0\n",
      "round 484\n",
      "current_H 278.8976135253906,propsed_H279.4744873046875\n",
      "accept_rate 0.5616514712989662\n",
      "round 485\n",
      "current_H 283.8631896972656,propsed_H285.5564270019531\n",
      "accept_rate 0.18392314392587045\n",
      "round 486\n",
      "current_H 280.6573486328125,propsed_H280.9540100097656\n",
      "accept_rate 0.7432956667949588\n",
      "round 487\n",
      "current_H 279.19903564453125,propsed_H278.9942932128906\n",
      "accept_rate 1.0\n",
      "round 488\n",
      "current_H 282.8998107910156,propsed_H282.931884765625\n",
      "accept_rate 0.9684349398329974\n",
      "round 489\n",
      "current_H 282.7970275878906,propsed_H282.8868713378906\n",
      "accept_rate 0.9140739981758944\n",
      "round 490\n",
      "current_H 279.9751892089844,propsed_H279.59991455078125\n",
      "accept_rate 1.0\n",
      "round 491\n",
      "current_H 276.55926513671875,propsed_H276.59478759765625\n",
      "accept_rate 0.9651010569120344\n",
      "round 492\n",
      "current_H 276.15667724609375,propsed_H276.0552673339844\n",
      "accept_rate 1.0\n",
      "round 493\n",
      "current_H 279.09405517578125,propsed_H279.2626647949219\n",
      "accept_rate 0.8448386478562652\n",
      "round 494\n",
      "current_H 287.1672668457031,propsed_H288.3943176269531\n",
      "accept_rate 0.29315588484653576\n",
      "round 495\n",
      "current_H 279.5086364746094,propsed_H279.3215637207031\n",
      "accept_rate 1.0\n",
      "round 496\n",
      "current_H 276.5362243652344,propsed_H277.2976379394531\n",
      "accept_rate 0.46700581282930304\n",
      "round 497\n",
      "current_H 279.2740173339844,propsed_H278.6123046875\n",
      "accept_rate 1.0\n",
      "round 498\n",
      "current_H 278.8062438964844,propsed_H278.7434387207031\n",
      "accept_rate 1.0\n",
      "round 499\n",
      "current_H 280.6148681640625,propsed_H280.3049621582031\n",
      "accept_rate 1.0\n",
      "length of chain is 500\n",
      "burn in is 100\n",
      "total time is 1527061961.057067\n",
      "sd is [0.14882859 0.13430805 0.11647929 0.14182821 0.14591965 0.11813326\n",
      " 0.15791513]\n",
      "mean is [ 0.33919823  1.0713744  -0.08725935  0.05106548  0.50662214  0.45208302\n",
      "  0.21474595]\n",
      "Inference for Stan model: anon_model_4bac8359d39f32cfa57c3e3acae076d2.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "          mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "beta[0]   0.38  2.4e-3   0.15   0.09   0.28   0.38   0.48   0.67   3836    1.0\n",
      "beta[1]   1.06  2.1e-3   0.13   0.82   0.97   1.06   1.15   1.33   4000    1.0\n",
      "beta[2]  -0.08  1.9e-3   0.12  -0.31  -0.16  -0.08 2.9e-3   0.16   4000    1.0\n",
      "beta[3]   0.04  2.4e-3   0.14  -0.24  -0.06   0.04   0.14   0.31   3623    1.0\n",
      "beta[4]   0.47  2.5e-3   0.15   0.18   0.37   0.47   0.57   0.76   3541    1.0\n",
      "beta[5]   0.45  1.9e-3   0.12   0.22   0.37   0.45   0.52   0.68   4000    1.0\n",
      "beta[6]   0.23  2.5e-3   0.15  -0.07   0.13   0.23   0.33   0.54   3875    1.0\n",
      "lp__    -275.6    0.04   1.87 -280.1 -276.6 -275.3 -274.3 -272.9   1753    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed May 23 03:52:33 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "%run -i \"new_testleapfrog_logit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "p \n",
      "-6.2433\n",
      " 5.4033\n",
      " 0.7358\n",
      "-2.4458\n",
      "-5.2331\n",
      " 2.3176\n",
      "-6.1049\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.32710756693069204\n",
      "accepted False\n",
      "q \n",
      " 0.4705\n",
      " 1.6563\n",
      " 0.5153\n",
      "-0.2744\n",
      "-2.2606\n",
      " 1.2280\n",
      " 0.7928\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 1\n",
      "p \n",
      "  2.5378\n",
      "-20.1651\n",
      " -3.4494\n",
      " -5.2754\n",
      "-11.6100\n",
      " -6.1469\n",
      " -0.6690\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.14568604343179317\n",
      "accepted False\n",
      "q \n",
      " 0.4705\n",
      " 1.6563\n",
      " 0.5153\n",
      "-0.2744\n",
      "-2.2606\n",
      " 1.2280\n",
      " 0.7928\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 2\n",
      "p \n",
      "  3.2593\n",
      "  6.4909\n",
      " 10.4310\n",
      " 14.4437\n",
      "  9.0778\n",
      " -3.0310\n",
      "  5.1490\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.2808172655521268\n",
      "accepted False\n",
      "q \n",
      " 0.4705\n",
      " 1.6563\n",
      " 0.5153\n",
      "-0.2744\n",
      "-2.2606\n",
      " 1.2280\n",
      " 0.7928\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 3\n",
      "p \n",
      "-0.4526\n",
      " 4.1486\n",
      " 5.3283\n",
      " 8.1426\n",
      "-2.1113\n",
      " 8.6010\n",
      "-3.5671\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.373938907551137\n",
      "accepted True\n",
      "q \n",
      " 0.3240\n",
      " 1.0303\n",
      " 0.2183\n",
      " 0.1355\n",
      "-0.5076\n",
      " 0.5998\n",
      " 0.1415\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 4\n",
      "p \n",
      "-6.0653\n",
      " 1.6810\n",
      " 9.8375\n",
      "-2.5430\n",
      " 9.4190\n",
      " 7.0811\n",
      "-3.1884\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2888\n",
      " 0.9996\n",
      " 0.1626\n",
      "-0.0467\n",
      " 0.0829\n",
      " 0.5782\n",
      " 0.1501\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 5\n",
      "p \n",
      "-15.0981\n",
      " -0.2706\n",
      "-21.2675\n",
      " -1.5460\n",
      " -6.3333\n",
      " -9.4662\n",
      " -9.4213\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1496\n",
      " 1.0275\n",
      "-0.1489\n",
      " 0.0552\n",
      " 0.2049\n",
      " 0.3829\n",
      " 0.2702\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 6\n",
      "p \n",
      " -8.3049\n",
      " 29.6921\n",
      " 11.0158\n",
      "  5.0994\n",
      " -7.8477\n",
      "-15.1389\n",
      "  6.5193\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0436\n",
      " 1.4112\n",
      "-0.0620\n",
      " 0.2076\n",
      " 0.0790\n",
      " 0.2477\n",
      " 0.3838\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 7\n",
      "p \n",
      " -7.2128\n",
      "-14.1020\n",
      " -5.2322\n",
      " -3.3118\n",
      " -1.2758\n",
      " -6.9955\n",
      "-11.5354\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1919\n",
      " 1.0178\n",
      "-0.0601\n",
      " 0.1015\n",
      " 0.2799\n",
      " 0.2561\n",
      " 0.2075\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 8\n",
      "p \n",
      " 6.2947\n",
      " 5.2066\n",
      " 2.8622\n",
      "-9.7464\n",
      " 0.5296\n",
      "-5.0088\n",
      " 2.1021\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9875733974597426\n",
      "accepted True\n",
      "q \n",
      " 0.3631\n",
      " 1.1063\n",
      "-0.0529\n",
      "-0.1055\n",
      " 0.4786\n",
      " 0.2880\n",
      " 0.1830\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 9\n",
      "p \n",
      "-10.3362\n",
      " -2.8667\n",
      " -7.1226\n",
      "  8.4696\n",
      " 15.9774\n",
      "  2.5489\n",
      "-11.9718\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9992490251800946\n",
      "accepted True\n",
      "q \n",
      " 0.3383\n",
      " 1.0577\n",
      "-0.1414\n",
      "-0.0495\n",
      " 0.6681\n",
      " 0.3848\n",
      " 0.1380\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 10\n",
      "p \n",
      "  6.2820\n",
      " -1.9876\n",
      " -5.5448\n",
      "  6.2229\n",
      " -0.7018\n",
      " -6.4339\n",
      " 13.0415\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3000\n",
      " 1.0117\n",
      "-0.2304\n",
      " 0.0921\n",
      " 0.5347\n",
      " 0.3246\n",
      " 0.3821\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 11\n",
      "p \n",
      " -0.8618\n",
      " -7.9643\n",
      " -3.4840\n",
      "  0.4643\n",
      "  1.3381\n",
      "-13.8132\n",
      " -7.9152\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9934283418213062\n",
      "accepted True\n",
      "q \n",
      " 0.3845\n",
      " 0.9346\n",
      "-0.1627\n",
      " 0.0700\n",
      " 0.5265\n",
      " 0.2235\n",
      " 0.2138\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 12\n",
      "p \n",
      "  2.3069\n",
      " -9.5379\n",
      " -6.1352\n",
      " -6.2729\n",
      " -9.5163\n",
      " 14.4270\n",
      " -4.8890\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9905146093421192\n",
      "accepted True\n",
      "q \n",
      " 0.4565\n",
      " 0.8939\n",
      "-0.1245\n",
      " 0.0595\n",
      " 0.4140\n",
      " 0.4838\n",
      " 0.1327\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 13\n",
      "p \n",
      "  5.4939\n",
      "  2.6516\n",
      "  0.5694\n",
      "-11.0678\n",
      "-12.8039\n",
      "  1.9530\n",
      "  0.0175\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9952211491262833\n",
      "accepted True\n",
      "q \n",
      " 0.5109\n",
      " 1.0200\n",
      "-0.0618\n",
      "-0.0035\n",
      " 0.3387\n",
      " 0.4979\n",
      " 0.1035\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 14\n",
      "p \n",
      "-12.3231\n",
      "  2.9005\n",
      " -6.8064\n",
      " 25.6468\n",
      " 17.2115\n",
      " -9.2427\n",
      "-16.0379\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4063\n",
      " 1.0741\n",
      "-0.1502\n",
      " 0.2893\n",
      " 0.4092\n",
      " 0.3676\n",
      " 0.0321\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 15\n",
      "p \n",
      "-16.7214\n",
      " -0.9453\n",
      "  1.7943\n",
      " 10.1198\n",
      "  6.3133\n",
      "  7.9047\n",
      " -3.9617\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1578\n",
      " 1.0341\n",
      "-0.1019\n",
      " 0.3043\n",
      " 0.4048\n",
      " 0.4854\n",
      " 0.2176\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 16\n",
      "p \n",
      " 0.9471\n",
      " 5.1610\n",
      " 7.2335\n",
      "-1.6968\n",
      " 3.1720\n",
      " 0.8099\n",
      " 0.3212\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2868\n",
      " 1.1042\n",
      "-0.0226\n",
      " 0.1105\n",
      " 0.4982\n",
      " 0.4840\n",
      " 0.1806\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 17\n",
      "p \n",
      "  9.1640\n",
      "  5.1879\n",
      "  8.9387\n",
      "  7.2195\n",
      " 12.3939\n",
      "-19.1058\n",
      "  1.2843\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4817\n",
      " 1.1434\n",
      " 0.0025\n",
      " 0.0442\n",
      " 0.6402\n",
      " 0.2560\n",
      " 0.1050\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 18\n",
      "p \n",
      " -4.3985\n",
      "  7.2974\n",
      "  7.6247\n",
      "  4.8729\n",
      " 14.0055\n",
      " -3.5576\n",
      "-13.7996\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5504\n",
      " 1.2321\n",
      " 0.0624\n",
      "-0.0287\n",
      " 0.7544\n",
      " 0.3256\n",
      "-0.0818\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 19\n",
      "p \n",
      " 12.0507\n",
      " -3.9327\n",
      " -1.4632\n",
      "-10.5011\n",
      " -7.2775\n",
      "  6.4797\n",
      " -3.9325\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.7272\n",
      " 1.1326\n",
      " 0.0242\n",
      "-0.1014\n",
      " 0.6149\n",
      " 0.4766\n",
      "-0.1314\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 20\n",
      "p \n",
      " 4.4840\n",
      "-6.8003\n",
      " 7.0748\n",
      " 1.4699\n",
      "-6.8705\n",
      " 9.0004\n",
      "-3.6162\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6662\n",
      " 1.0147\n",
      " 0.1091\n",
      " 0.0676\n",
      " 0.3842\n",
      " 0.5772\n",
      "-0.1091\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 21\n",
      "p \n",
      " -0.4507\n",
      " 15.2755\n",
      " -8.6751\n",
      " -1.0200\n",
      " -6.1480\n",
      "-11.1605\n",
      "-13.0585\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6782\n",
      " 1.2827\n",
      "-0.0334\n",
      " 0.1103\n",
      " 0.3292\n",
      " 0.4062\n",
      "-0.1862\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 22\n",
      "p \n",
      "  5.0260\n",
      "-15.5558\n",
      " -9.0333\n",
      " -6.5424\n",
      "-11.7606\n",
      "  8.5970\n",
      " -2.9924\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6111\n",
      " 0.9845\n",
      "-0.0828\n",
      " 0.0993\n",
      " 0.2867\n",
      " 0.5164\n",
      "-0.0384\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 23\n",
      "p \n",
      " -0.1071\n",
      "  3.7231\n",
      " 21.1518\n",
      " -5.6099\n",
      "  3.2580\n",
      " 13.7181\n",
      " -8.7182\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6459\n",
      " 1.0780\n",
      " 0.1862\n",
      "-0.0510\n",
      " 0.4149\n",
      " 0.6757\n",
      "-0.1731\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 24\n",
      "p \n",
      "  5.2539\n",
      "  5.3015\n",
      "  5.8892\n",
      "  8.3161\n",
      "  5.8033\n",
      " -4.5086\n",
      " 11.4139\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5028\n",
      " 1.0963\n",
      " 0.0635\n",
      " 0.0415\n",
      " 0.4666\n",
      " 0.5131\n",
      " 0.1200\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 25\n",
      "p \n",
      " 0.7514\n",
      "-1.8298\n",
      " 8.4200\n",
      " 2.8612\n",
      "-0.1227\n",
      "-3.3093\n",
      " 0.8784\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4387\n",
      " 1.0363\n",
      " 0.0935\n",
      " 0.0913\n",
      " 0.4116\n",
      " 0.4443\n",
      " 0.1513\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 26\n",
      "p \n",
      "  8.5297\n",
      " -3.3215\n",
      "  0.1786\n",
      " -7.6492\n",
      " -4.2038\n",
      "-15.6195\n",
      "  0.2342\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9937571464850357\n",
      "accepted True\n",
      "q \n",
      " 0.5331\n",
      " 1.0093\n",
      " 0.0231\n",
      "-0.0270\n",
      " 0.4635\n",
      " 0.2680\n",
      " 0.1258\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 27\n",
      "p \n",
      " -6.7892\n",
      "  7.6432\n",
      " -7.1724\n",
      " 10.0727\n",
      "  0.6342\n",
      "  2.4507\n",
      "  2.1458\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3236\n",
      " 1.1197\n",
      "-0.1271\n",
      " 0.1689\n",
      " 0.3745\n",
      " 0.3607\n",
      " 0.2904\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 28\n",
      "p \n",
      "-10.0407\n",
      " 10.0792\n",
      " -2.9562\n",
      "  4.0595\n",
      " -8.5159\n",
      "  1.2755\n",
      "  1.6498\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1466\n",
      " 1.2314\n",
      "-0.1467\n",
      " 0.2895\n",
      " 0.2054\n",
      " 0.4097\n",
      " 0.3997\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 29\n",
      "p \n",
      "  3.7245\n",
      " -0.7551\n",
      "-12.3111\n",
      " -1.1556\n",
      " -6.0227\n",
      " -8.2139\n",
      "  0.5238\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2890\n",
      " 1.1578\n",
      "-0.2454\n",
      " 0.2156\n",
      " 0.2769\n",
      " 0.3244\n",
      " 0.3454\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 30\n",
      "p \n",
      "-3.2386\n",
      "-8.5257\n",
      " 5.1220\n",
      " 1.3871\n",
      "-2.0568\n",
      "-7.4881\n",
      "-3.0373\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2843\n",
      " 0.9707\n",
      "-0.0777\n",
      " 0.1842\n",
      " 0.2933\n",
      " 0.2897\n",
      " 0.2665\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 31\n",
      "p \n",
      " -0.3594\n",
      "  6.0736\n",
      " 13.2915\n",
      "  3.1849\n",
      " 10.0316\n",
      "  9.7689\n",
      " -7.1136\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4348\n",
      " 1.0851\n",
      " 0.0692\n",
      " 0.0651\n",
      " 0.4707\n",
      " 0.4848\n",
      " 0.0534\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 32\n",
      "p \n",
      " -8.1515\n",
      " -3.6751\n",
      " -4.5277\n",
      "  1.8516\n",
      "  6.4833\n",
      " 11.5958\n",
      " -2.0695\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3053\n",
      " 1.0266\n",
      "-0.0545\n",
      " 0.0243\n",
      " 0.5747\n",
      " 0.5966\n",
      " 0.2057\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 33\n",
      "p \n",
      "  2.5882\n",
      "  0.5118\n",
      " 21.1776\n",
      "  6.8055\n",
      "  7.8820\n",
      " 12.0268\n",
      "  4.1108\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3699\n",
      " 1.0287\n",
      " 0.1540\n",
      " 0.0483\n",
      " 0.5658\n",
      " 0.6978\n",
      " 0.1662\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 34\n",
      "p \n",
      "  6.6719\n",
      " -1.5167\n",
      " 10.2711\n",
      " 18.5502\n",
      "  4.2147\n",
      "  6.8413\n",
      "  5.4165\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4278\n",
      " 1.0088\n",
      " 0.1424\n",
      " 0.3227\n",
      " 0.3764\n",
      " 0.6823\n",
      " 0.1697\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 35\n",
      "p \n",
      " 1.9033\n",
      " 2.5375\n",
      "-4.5823\n",
      "-0.4631\n",
      " 5.5431\n",
      " 1.9840\n",
      "-7.6568\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5458\n",
      " 1.0916\n",
      "-0.0052\n",
      " 0.1100\n",
      " 0.5515\n",
      " 0.6031\n",
      " 0.0449\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 36\n",
      "p \n",
      " -9.5315\n",
      " -1.1602\n",
      "  4.7380\n",
      " 12.9559\n",
      "  6.9042\n",
      " -1.6121\n",
      " -5.9626\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3554\n",
      " 1.0392\n",
      " 0.0172\n",
      " 0.2452\n",
      " 0.4570\n",
      " 0.5058\n",
      " 0.1108\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 37\n",
      "p \n",
      "-14.1902\n",
      " -3.0030\n",
      " -0.1717\n",
      " -4.2528\n",
      "  0.6995\n",
      " -8.7311\n",
      " -0.5228\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1178\n",
      " 0.9746\n",
      "-0.0363\n",
      " 0.0807\n",
      " 0.4978\n",
      " 0.3520\n",
      " 0.3334\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 38\n",
      "p \n",
      "-11.9825\n",
      "  4.7779\n",
      "-10.1247\n",
      " -2.7422\n",
      " -7.7741\n",
      " -6.3604\n",
      " -7.4473\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9942505575437953\n",
      "accepted True\n",
      "q \n",
      " 0.1022\n",
      " 1.0889\n",
      "-0.1353\n",
      " 0.1199\n",
      " 0.3726\n",
      " 0.3147\n",
      " 0.3156\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 39\n",
      "p \n",
      "-11.6276\n",
      "  0.4455\n",
      "  2.7541\n",
      "  8.1549\n",
      " 11.2317\n",
      " -5.8265\n",
      "-12.0505\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9966669914827339\n",
      "accepted True\n",
      "q \n",
      " 0.1689\n",
      " 1.0758\n",
      "-0.0697\n",
      " 0.1186\n",
      " 0.4948\n",
      " 0.3102\n",
      " 0.1795\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 40\n",
      "p \n",
      "  3.3028\n",
      "  2.1480\n",
      " -8.4689\n",
      " -7.0992\n",
      "-12.4734\n",
      " -4.5525\n",
      " -0.3028\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3022\n",
      " 1.1124\n",
      "-0.1399\n",
      " 0.0968\n",
      " 0.3590\n",
      " 0.3185\n",
      " 0.1906\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 41\n",
      "p \n",
      "  8.4297\n",
      "  7.8605\n",
      " -2.3142\n",
      "  6.3760\n",
      " -7.0925\n",
      " 14.9709\n",
      " -0.6953\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4971\n",
      " 1.2332\n",
      "-0.1232\n",
      " 0.2513\n",
      " 0.2278\n",
      " 0.5654\n",
      " 0.0686\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 42\n",
      "p \n",
      " -0.2471\n",
      " -0.1414\n",
      "  2.5429\n",
      "-12.8361\n",
      " -6.7458\n",
      "  1.1182\n",
      " -6.0552\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5090\n",
      " 1.1595\n",
      "-0.0216\n",
      " 0.0005\n",
      " 0.3488\n",
      " 0.5268\n",
      " 0.0220\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 43\n",
      "p \n",
      "  9.0625\n",
      " -0.5060\n",
      "-11.3144\n",
      "-12.5552\n",
      "-11.1384\n",
      "-10.2875\n",
      "  4.9454\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9985395615897346\n",
      "accepted True\n",
      "q \n",
      " 0.5284\n",
      " 1.1291\n",
      "-0.1675\n",
      "-0.0862\n",
      " 0.3958\n",
      " 0.3653\n",
      " 0.1686\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 44\n",
      "p \n",
      " -3.2295\n",
      "  9.3265\n",
      "  7.5278\n",
      " -3.0972\n",
      "  4.8133\n",
      " 10.3808\n",
      " -1.3714\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4654\n",
      " 1.2272\n",
      "-0.0635\n",
      "-0.1428\n",
      " 0.5238\n",
      " 0.5327\n",
      " 0.1537\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 45\n",
      "p \n",
      " 17.3129\n",
      "  3.1687\n",
      " 15.7290\n",
      " -1.6592\n",
      " -3.7236\n",
      " -7.6575\n",
      " 24.5416\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4525\n",
      " 1.1490\n",
      " 0.0209\n",
      "-0.0945\n",
      " 0.4622\n",
      " 0.4021\n",
      " 0.4050\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 46\n",
      "p \n",
      "-18.3208\n",
      "  4.8913\n",
      "  5.2820\n",
      " -9.2639\n",
      " -3.7660\n",
      "  0.5208\n",
      "-11.0282\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2239\n",
      " 1.1608\n",
      " 0.0830\n",
      "-0.1265\n",
      " 0.4397\n",
      " 0.4241\n",
      " 0.2849\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 47\n",
      "p \n",
      " 0.6414\n",
      "-1.0917\n",
      "-3.8378\n",
      "-2.5903\n",
      " 0.7002\n",
      " 3.8302\n",
      "-2.1496\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3342\n",
      " 1.1102\n",
      "-0.0257\n",
      "-0.1007\n",
      " 0.5070\n",
      " 0.4800\n",
      " 0.2277\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 48\n",
      "p \n",
      "-1.3242\n",
      "-1.5238\n",
      " 0.1875\n",
      "-5.1654\n",
      "-7.2070\n",
      "-5.5811\n",
      " 0.6066\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.999498135657761\n",
      "accepted True\n",
      "q \n",
      " 0.3068\n",
      " 1.0587\n",
      "-0.0316\n",
      "-0.0410\n",
      " 0.4102\n",
      " 0.3928\n",
      " 0.2629\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 49\n",
      "p \n",
      "  5.5537\n",
      "-11.2325\n",
      " -3.3076\n",
      " 14.0066\n",
      "  5.1823\n",
      "  2.8494\n",
      "  0.2213\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9947981702014214\n",
      "accepted True\n",
      "q \n",
      " 0.4084\n",
      " 0.9087\n",
      "-0.0893\n",
      " 0.1796\n",
      " 0.3985\n",
      " 0.4466\n",
      " 0.2178\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 50\n",
      "p \n",
      "-10.7769\n",
      "  2.6536\n",
      "  0.0393\n",
      "-10.5167\n",
      "  7.4079\n",
      "  3.5669\n",
      "  2.0448\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2207\n",
      " 0.9935\n",
      "-0.1183\n",
      "-0.1387\n",
      " 0.6707\n",
      " 0.4769\n",
      " 0.3871\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 51\n",
      "p \n",
      "  4.2903\n",
      " 11.6672\n",
      "-19.2341\n",
      " -3.8176\n",
      " -3.0396\n",
      " -2.0662\n",
      "  6.6355\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2936\n",
      " 1.2215\n",
      "-0.3699\n",
      "-0.1085\n",
      " 0.6445\n",
      " 0.4395\n",
      " 0.4704\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 52\n",
      "p \n",
      " 11.2039\n",
      " 11.1710\n",
      " 25.6045\n",
      " 13.3287\n",
      " 11.1306\n",
      " 15.0393\n",
      " 21.4489\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3351\n",
      " 1.2638\n",
      "-0.0770\n",
      " 0.0203\n",
      " 0.6120\n",
      " 0.6510\n",
      " 0.5284\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 53\n",
      "p \n",
      " -1.7746\n",
      "  7.3623\n",
      " 12.8404\n",
      " -2.9194\n",
      "  0.6561\n",
      " -0.2088\n",
      " -2.2982\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3795\n",
      " 1.2558\n",
      " 0.0875\n",
      "-0.0432\n",
      " 0.5534\n",
      " 0.5601\n",
      " 0.2726\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 54\n",
      "p \n",
      " -7.3651\n",
      " 11.4279\n",
      " 21.2222\n",
      " 11.4484\n",
      " 12.8554\n",
      " -4.2114\n",
      "  8.2139\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1760\n",
      " 1.2827\n",
      " 0.1810\n",
      " 0.0419\n",
      " 0.5817\n",
      " 0.4648\n",
      " 0.4078\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 55\n",
      "p \n",
      "-2.4981\n",
      " 0.0778\n",
      " 5.6918\n",
      "-5.0858\n",
      "-0.1023\n",
      "-5.3111\n",
      "-5.8623\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3059\n",
      " 1.1610\n",
      " 0.1446\n",
      "-0.0505\n",
      " 0.5562\n",
      " 0.3919\n",
      " 0.2064\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 56\n",
      "p \n",
      "  6.0498\n",
      "  2.5125\n",
      "  0.3403\n",
      " -8.7210\n",
      "-14.6159\n",
      " 13.0261\n",
      "  7.9564\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3578\n",
      " 1.1558\n",
      " 0.0575\n",
      "-0.0078\n",
      " 0.3481\n",
      " 0.5735\n",
      " 0.2754\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 57\n",
      "p \n",
      "  5.2404\n",
      " -6.2685\n",
      " -3.2890\n",
      "  3.1588\n",
      " -0.4347\n",
      " 10.4907\n",
      " -0.4816\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4631\n",
      " 1.0412\n",
      "-0.0263\n",
      " 0.0740\n",
      " 0.3839\n",
      " 0.6448\n",
      " 0.1967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 58\n",
      "p \n",
      " -1.5120\n",
      " -0.0485\n",
      "  5.6660\n",
      "-12.4725\n",
      " -2.7729\n",
      "  5.7228\n",
      "  3.1583\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3807\n",
      " 1.0450\n",
      " 0.0147\n",
      "-0.1336\n",
      " 0.5025\n",
      " 0.6216\n",
      " 0.2677\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 59\n",
      "p \n",
      " -5.4138\n",
      " 17.7282\n",
      "-10.0200\n",
      " 12.7324\n",
      " 10.4699\n",
      "  8.1173\n",
      " -7.6518\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4163\n",
      " 1.3375\n",
      "-0.1725\n",
      " 0.0455\n",
      " 0.5653\n",
      " 0.6688\n",
      " 0.1627\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 60\n",
      "p \n",
      " -1.1448\n",
      "  5.2330\n",
      "-11.2382\n",
      "  8.4493\n",
      " -1.7114\n",
      "  0.9265\n",
      "  7.2555\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2792\n",
      " 1.2905\n",
      "-0.3149\n",
      " 0.2235\n",
      " 0.4226\n",
      " 0.5682\n",
      " 0.3924\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 61\n",
      "p \n",
      " 14.4418\n",
      "  3.1679\n",
      " 11.1898\n",
      " -2.3235\n",
      "  2.0496\n",
      " -0.0108\n",
      "  5.9869\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5430\n",
      " 1.2131\n",
      "-0.0916\n",
      " 0.0352\n",
      " 0.5174\n",
      " 0.5255\n",
      " 0.2036\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 62\n",
      "p \n",
      " -8.3992\n",
      "  1.7739\n",
      "  0.9540\n",
      " 20.3509\n",
      " 17.5949\n",
      " -6.5730\n",
      "  8.5979\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2082\n",
      " 1.1181\n",
      "-0.1822\n",
      " 0.2078\n",
      " 0.5917\n",
      " 0.3903\n",
      " 0.4996\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 63\n",
      "p \n",
      "  3.7689\n",
      "  8.4146\n",
      " 18.2219\n",
      "  1.9594\n",
      " 18.3276\n",
      "  4.9573\n",
      "  3.4641\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3846\n",
      " 1.1984\n",
      " 0.0157\n",
      "-0.0805\n",
      " 0.8688\n",
      " 0.5047\n",
      " 0.3085\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 64\n",
      "p \n",
      "  4.9762\n",
      "-13.5369\n",
      "-28.0594\n",
      " -4.1358\n",
      " -5.9670\n",
      "  8.9203\n",
      "-12.0741\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5813\n",
      " 0.9959\n",
      "-0.2896\n",
      " 0.0011\n",
      " 0.6529\n",
      " 0.5718\n",
      " 0.1119\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 65\n",
      "p \n",
      " 10.7427\n",
      "  5.8484\n",
      " 14.3443\n",
      "  0.7196\n",
      "  9.1723\n",
      "  1.2728\n",
      "  2.8880\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6928\n",
      " 1.1015\n",
      "-0.0732\n",
      "-0.0986\n",
      " 0.7330\n",
      " 0.5586\n",
      " 0.0331\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 66\n",
      "p \n",
      "-18.0358\n",
      " -1.5090\n",
      " -4.6175\n",
      "  9.1921\n",
      " 12.1633\n",
      " 12.7313\n",
      "  0.7226\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2277\n",
      " 1.0324\n",
      "-0.1696\n",
      " 0.0068\n",
      " 0.7270\n",
      " 0.6409\n",
      " 0.3595\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 67\n",
      "p \n",
      " -2.9868\n",
      " 11.6422\n",
      " -2.4438\n",
      " -8.9740\n",
      " -6.9666\n",
      " -8.3760\n",
      "  1.8873\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2230\n",
      " 1.2022\n",
      "-0.1683\n",
      "-0.0628\n",
      " 0.5716\n",
      " 0.4410\n",
      " 0.3684\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 68\n",
      "p \n",
      "-7.1295\n",
      " 9.7582\n",
      " 9.2034\n",
      " 5.2287\n",
      " 2.9238\n",
      "-7.8565\n",
      " 0.7218\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1668\n",
      " 1.2467\n",
      "-0.0538\n",
      " 0.0424\n",
      " 0.4855\n",
      " 0.3507\n",
      " 0.3555\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 69\n",
      "p \n",
      " 3.5511\n",
      "-3.2298\n",
      " 1.0175\n",
      "-8.8946\n",
      "-1.2605\n",
      "-7.6425\n",
      " 3.2904\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2850\n",
      " 1.1022\n",
      "-0.0593\n",
      "-0.1111\n",
      " 0.5651\n",
      " 0.3010\n",
      " 0.3364\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 70\n",
      "p \n",
      "-19.6721\n",
      " -6.9079\n",
      "-24.0261\n",
      "-22.9383\n",
      "-22.0777\n",
      " 20.7943\n",
      "-14.9039\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9820125761350186\n",
      "accepted True\n",
      "q \n",
      " 0.1474\n",
      " 1.0474\n",
      "-0.2053\n",
      "-0.1435\n",
      " 0.3843\n",
      " 0.5912\n",
      " 0.3091\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 71\n",
      "p \n",
      " 11.6454\n",
      " 12.1109\n",
      " 16.6223\n",
      " 19.9886\n",
      "  2.4704\n",
      "  0.2916\n",
      " 24.2318\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1707\n",
      " 1.1431\n",
      "-0.0909\n",
      " 0.2048\n",
      " 0.2393\n",
      " 0.5333\n",
      " 0.5097\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 72\n",
      "p \n",
      " 0.5981\n",
      " 1.9019\n",
      "-7.6818\n",
      "-9.7528\n",
      " 1.0804\n",
      " 6.7674\n",
      " 0.5670\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2941\n",
      " 1.1529\n",
      "-0.1824\n",
      "-0.0659\n",
      " 0.5089\n",
      " 0.5747\n",
      " 0.4112\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 73\n",
      "p \n",
      " -4.1732\n",
      " 20.9219\n",
      " -6.7711\n",
      "  3.7908\n",
      "  7.7495\n",
      "-12.2343\n",
      " -2.8717\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3177\n",
      " 1.4366\n",
      "-0.2791\n",
      "-0.0484\n",
      " 0.6150\n",
      " 0.3837\n",
      " 0.3363\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 74\n",
      "p \n",
      "-9.5944\n",
      " 1.4147\n",
      " 3.2574\n",
      " 4.1620\n",
      " 4.8282\n",
      "-7.9460\n",
      " 6.3231\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0855\n",
      " 1.2252\n",
      "-0.1959\n",
      " 0.0176\n",
      " 0.5685\n",
      " 0.2944\n",
      " 0.5331\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 75\n",
      "p \n",
      " -4.3052\n",
      "-13.5818\n",
      "-12.7641\n",
      "-10.6243\n",
      "-12.6598\n",
      "  6.5330\n",
      " -5.5448\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1936\n",
      " 0.9655\n",
      "-0.1985\n",
      " 0.0054\n",
      " 0.4209\n",
      " 0.4310\n",
      " 0.3788\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 76\n",
      "p \n",
      " -2.0813\n",
      "  4.2056\n",
      "-18.0263\n",
      "  7.0926\n",
      "  2.9529\n",
      "  4.6543\n",
      "-13.7712\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3921\n",
      " 1.1174\n",
      "-0.3123\n",
      " 0.1239\n",
      " 0.4540\n",
      " 0.5019\n",
      " 0.1380\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 77\n",
      "p \n",
      " -5.9935\n",
      " 12.6500\n",
      "  2.2853\n",
      " -9.7476\n",
      " -7.6492\n",
      "-10.6041\n",
      "  1.8780\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2674\n",
      " 1.2470\n",
      "-0.1904\n",
      "-0.0020\n",
      " 0.4122\n",
      " 0.3496\n",
      " 0.2567\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 78\n",
      "p \n",
      " 11.0641\n",
      "  0.1926\n",
      " -3.4864\n",
      "  3.1035\n",
      " -3.0449\n",
      " -2.6062\n",
      " -4.7644\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5531\n",
      " 1.1905\n",
      "-0.1489\n",
      " 0.0983\n",
      " 0.3726\n",
      " 0.3788\n",
      " 0.0388\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 79\n",
      "p \n",
      " 11.9165\n",
      " -2.7219\n",
      "  0.3356\n",
      " -3.6243\n",
      " -8.5052\n",
      " 12.9093\n",
      " -4.7506\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.7399\n",
      " 1.1435\n",
      "-0.0546\n",
      " 0.0940\n",
      " 0.3218\n",
      " 0.5840\n",
      "-0.1102\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 80\n",
      "p \n",
      "  1.5209\n",
      "  2.2017\n",
      " 12.7453\n",
      "  7.3135\n",
      "  8.8092\n",
      " -5.3115\n",
      " 17.6381\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4085\n",
      " 1.0562\n",
      "-0.0199\n",
      " 0.0789\n",
      " 0.4527\n",
      " 0.4415\n",
      " 0.3091\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 81\n",
      "p \n",
      "-3.7215\n",
      "-5.8319\n",
      " 1.3020\n",
      "-2.5347\n",
      " 4.8046\n",
      " 3.5008\n",
      "-5.3554\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3959\n",
      " 0.9798\n",
      "-0.0136\n",
      "-0.0315\n",
      " 0.5712\n",
      " 0.4846\n",
      " 0.2195\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 82\n",
      "p \n",
      "-15.6162\n",
      " -4.2231\n",
      "-14.6119\n",
      " -2.7071\n",
      " -6.4446\n",
      " -6.8470\n",
      "-21.1566\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9881802358143368\n",
      "accepted True\n",
      "q \n",
      " 0.3184\n",
      " 0.9912\n",
      "-0.1112\n",
      " 0.0687\n",
      " 0.4181\n",
      " 0.3766\n",
      " 0.0785\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 83\n",
      "p \n",
      " 18.2012\n",
      " -3.3547\n",
      " 10.4016\n",
      " -1.0247\n",
      " 11.0196\n",
      "  3.1932\n",
      " 10.2521\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5593\n",
      " 0.9690\n",
      "-0.0399\n",
      "-0.1087\n",
      " 0.6683\n",
      " 0.4545\n",
      " 0.1101\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 84\n",
      "p \n",
      " 2.0753\n",
      "-3.8015\n",
      " 6.6365\n",
      " 3.4085\n",
      "-0.1715\n",
      " 5.9639\n",
      "-4.7770\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9984416004324708\n",
      "accepted True\n",
      "q \n",
      " 0.5624\n",
      " 0.9666\n",
      " 0.0466\n",
      " 0.0211\n",
      " 0.5197\n",
      " 0.5300\n",
      " 0.0281\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 85\n",
      "p \n",
      " -9.6311\n",
      "  0.1475\n",
      "-11.6351\n",
      " 13.1537\n",
      "  5.0511\n",
      "  5.8963\n",
      "-16.3955\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4866\n",
      " 1.0439\n",
      "-0.0963\n",
      " 0.2241\n",
      " 0.4449\n",
      " 0.5641\n",
      "-0.0364\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 86\n",
      "p \n",
      "-12.8580\n",
      " -3.6986\n",
      " -0.4872\n",
      "  5.8186\n",
      "  7.0058\n",
      "-13.7327\n",
      "-18.1313\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9950541185790013\n",
      "accepted True\n",
      "q \n",
      " 0.3934\n",
      " 1.0041\n",
      "-0.0466\n",
      " 0.1855\n",
      " 0.4829\n",
      " 0.3464\n",
      "-0.0698\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 87\n",
      "p \n",
      "-23.1086\n",
      "-11.2399\n",
      "  7.0606\n",
      " 10.8595\n",
      " 13.7824\n",
      "  6.9900\n",
      "-19.0099\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9839814737747197\n",
      "accepted True\n",
      "q \n",
      " 0.2074\n",
      " 0.8814\n",
      " 0.0658\n",
      " 0.1914\n",
      " 0.5419\n",
      " 0.4687\n",
      "-0.0268\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 88\n",
      "p \n",
      "  4.6800\n",
      " 11.9790\n",
      " -1.5005\n",
      " 15.1978\n",
      " 12.0368\n",
      " -1.0072\n",
      " -6.7903\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4479\n",
      " 1.1324\n",
      "-0.0354\n",
      " 0.2473\n",
      " 0.5762\n",
      " 0.4702\n",
      "-0.1067\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 89\n",
      "p \n",
      "-12.3465\n",
      "  1.3184\n",
      "  3.6993\n",
      "-11.1211\n",
      " -9.6665\n",
      " -2.6569\n",
      "-12.8640\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3328\n",
      " 1.1117\n",
      " 0.0632\n",
      " 0.0829\n",
      " 0.4144\n",
      " 0.4245\n",
      "-0.0643\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 90\n",
      "p \n",
      "-11.9099\n",
      "  5.5459\n",
      "-19.6478\n",
      "  3.3843\n",
      " -0.6537\n",
      "  1.5570\n",
      "-20.1062\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3686\n",
      " 1.2242\n",
      "-0.1594\n",
      " 0.1574\n",
      " 0.4060\n",
      " 0.4584\n",
      "-0.1048\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 91\n",
      "p \n",
      "-3.4885\n",
      "-3.3224\n",
      "-4.0383\n",
      "-3.7985\n",
      "-1.4825\n",
      " 4.8452\n",
      "-2.8999\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3438\n",
      " 1.1055\n",
      "-0.1440\n",
      " 0.0611\n",
      " 0.4539\n",
      " 0.5020\n",
      " 0.0536\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 92\n",
      "p \n",
      " -6.7159\n",
      "  2.8987\n",
      "-23.6255\n",
      "-13.2273\n",
      "-17.5988\n",
      " -0.4810\n",
      " -4.9876\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9867136517027942\n",
      "accepted True\n",
      "q \n",
      " 0.2820\n",
      " 1.1754\n",
      "-0.3211\n",
      " 0.0347\n",
      " 0.3394\n",
      " 0.4622\n",
      " 0.1967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 93\n",
      "p \n",
      " -7.0164\n",
      " 12.1499\n",
      " 22.7298\n",
      "  9.1069\n",
      "  3.6096\n",
      " -6.7977\n",
      "  0.2370\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2154\n",
      " 1.2248\n",
      " 0.0086\n",
      " 0.1497\n",
      " 0.2791\n",
      " 0.3809\n",
      " 0.1827\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 94\n",
      "p \n",
      " 12.0782\n",
      " -5.2446\n",
      "-14.9565\n",
      " -0.2065\n",
      "-10.5612\n",
      " -4.1773\n",
      " -1.0219\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4714\n",
      " 1.1091\n",
      "-0.1624\n",
      " 0.2048\n",
      " 0.2389\n",
      " 0.3637\n",
      " 0.1194\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 95\n",
      "p \n",
      " -8.1764\n",
      " 11.2568\n",
      "  3.1118\n",
      " 20.2026\n",
      " -0.2261\n",
      "  5.6300\n",
      " -9.7459\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4025\n",
      " 1.2556\n",
      "-0.0746\n",
      " 0.5050\n",
      " 0.0747\n",
      " 0.4822\n",
      " 0.0245\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 96\n",
      "p \n",
      " -4.0086\n",
      "  7.4333\n",
      "  9.7455\n",
      " -9.8985\n",
      " -9.3220\n",
      "  6.1331\n",
      " 24.0589\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0551\n",
      " 1.2031\n",
      "-0.0442\n",
      " 0.2058\n",
      " 0.1774\n",
      " 0.5166\n",
      " 0.5721\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 97\n",
      "p \n",
      " -0.7495\n",
      " -2.2304\n",
      " 15.1325\n",
      " -4.8691\n",
      " -0.4590\n",
      " -1.5537\n",
      "  4.5824\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1499\n",
      " 1.0629\n",
      " 0.1080\n",
      " 0.0368\n",
      " 0.3228\n",
      " 0.4598\n",
      " 0.4457\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 98\n",
      "p \n",
      " -3.0483\n",
      " -4.9799\n",
      "-11.8032\n",
      " -4.7799\n",
      " -0.3181\n",
      "-11.6165\n",
      " -1.2127\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1956\n",
      " 0.9934\n",
      "-0.1151\n",
      "-0.0367\n",
      " 0.4706\n",
      " 0.3008\n",
      " 0.4300\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 99\n",
      "p \n",
      " 12.9064\n",
      "  4.2819\n",
      " 12.3385\n",
      " -6.9326\n",
      " -0.4790\n",
      "  1.1558\n",
      "  6.4352\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4453\n",
      " 1.0753\n",
      " 0.0163\n",
      "-0.1431\n",
      " 0.5368\n",
      " 0.3934\n",
      " 0.2639\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 100\n",
      "p \n",
      "-7.1600\n",
      " 0.4630\n",
      "-2.1762\n",
      " 4.2531\n",
      " 0.0516\n",
      " 9.3781\n",
      "-8.8384\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3932\n",
      " 1.0827\n",
      "-0.0147\n",
      " 0.0300\n",
      " 0.4437\n",
      " 0.5290\n",
      " 0.1528\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 101\n",
      "p \n",
      "  1.1489\n",
      "-12.0302\n",
      "-13.3229\n",
      "-11.4468\n",
      " -6.5217\n",
      " 11.5376\n",
      "  8.8622\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9952998102936312\n",
      "accepted True\n",
      "q \n",
      " 0.2957\n",
      " 0.9242\n",
      "-0.1944\n",
      "-0.0902\n",
      " 0.5171\n",
      " 0.6047\n",
      " 0.4168\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 102\n",
      "p \n",
      " -6.1893\n",
      " -1.8560\n",
      " 14.7485\n",
      " -4.8998\n",
      "  2.4865\n",
      "  6.9652\n",
      "  5.9259\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1797\n",
      " 0.9263\n",
      "-0.0029\n",
      "-0.1447\n",
      " 0.5548\n",
      " 0.6091\n",
      " 0.4619\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 103\n",
      "p \n",
      "  1.9241\n",
      " -9.7941\n",
      "  1.9110\n",
      "-10.2402\n",
      "-13.5997\n",
      "  9.9820\n",
      "  2.1639\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2669\n",
      " 0.8683\n",
      " 0.0324\n",
      "-0.0785\n",
      " 0.3790\n",
      " 0.6451\n",
      " 0.3679\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 104\n",
      "p \n",
      "  4.3270\n",
      " 20.9605\n",
      " -1.8383\n",
      " 13.3372\n",
      " 11.5462\n",
      "  1.9583\n",
      "  9.9345\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3127\n",
      " 1.2150\n",
      "-0.1405\n",
      " 0.0443\n",
      " 0.5060\n",
      " 0.5989\n",
      " 0.4251\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 105\n",
      "p \n",
      " 5.4821\n",
      "-1.2831\n",
      " 7.2749\n",
      "-1.0692\n",
      "-5.1566\n",
      "-1.9630\n",
      "-6.5259\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5153\n",
      " 1.1194\n",
      " 0.0314\n",
      " 0.0781\n",
      " 0.3822\n",
      " 0.5110\n",
      " 0.0916\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 106\n",
      "p \n",
      " -4.1896\n",
      " -0.7808\n",
      "-13.9443\n",
      " -4.5413\n",
      " -4.8616\n",
      " -3.5775\n",
      "-13.2619\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5071\n",
      " 1.1194\n",
      "-0.1186\n",
      " 0.0521\n",
      " 0.4039\n",
      " 0.4374\n",
      " 0.0203\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 107\n",
      "p \n",
      " -9.6561\n",
      " -4.7569\n",
      " -0.1564\n",
      "  0.3904\n",
      " 11.1820\n",
      " -2.6092\n",
      "-12.7941\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9948772723313261\n",
      "accepted True\n",
      "q \n",
      " 0.4273\n",
      " 1.0334\n",
      "-0.0802\n",
      "-0.0474\n",
      " 0.6077\n",
      " 0.4112\n",
      " 0.0166\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 108\n",
      "p \n",
      " -0.8678\n",
      "  0.4816\n",
      "  3.5285\n",
      "  0.1526\n",
      "-14.3526\n",
      "  2.8733\n",
      "  5.2450\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9943054356251531\n",
      "accepted True\n",
      "q \n",
      " 0.3133\n",
      " 1.0286\n",
      "-0.0199\n",
      " 0.1473\n",
      " 0.2706\n",
      " 0.4518\n",
      " 0.1805\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 109\n",
      "p \n",
      " -4.5295\n",
      " -2.0564\n",
      "-14.0454\n",
      "  4.2098\n",
      " -2.9397\n",
      "-10.6108\n",
      " -8.3866\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9904612392786141\n",
      "accepted True\n",
      "q \n",
      " 0.3267\n",
      " 1.0366\n",
      "-0.1693\n",
      " 0.2148\n",
      " 0.2898\n",
      " 0.3229\n",
      " 0.1674\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 110\n",
      "p \n",
      "-23.8007\n",
      "  6.2561\n",
      "-16.3056\n",
      " -1.0513\n",
      "  0.8933\n",
      "  6.7903\n",
      "-26.6185\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2528\n",
      " 1.1854\n",
      "-0.2276\n",
      " 0.1546\n",
      " 0.3785\n",
      " 0.4585\n",
      " 0.0166\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 111\n",
      "p \n",
      "-16.8436\n",
      "  4.9801\n",
      "  1.0328\n",
      "  6.2534\n",
      "  3.7371\n",
      " -3.9551\n",
      "-10.3356\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1425\n",
      " 1.1877\n",
      "-0.1345\n",
      " 0.1916\n",
      " 0.3802\n",
      " 0.4055\n",
      " 0.0964\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 112\n",
      "p \n",
      " 11.2284\n",
      " -4.2595\n",
      " -2.6269\n",
      "-15.1842\n",
      "-16.0765\n",
      " -7.6188\n",
      "  3.6479\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3722\n",
      " 1.0679\n",
      "-0.0954\n",
      " 0.0214\n",
      " 0.3243\n",
      " 0.3334\n",
      " 0.1263\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 113\n",
      "p \n",
      " -6.1638\n",
      " -1.7346\n",
      " -3.8564\n",
      " -1.6922\n",
      "-10.4894\n",
      "-11.7672\n",
      " -9.4579\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9843346973279321\n",
      "accepted True\n",
      "q \n",
      " 0.3414\n",
      " 1.0537\n",
      "-0.0697\n",
      " 0.1291\n",
      " 0.2196\n",
      " 0.2565\n",
      " 0.0936\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 114\n",
      "p \n",
      " 11.2616\n",
      "-10.2892\n",
      " 10.0768\n",
      " -0.4316\n",
      "  5.5462\n",
      "  2.2466\n",
      " -1.5402\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9780358735858661\n",
      "accepted True\n",
      "q \n",
      " 0.5534\n",
      " 0.9225\n",
      " 0.0459\n",
      " 0.0170\n",
      " 0.4194\n",
      " 0.3748\n",
      "-0.0032\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 115\n",
      "p \n",
      "-6.9625\n",
      " 3.8736\n",
      " 6.0758\n",
      " 0.2248\n",
      "-1.1043\n",
      "-1.6365\n",
      " 7.4657\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9910001491962473\n",
      "accepted True\n",
      "q \n",
      " 0.2840\n",
      " 0.9906\n",
      " 0.0262\n",
      " 0.0390\n",
      " 0.3983\n",
      " 0.3755\n",
      " 0.2704\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 116\n",
      "p \n",
      " 14.9022\n",
      "-17.6605\n",
      "  6.7563\n",
      "  6.1958\n",
      "  4.9499\n",
      " -3.5171\n",
      " 12.3585\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.983103290892141\n",
      "accepted True\n",
      "q \n",
      " 0.4169\n",
      " 0.7726\n",
      " 0.0152\n",
      " 0.0722\n",
      " 0.4795\n",
      " 0.3650\n",
      " 0.3327\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 117\n",
      "p \n",
      "  1.0896\n",
      " -6.4221\n",
      " -5.6839\n",
      "-11.3234\n",
      " -3.7492\n",
      " -1.6119\n",
      "  9.5216\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9965447414699405\n",
      "accepted True\n",
      "q \n",
      " 0.3009\n",
      " 0.8129\n",
      "-0.1103\n",
      "-0.0982\n",
      " 0.5613\n",
      " 0.3679\n",
      " 0.5004\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 118\n",
      "p \n",
      "  5.1692\n",
      " -3.4642\n",
      "-12.3952\n",
      "-22.9359\n",
      "-10.0655\n",
      "  1.2970\n",
      "-12.4525\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9809774478317093\n",
      "accepted True\n",
      "q \n",
      " 0.5628\n",
      " 0.9443\n",
      "-0.1443\n",
      "-0.2947\n",
      " 0.6156\n",
      " 0.4305\n",
      " 0.1449\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 119\n",
      "p \n",
      " -6.5092\n",
      "  6.4766\n",
      "-11.9920\n",
      " -0.9929\n",
      " -5.1458\n",
      " -2.3153\n",
      " -8.8008\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9850720267756662\n",
      "accepted True\n",
      "q \n",
      " 0.4620\n",
      " 1.0995\n",
      "-0.2101\n",
      "-0.1065\n",
      " 0.4875\n",
      " 0.4089\n",
      " 0.1190\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 120\n",
      "p \n",
      "  4.9983\n",
      " 14.4324\n",
      " -4.5400\n",
      "  6.8232\n",
      " -9.0663\n",
      "  7.5346\n",
      "  1.1711\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5129\n",
      " 1.3098\n",
      "-0.2086\n",
      " 0.1547\n",
      " 0.2685\n",
      " 0.5299\n",
      " 0.0973\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 121\n",
      "p \n",
      " -6.1166\n",
      "  4.1757\n",
      " -3.1596\n",
      "  0.2522\n",
      " 10.5559\n",
      "  3.7099\n",
      "  7.3274\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2831\n",
      " 1.2368\n",
      "-0.2628\n",
      "-0.0156\n",
      " 0.5653\n",
      " 0.5252\n",
      " 0.3883\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 122\n",
      "p \n",
      " -3.4445\n",
      " -8.5809\n",
      "-16.9825\n",
      " -5.5040\n",
      "  3.2488\n",
      " -9.3745\n",
      "  3.7725\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2001\n",
      " 1.0376\n",
      "-0.3940\n",
      "-0.1161\n",
      " 0.6970\n",
      " 0.3486\n",
      " 0.5445\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 123\n",
      "p \n",
      " 17.9090\n",
      "  0.9421\n",
      " -0.7773\n",
      " -2.2765\n",
      " 14.5006\n",
      " -3.3272\n",
      " 12.6171\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4833\n",
      " 1.0766\n",
      "-0.3664\n",
      "-0.2918\n",
      " 0.9720\n",
      " 0.3659\n",
      " 0.4792\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 124\n",
      "p \n",
      "  4.3354\n",
      "  1.0423\n",
      "  3.5641\n",
      " -9.1042\n",
      " -7.6550\n",
      " 11.5068\n",
      "  1.4270\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5061\n",
      " 1.0882\n",
      "-0.1579\n",
      "-0.2158\n",
      " 0.6796\n",
      " 0.5495\n",
      " 0.3014\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 125\n",
      "p \n",
      " 7.0766\n",
      "-7.0466\n",
      "-9.3534\n",
      " 8.3121\n",
      "-6.0087\n",
      "-7.5528\n",
      "-3.1259\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5562\n",
      " 0.9867\n",
      "-0.1893\n",
      " 0.1245\n",
      " 0.4011\n",
      " 0.4025\n",
      " 0.1724\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 126\n",
      "p \n",
      " -5.2791\n",
      "  5.0127\n",
      "  9.8334\n",
      "  1.7057\n",
      " 12.3247\n",
      "  2.8631\n",
      "  5.2740\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3615\n",
      " 1.0479\n",
      "-0.0958\n",
      "-0.0243\n",
      " 0.6085\n",
      " 0.4526\n",
      " 0.3147\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 127\n",
      "p \n",
      "  5.3571\n",
      " 15.4706\n",
      "  8.4849\n",
      " -2.0145\n",
      "  0.2609\n",
      "  0.5464\n",
      " 18.0735\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2861\n",
      " 1.2512\n",
      "-0.0920\n",
      "-0.0705\n",
      " 0.5917\n",
      " 0.4632\n",
      " 0.5196\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 128\n",
      "p \n",
      "-0.5949\n",
      "-7.9878\n",
      " 8.3039\n",
      " 0.5558\n",
      " 5.4797\n",
      "-0.0348\n",
      " 4.2410\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2698\n",
      " 1.0062\n",
      "-0.0039\n",
      "-0.0731\n",
      " 0.6162\n",
      " 0.4455\n",
      " 0.4513\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 129\n",
      "p \n",
      "-7.6262\n",
      "-4.9730\n",
      "-1.7177\n",
      "-3.4310\n",
      " 5.8189\n",
      " 3.2976\n",
      "-7.7202\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2872\n",
      " 0.9703\n",
      "-0.0356\n",
      "-0.1304\n",
      " 0.6866\n",
      " 0.4826\n",
      " 0.3021\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 130\n",
      "p \n",
      " 21.9249\n",
      "-19.0048\n",
      " -3.8785\n",
      " -0.2757\n",
      "  2.9855\n",
      " -8.4632\n",
      " -4.0490\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9794628209884696\n",
      "accepted True\n",
      "q \n",
      " 0.7165\n",
      " 0.8009\n",
      "-0.0658\n",
      "-0.0897\n",
      " 0.6883\n",
      " 0.3814\n",
      " 0.0235\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 131\n",
      "p \n",
      " -6.8307\n",
      " 16.2923\n",
      " 17.6532\n",
      "  3.1675\n",
      "  0.1865\n",
      " -1.9176\n",
      "  0.8297\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4661\n",
      " 1.0744\n",
      " 0.1048\n",
      " 0.0051\n",
      " 0.4970\n",
      " 0.3935\n",
      " 0.0869\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 132\n",
      "p \n",
      "  8.2838\n",
      " 14.9561\n",
      " 11.3995\n",
      " -1.7903\n",
      " 15.6712\n",
      "  6.3697\n",
      " 10.2022\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5451\n",
      " 1.2856\n",
      " 0.0665\n",
      "-0.2330\n",
      " 0.8321\n",
      " 0.5207\n",
      " 0.1754\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 133\n",
      "p \n",
      "-10.3471\n",
      "  6.3748\n",
      "-13.3200\n",
      " -8.0311\n",
      " -7.9845\n",
      "  3.7097\n",
      " -0.4542\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2667\n",
      " 1.2711\n",
      "-0.1633\n",
      "-0.1390\n",
      " 0.5930\n",
      " 0.5079\n",
      " 0.3644\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 134\n",
      "p \n",
      "-11.5997\n",
      " -5.2505\n",
      " 10.3731\n",
      " -2.3270\n",
      " -1.2672\n",
      "-12.2511\n",
      "  0.7936\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0830\n",
      " 1.0329\n",
      " 0.0027\n",
      "-0.0632\n",
      " 0.4800\n",
      " 0.3074\n",
      " 0.4317\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 135\n",
      "p \n",
      "  0.0161\n",
      "-17.1020\n",
      " -1.3104\n",
      " -8.9227\n",
      " -4.8563\n",
      " 11.8461\n",
      "  7.2997\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9920317804943689\n",
      "accepted True\n",
      "q \n",
      " 0.1275\n",
      " 0.8135\n",
      "-0.0374\n",
      "-0.1085\n",
      " 0.4987\n",
      " 0.4886\n",
      " 0.5054\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 136\n",
      "p \n",
      "  8.9582\n",
      " -8.7218\n",
      " -3.6785\n",
      "  3.1250\n",
      " 14.4795\n",
      " -2.4244\n",
      "  6.3392\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3225\n",
      " 0.8080\n",
      "-0.1493\n",
      "-0.1590\n",
      " 0.7543\n",
      " 0.4416\n",
      " 0.4527\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 137\n",
      "p \n",
      "  6.5194\n",
      " 14.6626\n",
      "  0.8255\n",
      "-10.6566\n",
      "-20.0924\n",
      "  4.3928\n",
      " 20.6314\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2188\n",
      " 1.0958\n",
      "-0.1567\n",
      "-0.0681\n",
      " 0.3986\n",
      " 0.4859\n",
      " 0.6484\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 138\n",
      "p \n",
      " 4.0572\n",
      "-5.2028\n",
      "-3.3290\n",
      " 6.7530\n",
      "-0.5254\n",
      "-9.7815\n",
      " 7.8291\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2429\n",
      " 0.9872\n",
      "-0.1867\n",
      " 0.1051\n",
      " 0.3706\n",
      " 0.3382\n",
      " 0.5869\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 139\n",
      "p \n",
      "  2.3819\n",
      " 15.8828\n",
      "  8.2848\n",
      " 12.0090\n",
      "  4.2240\n",
      " 24.9989\n",
      " 11.3133\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2600\n",
      " 1.2343\n",
      "-0.1292\n",
      " 0.2318\n",
      " 0.3452\n",
      " 0.6990\n",
      " 0.5535\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 140\n",
      "p \n",
      " 2.9323\n",
      " 0.6113\n",
      "-1.2065\n",
      "-4.7641\n",
      "-3.3784\n",
      "-4.3355\n",
      "-1.9530\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3945\n",
      " 1.1502\n",
      "-0.0958\n",
      " 0.0770\n",
      " 0.4054\n",
      " 0.5127\n",
      " 0.3108\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 141\n",
      "p \n",
      " -4.4770\n",
      "  3.7493\n",
      "  4.8456\n",
      " 11.2194\n",
      "  9.7079\n",
      "-13.8147\n",
      " -8.1387\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3979\n",
      " 1.1431\n",
      "-0.0389\n",
      " 0.1558\n",
      " 0.4610\n",
      " 0.3209\n",
      " 0.1525\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 142\n",
      "p \n",
      "-11.4266\n",
      "  0.5854\n",
      "  7.7881\n",
      " 11.4674\n",
      "  4.1048\n",
      "  8.8145\n",
      " -6.6288\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2692\n",
      " 1.0985\n",
      " 0.0489\n",
      " 0.2757\n",
      " 0.3648\n",
      " 0.4854\n",
      " 0.1453\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 143\n",
      "p \n",
      " -4.9531\n",
      "-11.7034\n",
      "-10.9340\n",
      " -1.6617\n",
      "-12.7025\n",
      "  6.5148\n",
      " -6.8348\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2739\n",
      " 0.9411\n",
      "-0.0613\n",
      " 0.2923\n",
      " 0.2122\n",
      " 0.5281\n",
      " 0.1671\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 144\n",
      "p \n",
      " -5.4758\n",
      "  7.0704\n",
      "  3.1040\n",
      "  3.6834\n",
      " 11.5283\n",
      " 15.6433\n",
      "-13.6905\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4193\n",
      " 1.1142\n",
      "-0.0167\n",
      " 0.1336\n",
      " 0.4604\n",
      " 0.6980\n",
      "-0.0295\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 145\n",
      "p \n",
      " -4.7294\n",
      " -0.8953\n",
      "-10.5691\n",
      "-24.7702\n",
      "-12.2449\n",
      "  2.5205\n",
      "  9.2793\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2185\n",
      " 1.0694\n",
      "-0.1704\n",
      "-0.2062\n",
      " 0.5449\n",
      " 0.5797\n",
      " 0.3634\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 146\n",
      "p \n",
      " 2.3755\n",
      " 6.1877\n",
      " 3.2033\n",
      "-1.6924\n",
      "-1.7740\n",
      " 4.6999\n",
      " 3.7360\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3027\n",
      " 1.1496\n",
      "-0.1117\n",
      "-0.1199\n",
      " 0.5013\n",
      " 0.5836\n",
      " 0.3204\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 147\n",
      "p \n",
      "-13.5025\n",
      " -6.8111\n",
      "-15.1223\n",
      "  1.6181\n",
      " -2.9053\n",
      " -0.0015\n",
      " -4.1962\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1231\n",
      " 1.0157\n",
      "-0.2426\n",
      " 0.0460\n",
      " 0.4275\n",
      " 0.4910\n",
      " 0.4264\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 148\n",
      "p \n",
      "  4.4323\n",
      "-12.5479\n",
      " 11.5451\n",
      " 11.7806\n",
      " 10.9000\n",
      "  4.2636\n",
      "  2.8996\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9985096842036023\n",
      "accepted True\n",
      "q \n",
      " 0.2773\n",
      " 0.8364\n",
      "-0.0578\n",
      " 0.1205\n",
      " 0.4954\n",
      " 0.5174\n",
      " 0.3145\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 149\n",
      "p \n",
      "  1.7852\n",
      " -9.1225\n",
      "  0.6113\n",
      "  3.7444\n",
      "-11.7591\n",
      " -2.1355\n",
      " -7.9385\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9842654974103553\n",
      "accepted True\n",
      "q \n",
      " 0.3961\n",
      " 0.8375\n",
      " 0.0147\n",
      " 0.2822\n",
      " 0.2217\n",
      " 0.4607\n",
      " 0.1155\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 150\n",
      "p \n",
      "-17.2225\n",
      " 11.8479\n",
      " 15.1354\n",
      " 14.5085\n",
      " 11.4615\n",
      "  7.8472\n",
      "  6.7828\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0638\n",
      " 1.0211\n",
      " 0.0680\n",
      " 0.3180\n",
      " 0.3032\n",
      " 0.5395\n",
      " 0.3818\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 151\n",
      "p \n",
      "  3.9859\n",
      "  1.3217\n",
      " 12.2764\n",
      "  3.5212\n",
      "  3.7939\n",
      "  9.3747\n",
      "  1.8256\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2746\n",
      " 1.0477\n",
      " 0.1365\n",
      " 0.2016\n",
      " 0.3898\n",
      " 0.6261\n",
      " 0.2366\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 152\n",
      "p \n",
      "  1.5127\n",
      "  1.0781\n",
      "-16.3727\n",
      " 13.2889\n",
      " -3.3706\n",
      "  3.9348\n",
      " -3.7700\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3668\n",
      " 1.0997\n",
      "-0.1425\n",
      " 0.4122\n",
      " 0.2495\n",
      " 0.5885\n",
      " 0.2020\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 153\n",
      "p \n",
      "-21.9047\n",
      " -4.6022\n",
      " -0.9258\n",
      "-12.7360\n",
      "-13.6325\n",
      " -0.6440\n",
      " -2.9787\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0055\n",
      " 0.9836\n",
      "-0.0672\n",
      " 0.1830\n",
      " 0.2098\n",
      " 0.4773\n",
      " 0.4119\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 154\n",
      "p \n",
      "  2.4000\n",
      " -4.1139\n",
      "  9.9370\n",
      " 21.1549\n",
      " 11.0538\n",
      " -8.7660\n",
      " 11.0421\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.997822037304241\n",
      "accepted True\n",
      "q \n",
      " 0.0648\n",
      " 0.9135\n",
      "-0.0384\n",
      " 0.3524\n",
      " 0.2767\n",
      " 0.3560\n",
      " 0.4951\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 155\n",
      "p \n",
      "  9.1166\n",
      "-12.0266\n",
      "  7.0248\n",
      "  2.6987\n",
      " -3.0096\n",
      "-13.5369\n",
      " -7.7013\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4187\n",
      " 0.8287\n",
      " 0.0760\n",
      " 0.2735\n",
      " 0.2795\n",
      " 0.2577\n",
      " 0.1140\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 156\n",
      "p \n",
      " 16.8242\n",
      "  9.2098\n",
      " 10.3049\n",
      "  2.7779\n",
      "  1.1731\n",
      "  0.1589\n",
      " 18.9284\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9921318329950691\n",
      "accepted True\n",
      "q \n",
      " 0.5038\n",
      " 1.0148\n",
      " 0.0449\n",
      " 0.1770\n",
      " 0.3658\n",
      " 0.3420\n",
      " 0.2613\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 157\n",
      "p \n",
      "-14.4773\n",
      "-12.7288\n",
      "  4.3060\n",
      "-11.2815\n",
      "-15.2633\n",
      "  2.3624\n",
      " -2.1268\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1693\n",
      " 0.8407\n",
      " 0.0992\n",
      " 0.1047\n",
      " 0.2208\n",
      " 0.3994\n",
      " 0.3706\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 158\n",
      "p \n",
      " -7.1967\n",
      " -9.9829\n",
      " -5.9661\n",
      "-10.6747\n",
      " -7.2544\n",
      "-21.7754\n",
      "-10.0315\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9633247262249989\n",
      "accepted True\n",
      "q \n",
      " 0.2184\n",
      " 0.8281\n",
      " 0.0066\n",
      "-0.0059\n",
      " 0.3279\n",
      " 0.1800\n",
      " 0.2641\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 159\n",
      "p \n",
      "  2.3004\n",
      "  7.7565\n",
      " -8.4549\n",
      " 12.9841\n",
      " 13.7870\n",
      " -7.2228\n",
      "  0.8912\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9682681340927064\n",
      "accepted True\n",
      "q \n",
      " 0.3173\n",
      " 1.0118\n",
      "-0.1730\n",
      " 0.0726\n",
      " 0.5114\n",
      " 0.2016\n",
      " 0.2726\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 160\n",
      "p \n",
      "-16.5967\n",
      " 14.8320\n",
      " -5.4400\n",
      " -0.3272\n",
      " -4.0016\n",
      " -0.0329\n",
      " -2.9661\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1042\n",
      " 1.2309\n",
      "-0.2028\n",
      " 0.1111\n",
      " 0.4076\n",
      " 0.2984\n",
      " 0.3792\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 161\n",
      "p \n",
      " -1.5490\n",
      " 10.1541\n",
      "  5.7381\n",
      "  1.3010\n",
      " -3.7874\n",
      "  2.8432\n",
      "  0.2205\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2086\n",
      " 1.2923\n",
      "-0.0872\n",
      " 0.1406\n",
      " 0.3319\n",
      " 0.4063\n",
      " 0.2839\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 162\n",
      "p \n",
      " 24.5897\n",
      "  1.2063\n",
      "  2.6407\n",
      " -1.4022\n",
      "  5.9980\n",
      "  4.4069\n",
      " 12.7830\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6024\n",
      " 1.2188\n",
      "-0.1141\n",
      "-0.0440\n",
      " 0.5822\n",
      " 0.4965\n",
      " 0.2113\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 163\n",
      "p \n",
      "-6.1830\n",
      "-1.1373\n",
      "-7.2907\n",
      " 0.7512\n",
      "-0.6298\n",
      " 9.3472\n",
      "-9.6732\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4937\n",
      " 1.1508\n",
      "-0.1388\n",
      " 0.0343\n",
      " 0.5081\n",
      " 0.5873\n",
      " 0.1268\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 164\n",
      "p \n",
      "  2.5310\n",
      " -0.8810\n",
      "  9.6175\n",
      " 15.8150\n",
      "  9.1160\n",
      " 12.7543\n",
      "  5.8422\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4395\n",
      " 1.0822\n",
      "-0.0443\n",
      " 0.2067\n",
      " 0.4758\n",
      " 0.6912\n",
      " 0.2042\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 165\n",
      "p \n",
      "  5.7246\n",
      "  6.8668\n",
      "-15.0047\n",
      " -3.2803\n",
      "  8.5505\n",
      " -6.9654\n",
      " 12.1978\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3951\n",
      " 1.1796\n",
      "-0.3432\n",
      "-0.0516\n",
      " 0.7595\n",
      " 0.4844\n",
      " 0.4655\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 166\n",
      "p \n",
      " -5.2568\n",
      "  9.3811\n",
      " 16.9269\n",
      " -8.3382\n",
      "  5.1691\n",
      "  0.5366\n",
      " 11.2153\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1920\n",
      " 1.2153\n",
      "-0.0924\n",
      "-0.2486\n",
      " 0.7902\n",
      " 0.4709\n",
      " 0.5783\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 167\n",
      "p \n",
      "-14.9552\n",
      " -0.5426\n",
      "  1.3958\n",
      " -1.9712\n",
      " -0.3306\n",
      " -0.7984\n",
      "-11.7765\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1557\n",
      " 1.1151\n",
      "-0.0183\n",
      "-0.1061\n",
      " 0.5970\n",
      " 0.4399\n",
      " 0.3280\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 168\n",
      "p \n",
      " -8.1764\n",
      " -5.8401\n",
      " -5.0185\n",
      " -9.3831\n",
      " -9.9450\n",
      " -3.2505\n",
      "-14.2906\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2599\n",
      " 1.0270\n",
      "-0.0143\n",
      "-0.0572\n",
      " 0.4344\n",
      " 0.4015\n",
      " 0.1340\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 169\n",
      "p \n",
      " -9.0060\n",
      " 11.7375\n",
      " 10.5979\n",
      " 17.6465\n",
      " 13.3232\n",
      "-18.8073\n",
      " -6.1557\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2325\n",
      " 1.1655\n",
      " 0.0344\n",
      " 0.1404\n",
      " 0.4531\n",
      " 0.2172\n",
      " 0.1158\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 170\n",
      "p \n",
      " -4.7710\n",
      " -5.6529\n",
      " 10.4072\n",
      " -4.9535\n",
      "  1.8393\n",
      "-11.2042\n",
      " -0.7122\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2188\n",
      " 1.0114\n",
      " 0.0993\n",
      "-0.0089\n",
      " 0.5178\n",
      " 0.1954\n",
      " 0.1971\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 171\n",
      "p \n",
      "-6.6168\n",
      "-0.6356\n",
      " 4.8186\n",
      " 6.7788\n",
      "-1.7952\n",
      " 1.9359\n",
      "-1.7974\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9996346902693813\n",
      "accepted True\n",
      "q \n",
      " 0.1910\n",
      " 1.0051\n",
      " 0.0838\n",
      " 0.1566\n",
      " 0.3601\n",
      " 0.3253\n",
      " 0.2238\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 172\n",
      "p \n",
      " -0.8736\n",
      " -0.2623\n",
      "  2.4500\n",
      " 15.3079\n",
      " 24.6447\n",
      " -2.9196\n",
      " -0.5192\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2853\n",
      " 1.0118\n",
      "-0.0276\n",
      " 0.0913\n",
      " 0.6955\n",
      " 0.3468\n",
      " 0.2355\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 173\n",
      "p \n",
      "  9.9031\n",
      "  4.2154\n",
      "  7.0326\n",
      " -9.4814\n",
      "-10.6363\n",
      " -2.8007\n",
      "  4.8892\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4414\n",
      " 1.0848\n",
      " 0.0368\n",
      " 0.0048\n",
      " 0.4920\n",
      " 0.3663\n",
      " 0.1757\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 174\n",
      "p \n",
      "-15.1547\n",
      " -0.5227\n",
      " -4.2292\n",
      "  8.4428\n",
      " -2.5172\n",
      "  1.4406\n",
      "-14.5975\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9968188447397799\n",
      "accepted True\n",
      "q \n",
      " 0.2915\n",
      " 1.0694\n",
      "-0.0052\n",
      " 0.2272\n",
      " 0.3062\n",
      " 0.4157\n",
      " 0.1065\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 175\n",
      "p \n",
      " -1.5429\n",
      " 16.3854\n",
      "  8.6095\n",
      " -6.0868\n",
      " -4.2426\n",
      " 10.8088\n",
      " -6.3763\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4166\n",
      " 1.3153\n",
      " 0.0863\n",
      " 0.0853\n",
      " 0.3355\n",
      " 0.5841\n",
      "-0.0252\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 176\n",
      "p \n",
      "  3.5314\n",
      " -1.6712\n",
      "  9.4506\n",
      "-12.6399\n",
      "-19.5900\n",
      "-13.6646\n",
      " -3.2993\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4603\n",
      " 1.1577\n",
      " 0.1899\n",
      " 0.0644\n",
      " 0.1437\n",
      " 0.3586\n",
      "-0.0322\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 177\n",
      "p \n",
      " -2.7883\n",
      " -1.6920\n",
      " 12.0369\n",
      "  3.0111\n",
      "  7.2733\n",
      " -1.2137\n",
      "  3.5545\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3427\n",
      " 1.0503\n",
      " 0.1676\n",
      " 0.0231\n",
      " 0.3575\n",
      " 0.3781\n",
      " 0.1437\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 178\n",
      "p \n",
      " -8.6603\n",
      " -6.5155\n",
      " -5.7588\n",
      "  0.6353\n",
      "  6.5326\n",
      "-13.7706\n",
      " -2.4418\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2180\n",
      " 0.9501\n",
      "-0.0288\n",
      "-0.0170\n",
      " 0.5261\n",
      " 0.2353\n",
      " 0.2960\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 179\n",
      "p \n",
      "-5.0416\n",
      " 1.1463\n",
      " 8.6207\n",
      "-8.2682\n",
      " 8.2000\n",
      "-0.8986\n",
      "-3.8249\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9938410233036553\n",
      "accepted True\n",
      "q \n",
      " 0.2705\n",
      " 1.0095\n",
      " 0.0373\n",
      "-0.2168\n",
      " 0.7135\n",
      " 0.3228\n",
      " 0.2337\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 180\n",
      "p \n",
      "  8.5982\n",
      " -4.3087\n",
      " 10.3867\n",
      " -1.7885\n",
      "  5.0761\n",
      " -6.4577\n",
      " -5.1460\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.992166841926689\n",
      "accepted True\n",
      "q \n",
      " 0.5213\n",
      " 0.9863\n",
      " 0.1141\n",
      "-0.1843\n",
      " 0.7008\n",
      " 0.3255\n",
      " 0.0289\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 181\n",
      "p \n",
      " 25.0064\n",
      " -8.0707\n",
      " -1.1744\n",
      "-14.3733\n",
      "-14.1105\n",
      " -5.9319\n",
      " 12.9245\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.7192\n",
      " 0.9363\n",
      " 0.0112\n",
      "-0.1943\n",
      " 0.5487\n",
      " 0.3225\n",
      " 0.1133\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 182\n",
      "p \n",
      " 9.8669\n",
      "-2.9432\n",
      " 2.6988\n",
      " 0.0772\n",
      "-9.5312\n",
      "-6.8288\n",
      " 6.5359\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9947231060806943\n",
      "accepted True\n",
      "q \n",
      " 0.6336\n",
      " 0.9483\n",
      " 0.0059\n",
      "-0.0033\n",
      " 0.3600\n",
      " 0.3038\n",
      " 0.1687\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 183\n",
      "p \n",
      " 11.0056\n",
      "-16.6705\n",
      " -3.4107\n",
      " -1.6689\n",
      "-12.1340\n",
      " 23.5311\n",
      " -1.2023\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9897562451642834\n",
      "accepted True\n",
      "q \n",
      " 0.6958\n",
      " 0.8244\n",
      " 0.0083\n",
      " 0.1158\n",
      " 0.2453\n",
      " 0.6410\n",
      " 0.0687\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 184\n",
      "p \n",
      "  2.8403\n",
      " -1.7041\n",
      " -8.6374\n",
      " -8.5975\n",
      "-13.4759\n",
      " 12.8199\n",
      "  0.2529\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5936\n",
      " 0.9397\n",
      "-0.0788\n",
      " 0.0815\n",
      " 0.2305\n",
      " 0.7058\n",
      " 0.1327\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 185\n",
      "p \n",
      " -2.9410\n",
      " 14.2453\n",
      "  8.3774\n",
      " 10.3749\n",
      " 19.8392\n",
      "  6.7065\n",
      " 14.3886\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3505\n",
      " 1.1299\n",
      "-0.1266\n",
      " 0.0081\n",
      " 0.5651\n",
      " 0.6782\n",
      " 0.4241\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 186\n",
      "p \n",
      "  0.5998\n",
      " 11.2511\n",
      "  4.9386\n",
      "  6.0706\n",
      "  2.3913\n",
      "  1.4643\n",
      "  9.7031\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2752\n",
      " 1.2471\n",
      "-0.1184\n",
      " 0.0922\n",
      " 0.4980\n",
      " 0.5984\n",
      " 0.4897\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 187\n",
      "p \n",
      "  8.4569\n",
      "  0.0781\n",
      "  5.7996\n",
      "  2.7188\n",
      " 19.3279\n",
      "  7.1162\n",
      " 11.2319\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4028\n",
      " 1.1623\n",
      "-0.1315\n",
      "-0.1488\n",
      " 0.8854\n",
      " 0.6376\n",
      " 0.4857\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 188\n",
      "p \n",
      " -1.4923\n",
      "  1.8230\n",
      " -8.0197\n",
      "-14.7536\n",
      " -8.6069\n",
      " -4.7034\n",
      "  5.7682\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2720\n",
      " 1.1353\n",
      "-0.2129\n",
      "-0.2260\n",
      " 0.6928\n",
      " 0.4580\n",
      " 0.5499\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 189\n",
      "p \n",
      "-12.9204\n",
      " -1.4600\n",
      "-14.9824\n",
      "  1.6049\n",
      "  3.7373\n",
      " -2.0696\n",
      " -1.9102\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1022\n",
      " 1.0864\n",
      "-0.3389\n",
      "-0.0920\n",
      " 0.6611\n",
      " 0.4065\n",
      " 0.5935\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 190\n",
      "p \n",
      "  0.5836\n",
      "  2.6586\n",
      " 16.2177\n",
      " -6.0920\n",
      "  2.3347\n",
      " 13.7602\n",
      " -2.5215\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3114\n",
      " 1.0949\n",
      "-0.0146\n",
      "-0.1759\n",
      " 0.6435\n",
      " 0.6033\n",
      " 0.2722\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 191\n",
      "p \n",
      "-11.1884\n",
      "  3.0218\n",
      " -3.9828\n",
      " -4.5458\n",
      " -3.4941\n",
      " -8.0804\n",
      " -1.7289\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1539\n",
      " 1.1047\n",
      "-0.0889\n",
      "-0.1010\n",
      " 0.5313\n",
      " 0.4142\n",
      " 0.3701\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 192\n",
      "p \n",
      " -6.6289\n",
      "  1.9220\n",
      " -1.6498\n",
      "  3.2372\n",
      " 10.7852\n",
      " -2.3715\n",
      "-11.8579\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2906\n",
      " 1.1237\n",
      "-0.0905\n",
      "-0.0876\n",
      " 0.6548\n",
      " 0.4098\n",
      " 0.1662\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 193\n",
      "p \n",
      " 9.5731\n",
      " 2.7561\n",
      "-2.6896\n",
      " 0.6017\n",
      " 0.0835\n",
      "-8.2889\n",
      " 4.4665\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4403\n",
      " 1.1366\n",
      "-0.1426\n",
      "-0.0351\n",
      " 0.5953\n",
      " 0.3337\n",
      " 0.1885\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 194\n",
      "p \n",
      " 4.6375\n",
      " 0.3468\n",
      "-0.8777\n",
      " 8.3427\n",
      " 7.1686\n",
      " 2.8893\n",
      " 6.8570\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4264\n",
      " 1.1021\n",
      "-0.1758\n",
      " 0.0518\n",
      " 0.6056\n",
      " 0.4183\n",
      " 0.2889\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 195\n",
      "p \n",
      " -2.3370\n",
      "  1.3447\n",
      " -3.2746\n",
      " -4.6436\n",
      "  3.9320\n",
      "  7.5916\n",
      " 12.1447\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2413\n",
      " 1.0947\n",
      "-0.2389\n",
      "-0.0922\n",
      " 0.7029\n",
      " 0.5121\n",
      " 0.5505\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 196\n",
      "p \n",
      " -8.1394\n",
      " 12.2059\n",
      "  4.1374\n",
      " 11.0805\n",
      "  9.7484\n",
      "-10.1247\n",
      " -0.5759\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1755\n",
      " 1.2292\n",
      "-0.1751\n",
      " 0.0566\n",
      " 0.6315\n",
      " 0.3594\n",
      " 0.4635\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 197\n",
      "p \n",
      " -4.3587\n",
      " -5.1353\n",
      "  2.0280\n",
      " -2.3552\n",
      " 10.9313\n",
      " -9.2298\n",
      "-10.0058\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3237\n",
      " 1.0684\n",
      "-0.0832\n",
      "-0.1142\n",
      " 0.7778\n",
      " 0.2932\n",
      " 0.2161\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 198\n",
      "p \n",
      " 5.7983\n",
      "-2.9612\n",
      "-3.6867\n",
      "-1.8176\n",
      " 1.7948\n",
      "-8.4838\n",
      "-1.7118\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4582\n",
      " 1.0368\n",
      "-0.1221\n",
      "-0.0943\n",
      " 0.7075\n",
      " 0.2691\n",
      " 0.1629\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 199\n",
      "p \n",
      " -0.4625\n",
      "  0.2882\n",
      "-11.2363\n",
      "  0.1707\n",
      " 12.0429\n",
      "  0.9088\n",
      " -4.0624\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4841\n",
      " 1.0850\n",
      "-0.2543\n",
      "-0.1637\n",
      " 0.8684\n",
      " 0.3619\n",
      " 0.1830\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 200\n",
      "p \n",
      " 5.9087\n",
      " 8.2977\n",
      " 5.1828\n",
      " 1.2691\n",
      " 7.5792\n",
      " 8.5326\n",
      " 5.2788\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5306\n",
      " 1.2002\n",
      "-0.1700\n",
      "-0.1646\n",
      " 0.8476\n",
      " 0.5199\n",
      " 0.1957\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 201\n",
      "p \n",
      " 3.2357\n",
      "-8.6947\n",
      "-9.4437\n",
      " 0.2952\n",
      " 2.4509\n",
      " 0.6440\n",
      "-3.6839\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5420\n",
      " 1.0281\n",
      "-0.2182\n",
      "-0.0784\n",
      " 0.7349\n",
      " 0.4862\n",
      " 0.1680\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 202\n",
      "p \n",
      "  3.2186\n",
      " -5.5894\n",
      " 15.2692\n",
      "  4.2259\n",
      "  8.2065\n",
      "  2.7502\n",
      " -2.3537\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5586\n",
      " 0.9523\n",
      " 0.0224\n",
      "-0.0467\n",
      " 0.6871\n",
      " 0.5119\n",
      " 0.0697\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 203\n",
      "p \n",
      " -6.1128\n",
      "-11.1090\n",
      "-15.3623\n",
      " -8.4119\n",
      " -2.7120\n",
      " 14.5507\n",
      "  0.8106\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3526\n",
      " 0.8711\n",
      "-0.1791\n",
      "-0.1038\n",
      " 0.6609\n",
      " 0.6308\n",
      " 0.3037\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 204\n",
      "p \n",
      "  4.9416\n",
      "  1.7814\n",
      " 10.4107\n",
      " -4.7601\n",
      " -5.8218\n",
      "  3.2019\n",
      " -0.9163\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4621\n",
      " 0.9772\n",
      " 0.0076\n",
      "-0.0637\n",
      " 0.4965\n",
      " 0.5949\n",
      " 0.1465\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 205\n",
      "p \n",
      " -3.5965\n",
      " -1.7848\n",
      " -4.3063\n",
      "  1.2319\n",
      " 10.9234\n",
      " -5.7625\n",
      " -2.4483\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3945\n",
      " 0.9876\n",
      "-0.1048\n",
      "-0.1106\n",
      " 0.6812\n",
      " 0.4534\n",
      " 0.2187\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 206\n",
      "p \n",
      " -3.1105\n",
      " 14.8794\n",
      " -2.5299\n",
      " -8.2346\n",
      " -3.4131\n",
      "-10.1129\n",
      " -4.2063\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3946\n",
      " 1.2371\n",
      "-0.1237\n",
      "-0.1508\n",
      " 0.6143\n",
      " 0.3411\n",
      " 0.1755\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 207\n",
      "p \n",
      "  2.4352\n",
      "  9.3076\n",
      " 15.0256\n",
      " -3.9220\n",
      " -9.8144\n",
      "  7.5908\n",
      "  7.1081\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3670\n",
      " 1.2681\n",
      " 0.0637\n",
      "-0.0422\n",
      " 0.3788\n",
      " 0.4888\n",
      " 0.2110\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 208\n",
      "p \n",
      " -0.5557\n",
      " 19.2769\n",
      " 20.5827\n",
      " -7.4328\n",
      " -3.1638\n",
      "-12.9555\n",
      " 12.1915\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2476\n",
      " 1.4250\n",
      " 0.1729\n",
      "-0.1343\n",
      " 0.4035\n",
      " 0.3252\n",
      " 0.3700\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 209\n",
      "p \n",
      "-20.7475\n",
      "  4.5807\n",
      "  0.1139\n",
      " -6.4018\n",
      " -7.7842\n",
      " -8.5421\n",
      "-17.2441\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1348\n",
      " 1.3025\n",
      " 0.1266\n",
      "-0.0339\n",
      " 0.3064\n",
      " 0.2818\n",
      " 0.1890\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 210\n",
      "p \n",
      " -3.8291\n",
      " 10.9407\n",
      "  9.3630\n",
      " -6.5161\n",
      " -8.8659\n",
      " -9.9640\n",
      "  5.8151\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1124\n",
      " 1.3296\n",
      " 0.1225\n",
      "-0.0247\n",
      " 0.2647\n",
      " 0.2415\n",
      " 0.3190\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 211\n",
      "p \n",
      "-2.7632\n",
      "-7.9212\n",
      "-0.8328\n",
      "-1.6001\n",
      " 7.3606\n",
      " 9.0052\n",
      " 0.5770\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1912\n",
      " 1.0668\n",
      " 0.0074\n",
      "-0.1005\n",
      " 0.5155\n",
      " 0.4288\n",
      " 0.3306\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 212\n",
      "p \n",
      " -7.8966\n",
      "  2.7121\n",
      "-12.9918\n",
      " -0.3422\n",
      "-10.5227\n",
      "  0.5217\n",
      " -5.4410\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9993388455205786\n",
      "accepted True\n",
      "q \n",
      " 0.1834\n",
      " 1.1176\n",
      "-0.1389\n",
      " 0.0915\n",
      " 0.3178\n",
      " 0.4341\n",
      " 0.3087\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 213\n",
      "p \n",
      "-1.5453\n",
      " 5.7452\n",
      " 8.8661\n",
      " 7.0350\n",
      " 1.7001\n",
      " 6.3642\n",
      " 2.9521\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2222\n",
      " 1.1541\n",
      "-0.0366\n",
      " 0.1689\n",
      " 0.3122\n",
      " 0.5199\n",
      " 0.2925\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 214\n",
      "p \n",
      " -6.6600\n",
      " 10.7253\n",
      "  6.4118\n",
      " -1.6739\n",
      "  5.5214\n",
      " -4.8084\n",
      "  2.1841\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1745\n",
      " 1.2439\n",
      "-0.0272\n",
      " 0.0129\n",
      " 0.4841\n",
      " 0.4309\n",
      " 0.3514\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 215\n",
      "p \n",
      "-11.2167\n",
      " -5.0546\n",
      " -1.3890\n",
      " -4.9435\n",
      " -0.3807\n",
      "-22.2100\n",
      "  8.1241\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      "-0.0550\n",
      " 1.0405\n",
      "-0.1127\n",
      "-0.0500\n",
      " 0.5192\n",
      " 0.1422\n",
      " 0.6463\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 216\n",
      "p \n",
      "-5.3625\n",
      "-0.3756\n",
      " 1.5259\n",
      " 7.2225\n",
      " 9.5985\n",
      " 3.4510\n",
      "-3.7308\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1087\n",
      " 1.0253\n",
      "-0.0913\n",
      " 0.0168\n",
      " 0.5764\n",
      " 0.3147\n",
      " 0.4238\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 217\n",
      "p \n",
      "-7.1358\n",
      "-6.7683\n",
      " 7.4048\n",
      "-0.3118\n",
      " 6.2596\n",
      "-9.8228\n",
      "-2.4750\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9934285786731082\n",
      "accepted True\n",
      "q \n",
      " 0.1351\n",
      " 0.9280\n",
      "-0.0045\n",
      "-0.0382\n",
      " 0.6168\n",
      " 0.2586\n",
      " 0.3657\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 218\n",
      "p \n",
      "  7.4121\n",
      "  8.5608\n",
      " -2.1558\n",
      "  9.1242\n",
      "  2.1468\n",
      "-13.5454\n",
      "  5.5488\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2938\n",
      " 1.0912\n",
      "-0.1103\n",
      " 0.1136\n",
      " 0.5133\n",
      " 0.1884\n",
      " 0.3355\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 219\n",
      "p \n",
      " -4.7434\n",
      " 13.1522\n",
      "  3.9794\n",
      " -4.6747\n",
      " 13.7471\n",
      "-11.7960\n",
      " -6.6840\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3683\n",
      " 1.2723\n",
      "-0.0870\n",
      "-0.1644\n",
      " 0.8002\n",
      " 0.1768\n",
      " 0.2028\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 220\n",
      "p \n",
      "  1.2282\n",
      " -1.8896\n",
      " -1.7218\n",
      " -7.7463\n",
      "  1.6847\n",
      "-12.6808\n",
      "  1.3280\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3715\n",
      " 1.1435\n",
      "-0.1182\n",
      "-0.2223\n",
      " 0.7733\n",
      " 0.1526\n",
      " 0.2670\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 221\n",
      "p \n",
      " -1.0727\n",
      "-12.8216\n",
      " -2.6925\n",
      " 11.3663\n",
      " 11.2562\n",
      "-12.2251\n",
      " -6.2993\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4007\n",
      " 0.9208\n",
      "-0.1268\n",
      "-0.0091\n",
      " 0.7118\n",
      " 0.1503\n",
      " 0.1943\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 222\n",
      "p \n",
      " -1.6267\n",
      " -7.2514\n",
      "  7.9471\n",
      " -5.3533\n",
      " 11.6321\n",
      "-12.6139\n",
      "  5.3629\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9939668518058661\n",
      "accepted True\n",
      "q \n",
      " 0.3102\n",
      " 0.8683\n",
      "-0.0654\n",
      "-0.2053\n",
      " 0.8687\n",
      " 0.1398\n",
      " 0.3430\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 223\n",
      "p \n",
      " -3.1549\n",
      "-10.2344\n",
      " -4.1644\n",
      "-15.8814\n",
      " -6.9717\n",
      " -3.6872\n",
      " -3.3128\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3018\n",
      " 0.8367\n",
      "-0.0750\n",
      "-0.2563\n",
      " 0.7165\n",
      " 0.2369\n",
      " 0.3147\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 224\n",
      "p \n",
      " -1.9070\n",
      " 10.2340\n",
      "  6.9784\n",
      "  6.6448\n",
      " 10.5213\n",
      "  1.4806\n",
      "  4.4921\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.981494817020158\n",
      "accepted True\n",
      "q \n",
      " 0.2847\n",
      " 1.0341\n",
      "-0.0586\n",
      "-0.1577\n",
      " 0.7253\n",
      " 0.3389\n",
      " 0.3379\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 225\n",
      "p \n",
      " 19.4011\n",
      " -2.3006\n",
      "  4.7709\n",
      "  4.4046\n",
      "  6.2931\n",
      "  5.6409\n",
      "  1.5224\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6708\n",
      " 1.0389\n",
      "-0.0244\n",
      "-0.0872\n",
      " 0.7160\n",
      " 0.4801\n",
      " 0.0777\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 226\n",
      "p \n",
      " -8.5302\n",
      "  8.4607\n",
      "-10.7321\n",
      " 15.3586\n",
      "  9.2289\n",
      " -4.6026\n",
      " -3.0594\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4205\n",
      " 1.1591\n",
      "-0.2137\n",
      " 0.1441\n",
      " 0.6159\n",
      " 0.4011\n",
      " 0.2143\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 227\n",
      "p \n",
      "  5.9161\n",
      " -0.9546\n",
      "-12.1150\n",
      "  4.0541\n",
      "  1.4361\n",
      "  9.2248\n",
      "  1.0931\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5013\n",
      " 1.1401\n",
      "-0.3060\n",
      " 0.1492\n",
      " 0.5869\n",
      " 0.5399\n",
      " 0.2212\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 228\n",
      "p \n",
      " 5.0308\n",
      " 0.3450\n",
      "-9.0628\n",
      "-7.9475\n",
      "-4.6510\n",
      " 4.2253\n",
      "-4.3838\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5913\n",
      " 1.1508\n",
      "-0.2708\n",
      " 0.0041\n",
      " 0.5730\n",
      " 0.5561\n",
      " 0.1159\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 229\n",
      "p \n",
      "-11.4149\n",
      "  0.7662\n",
      "-11.8829\n",
      "  0.3894\n",
      "-10.0240\n",
      "  9.0922\n",
      "-13.4295\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4212\n",
      " 1.1555\n",
      "-0.2379\n",
      " 0.1696\n",
      " 0.3281\n",
      " 0.6103\n",
      " 0.0746\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 230\n",
      "p \n",
      "  2.4660\n",
      " -4.8719\n",
      " -5.5991\n",
      " -4.6876\n",
      "-11.2772\n",
      " 23.4706\n",
      "  0.3144\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4458\n",
      " 1.0894\n",
      "-0.1818\n",
      " 0.1577\n",
      " 0.2653\n",
      " 0.8263\n",
      " 0.1265\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 231\n",
      "p \n",
      " -0.2883\n",
      "-12.7665\n",
      " -4.9067\n",
      "  0.6846\n",
      " 19.2228\n",
      " 13.5982\n",
      "  3.5082\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4010\n",
      " 0.9038\n",
      "-0.2407\n",
      "-0.0994\n",
      " 0.7409\n",
      " 0.8075\n",
      " 0.3009\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 232\n",
      "p \n",
      "-15.4745\n",
      "  2.5209\n",
      " -3.5897\n",
      " -5.8134\n",
      "-14.7725\n",
      "  3.8854\n",
      "-12.3177\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2353\n",
      " 1.0134\n",
      "-0.1139\n",
      " 0.0638\n",
      " 0.3478\n",
      " 0.6587\n",
      " 0.1967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 233\n",
      "p \n",
      "  3.2967\n",
      "  9.8412\n",
      "  0.4518\n",
      "  7.3515\n",
      " 16.7712\n",
      " -7.6177\n",
      " -0.4293\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3828\n",
      " 1.1607\n",
      "-0.1597\n",
      "-0.0189\n",
      " 0.6340\n",
      " 0.4865\n",
      " 0.1669\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 234\n",
      "p \n",
      "  7.2499\n",
      " 13.0830\n",
      " -0.0656\n",
      " -6.9769\n",
      " -8.9754\n",
      "-12.8336\n",
      "  4.7696\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4546\n",
      " 1.3056\n",
      "-0.1433\n",
      "-0.0326\n",
      " 0.4854\n",
      " 0.3236\n",
      " 0.1896\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 235\n",
      "p \n",
      "  3.2239\n",
      "  1.8434\n",
      " -5.7448\n",
      "-12.4557\n",
      " -2.9206\n",
      " -0.3748\n",
      "  9.4675\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3749\n",
      " 1.2268\n",
      "-0.2159\n",
      "-0.2035\n",
      " 0.6048\n",
      " 0.3686\n",
      " 0.3918\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 236\n",
      "p \n",
      "-14.1126\n",
      " -3.9577\n",
      " -8.8018\n",
      " -0.8186\n",
      " -1.2827\n",
      " 18.6661\n",
      " -3.8382\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1762\n",
      " 1.0990\n",
      "-0.2281\n",
      "-0.0642\n",
      " 0.5251\n",
      " 0.6130\n",
      " 0.4296\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 237\n",
      "p \n",
      " -6.7576\n",
      " -0.1182\n",
      "  0.1009\n",
      "  0.8697\n",
      " 17.6889\n",
      " 11.7872\n",
      "  2.9607\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1595\n",
      " 1.0862\n",
      "-0.2274\n",
      "-0.2065\n",
      " 0.8391\n",
      " 0.6857\n",
      " 0.4911\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 238\n",
      "p \n",
      "  0.7708\n",
      "-13.0563\n",
      "  1.4875\n",
      " 11.4010\n",
      " -1.9813\n",
      " -2.4130\n",
      "  4.2400\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1867\n",
      " 0.8468\n",
      "-0.1296\n",
      " 0.1525\n",
      " 0.4674\n",
      " 0.5108\n",
      " 0.4445\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 239\n",
      "p \n",
      " -2.3079\n",
      "  6.5371\n",
      " -4.7263\n",
      "-12.8698\n",
      "  1.4985\n",
      " -9.9398\n",
      " -6.2703\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3175\n",
      " 1.0384\n",
      "-0.1499\n",
      "-0.1374\n",
      " 0.6429\n",
      " 0.3664\n",
      " 0.2790\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 240\n",
      "p \n",
      " -3.9695\n",
      "  6.8091\n",
      " -2.4577\n",
      " 15.1291\n",
      " -1.5679\n",
      "  6.9623\n",
      " -7.5063\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3580\n",
      " 1.1482\n",
      "-0.1248\n",
      " 0.2261\n",
      " 0.3600\n",
      " 0.4899\n",
      " 0.1343\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 241\n",
      "p \n",
      " -3.0223\n",
      "-10.3140\n",
      " -0.6354\n",
      " 13.8387\n",
      "  3.4781\n",
      "  7.5129\n",
      " -7.3044\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9935319698768287\n",
      "accepted True\n",
      "q \n",
      " 0.3762\n",
      " 0.9742\n",
      "-0.0751\n",
      " 0.3563\n",
      " 0.3135\n",
      " 0.5582\n",
      " 0.0901\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 242\n",
      "p \n",
      "-18.3941\n",
      "  1.4414\n",
      "-20.3863\n",
      " -2.5229\n",
      "  3.4285\n",
      "  0.0696\n",
      "-23.5879\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3251\n",
      " 1.0850\n",
      "-0.2368\n",
      " 0.1657\n",
      " 0.4826\n",
      " 0.5034\n",
      " 0.0082\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 243\n",
      "p \n",
      "-10.7919\n",
      "  2.2118\n",
      "  5.0469\n",
      " -1.9121\n",
      "  7.4595\n",
      "  4.2721\n",
      "-11.4708\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3151\n",
      " 1.1075\n",
      "-0.0856\n",
      " 0.0081\n",
      " 0.5970\n",
      " 0.5337\n",
      "-0.0041\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 244\n",
      "p \n",
      "-13.0653\n",
      " 15.9099\n",
      "  2.7450\n",
      " -9.3569\n",
      " -2.1483\n",
      " -1.5485\n",
      " -6.4403\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2237\n",
      " 1.3142\n",
      "-0.0457\n",
      "-0.1099\n",
      " 0.5774\n",
      " 0.4873\n",
      " 0.0812\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 245\n",
      "p \n",
      "  1.1201\n",
      "  4.4655\n",
      " 22.3506\n",
      " 14.7352\n",
      " 10.7432\n",
      "-15.1602\n",
      " 12.9000\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1678\n",
      " 1.1714\n",
      " 0.1077\n",
      " 0.0780\n",
      " 0.5173\n",
      " 0.2819\n",
      " 0.2975\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 246\n",
      "p \n",
      " -1.8286\n",
      " 14.9886\n",
      "  4.8098\n",
      "  7.3772\n",
      "  9.1042\n",
      " -5.7171\n",
      "  4.4210\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2027\n",
      " 1.3283\n",
      " 0.0107\n",
      " 0.0755\n",
      " 0.5846\n",
      " 0.2923\n",
      " 0.3426\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 247\n",
      "p \n",
      " -5.1548\n",
      " 10.9730\n",
      " -2.5019\n",
      "-13.2153\n",
      " -9.0917\n",
      "  2.6482\n",
      "  5.5985\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1356\n",
      " 1.3670\n",
      "-0.0836\n",
      "-0.0855\n",
      " 0.5132\n",
      " 0.3905\n",
      " 0.4655\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 248\n",
      "p \n",
      " -5.4010\n",
      " -6.9287\n",
      "  5.5352\n",
      "-11.0901\n",
      " -4.5533\n",
      " 10.1956\n",
      " -7.4302\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2598\n",
      " 1.1079\n",
      " 0.0529\n",
      "-0.1558\n",
      " 0.5009\n",
      " 0.5418\n",
      " 0.2298\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 249\n",
      "p \n",
      " -4.4247\n",
      "  2.4384\n",
      " -8.9916\n",
      " -0.7855\n",
      " -5.0283\n",
      " 12.9612\n",
      "  3.0698\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2088\n",
      " 1.1334\n",
      "-0.1117\n",
      "-0.0240\n",
      " 0.4261\n",
      " 0.6459\n",
      " 0.3560\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 250\n",
      "p \n",
      "-11.6387\n",
      "-10.4584\n",
      "-17.6905\n",
      " -0.1214\n",
      "  1.5779\n",
      "  4.1127\n",
      " -9.3942\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1776\n",
      " 0.9794\n",
      "-0.2541\n",
      " 0.0177\n",
      " 0.5006\n",
      " 0.5788\n",
      " 0.3400\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 251\n",
      "p \n",
      " -3.2808\n",
      "  0.1350\n",
      "  7.9212\n",
      "  0.8865\n",
      " 12.0778\n",
      "  9.5487\n",
      " -0.5948\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2504\n",
      " 1.0076\n",
      "-0.1167\n",
      "-0.0929\n",
      " 0.6806\n",
      " 0.6389\n",
      " 0.2883\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 252\n",
      "p \n",
      "-19.0813\n",
      " 15.0023\n",
      " -2.7664\n",
      " 13.8165\n",
      " 12.0088\n",
      " 10.5586\n",
      "-21.5191\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2587\n",
      " 1.2820\n",
      "-0.1067\n",
      " 0.0990\n",
      " 0.6283\n",
      " 0.7111\n",
      " 0.0399\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 253\n",
      "p \n",
      "  0.7320\n",
      "  1.2256\n",
      " 11.1137\n",
      " -0.0392\n",
      " -4.0400\n",
      " 14.7133\n",
      "  1.1581\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3319\n",
      " 1.1865\n",
      " 0.0587\n",
      " 0.1149\n",
      " 0.4469\n",
      " 0.7823\n",
      " 0.0704\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 254\n",
      "p \n",
      "-10.3816\n",
      "  6.2808\n",
      "-13.0557\n",
      "  0.6903\n",
      " -2.7712\n",
      "  4.8475\n",
      " -8.5324\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2705\n",
      " 1.2471\n",
      "-0.1381\n",
      " 0.1439\n",
      " 0.4055\n",
      " 0.6803\n",
      " 0.1353\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 255\n",
      "p \n",
      "  9.6226\n",
      " -0.1381\n",
      " 10.0169\n",
      " -4.6091\n",
      "  3.5004\n",
      " -0.7951\n",
      " -5.6135\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5689\n",
      " 1.1639\n",
      " 0.0332\n",
      "-0.0442\n",
      " 0.5440\n",
      " 0.5796\n",
      "-0.0725\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 256\n",
      "p \n",
      "  5.8727\n",
      " -8.7252\n",
      "  3.0044\n",
      " -5.8889\n",
      "-11.9264\n",
      " -0.6231\n",
      "  4.8390\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4919\n",
      " 0.9792\n",
      " 0.0429\n",
      " 0.0259\n",
      " 0.3500\n",
      " 0.4972\n",
      " 0.0967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 257\n",
      "p \n",
      "  1.1215\n",
      " -8.8672\n",
      " -1.6647\n",
      "-14.9023\n",
      " -3.8772\n",
      " -5.0412\n",
      "  2.7671\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9885831948535029\n",
      "accepted True\n",
      "q \n",
      " 0.4137\n",
      " 0.9010\n",
      "-0.0234\n",
      "-0.1727\n",
      " 0.5097\n",
      " 0.4061\n",
      " 0.2384\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 258\n",
      "p \n",
      " 12.5229\n",
      "  8.5270\n",
      "  1.4081\n",
      " 13.1663\n",
      " 15.7722\n",
      "-27.9377\n",
      " 10.7124\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4971\n",
      " 1.0568\n",
      "-0.1421\n",
      "-0.0653\n",
      " 0.6738\n",
      " 0.1124\n",
      " 0.3095\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 259\n",
      "p \n",
      "-1.2260e+01\n",
      "-7.6972e-02\n",
      "-1.1390e-04\n",
      " 1.2457e+01\n",
      " 2.0637e+01\n",
      "-9.3075e+00\n",
      "-1.1458e+01\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3698\n",
      " 1.0484\n",
      "-0.1350\n",
      "-0.0139\n",
      " 0.8064\n",
      " 0.1560\n",
      " 0.2159\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 260\n",
      "p \n",
      " -7.5431\n",
      " -2.1172\n",
      " 14.3730\n",
      "  8.2386\n",
      "  4.7456\n",
      "  6.3281\n",
      " -5.6350\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3077\n",
      " 0.9934\n",
      " 0.0747\n",
      " 0.1103\n",
      " 0.5828\n",
      " 0.3687\n",
      " 0.1365\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 261\n",
      "p \n",
      " -4.7512\n",
      " -4.8953\n",
      " -4.2429\n",
      "  0.7655\n",
      "  4.1808\n",
      "  0.9842\n",
      "-10.9665\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3758\n",
      " 0.9765\n",
      "-0.0091\n",
      " 0.0589\n",
      " 0.5943\n",
      " 0.4172\n",
      " 0.0632\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 262\n",
      "p \n",
      "  8.8549\n",
      " -1.1708\n",
      "  5.0838\n",
      " -8.2711\n",
      "-15.6326\n",
      " -0.4804\n",
      " -1.0688\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5168\n",
      " 1.0102\n",
      " 0.0682\n",
      " 0.0756\n",
      " 0.3344\n",
      " 0.4344\n",
      "-0.0009\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 263\n",
      "p \n",
      "-0.2209\n",
      " 7.3816\n",
      " 1.9318\n",
      "-6.9113\n",
      " 3.1002\n",
      "-9.0231\n",
      " 2.7308\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9993779210799183\n",
      "accepted True\n",
      "q \n",
      " 0.4395\n",
      " 1.1195\n",
      "-0.0090\n",
      "-0.0992\n",
      " 0.5268\n",
      " 0.3377\n",
      " 0.1470\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 264\n",
      "p \n",
      "  6.3316\n",
      " -3.3352\n",
      "  0.2090\n",
      " -3.3491\n",
      "  4.7153\n",
      " 19.2334\n",
      " 10.7270\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4350\n",
      " 1.0523\n",
      "-0.0788\n",
      "-0.1679\n",
      " 0.6609\n",
      " 0.6110\n",
      " 0.3097\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 265\n",
      "p \n",
      " 10.4323\n",
      " -7.1422\n",
      "  8.5418\n",
      "  1.3820\n",
      " -6.2078\n",
      "  8.7501\n",
      " 12.3628\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4414\n",
      " 0.9410\n",
      " 0.0047\n",
      " 0.0055\n",
      " 0.4477\n",
      " 0.6399\n",
      " 0.3577\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 266\n",
      "p \n",
      " 12.7828\n",
      "  6.7285\n",
      " -4.8078\n",
      "-13.8623\n",
      "-12.9353\n",
      " -0.2859\n",
      " 12.3996\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5018\n",
      " 1.1073\n",
      "-0.1099\n",
      "-0.1082\n",
      " 0.4256\n",
      " 0.5536\n",
      " 0.4077\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 267\n",
      "p \n",
      "-4.8047\n",
      "-4.3913\n",
      "-2.8208\n",
      " 2.6716\n",
      " 6.2722\n",
      " 1.2103\n",
      " 0.5026\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3457\n",
      " 1.0073\n",
      "-0.1451\n",
      "-0.0521\n",
      " 0.5341\n",
      " 0.5034\n",
      " 0.4137\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 268\n",
      "p \n",
      "-4.7929\n",
      "-7.3965\n",
      " 8.4876\n",
      " 7.5697\n",
      " 3.8129\n",
      " 3.6752\n",
      "-4.2877\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3193\n",
      " 0.9112\n",
      " 0.0018\n",
      " 0.0920\n",
      " 0.4543\n",
      " 0.5171\n",
      " 0.2689\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 269\n",
      "p \n",
      " -5.0860\n",
      "  5.3695\n",
      "  1.8825\n",
      " -6.1827\n",
      "-13.3607\n",
      "  7.6016\n",
      " -1.5248\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9983331758988979\n",
      "accepted True\n",
      "q \n",
      " 0.2758\n",
      " 1.0541\n",
      " 0.0262\n",
      " 0.1165\n",
      " 0.2663\n",
      " 0.5754\n",
      " 0.2452\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 270\n",
      "p \n",
      "-12.5237\n",
      " -1.6628\n",
      " -8.9121\n",
      " -6.0696\n",
      "  2.5783\n",
      " 12.2053\n",
      " -8.1241\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2168\n",
      " 1.0572\n",
      "-0.0968\n",
      "-0.0324\n",
      " 0.4766\n",
      " 0.6536\n",
      " 0.2610\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 271\n",
      "p \n",
      "  0.2025\n",
      "  3.4736\n",
      "  1.9191\n",
      " 11.2838\n",
      "  9.5792\n",
      " -7.0608\n",
      "  2.8385\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2599\n",
      " 1.0816\n",
      "-0.1170\n",
      " 0.0827\n",
      " 0.5244\n",
      " 0.4741\n",
      " 0.2950\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 272\n",
      "p \n",
      "-13.2090\n",
      " -1.5403\n",
      "-10.0835\n",
      " 10.5914\n",
      " 14.0062\n",
      "  2.2548\n",
      "-14.2958\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9997414982706179\n",
      "accepted True\n",
      "q \n",
      " 0.2562\n",
      " 1.0755\n",
      "-0.2039\n",
      " 0.1171\n",
      " 0.6441\n",
      " 0.4891\n",
      " 0.1937\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 273\n",
      "p \n",
      " 2.4398\n",
      " 4.8359\n",
      " 0.3071\n",
      "-0.4904\n",
      " 0.3135\n",
      "-3.6495\n",
      " 6.4321\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2859\n",
      " 1.1220\n",
      "-0.1807\n",
      " 0.0590\n",
      " 0.5869\n",
      " 0.4240\n",
      " 0.2986\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 274\n",
      "p \n",
      " -4.6250\n",
      "-12.1780\n",
      " -0.9309\n",
      "  0.8341\n",
      " -7.9492\n",
      "  4.5226\n",
      "-11.6175\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3476\n",
      " 0.9322\n",
      "-0.0496\n",
      " 0.1742\n",
      " 0.3501\n",
      " 0.4820\n",
      " 0.1108\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 275\n",
      "p \n",
      "  0.7272\n",
      "  4.5010\n",
      "  0.4545\n",
      " -5.4059\n",
      "  1.3100\n",
      "  4.0540\n",
      " 12.8637\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2546\n",
      " 1.0244\n",
      "-0.1168\n",
      "-0.0027\n",
      " 0.5004\n",
      " 0.5048\n",
      " 0.3789\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 276\n",
      "p \n",
      " -3.9109\n",
      " -2.7567\n",
      "-29.3491\n",
      "-14.8486\n",
      "-12.3095\n",
      "  2.3661\n",
      " -1.5202\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9879321795977989\n",
      "accepted True\n",
      "q \n",
      " 0.2409\n",
      " 1.0637\n",
      "-0.3935\n",
      "-0.0899\n",
      " 0.5045\n",
      " 0.4892\n",
      " 0.4574\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 277\n",
      "p \n",
      "  2.3057\n",
      " -4.0909\n",
      " 11.3553\n",
      "  8.9746\n",
      "  7.8997\n",
      "-18.3245\n",
      "  9.2190\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2169\n",
      " 0.9408\n",
      "-0.1793\n",
      " 0.0268\n",
      " 0.5090\n",
      " 0.2426\n",
      " 0.4857\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 278\n",
      "p \n",
      " -9.3019\n",
      "-12.4245\n",
      " -1.4555\n",
      " -7.8853\n",
      "-16.4244\n",
      " 12.2291\n",
      " -4.7815\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9854217946119069\n",
      "accepted True\n",
      "q \n",
      " 0.1639\n",
      " 0.8363\n",
      "-0.0600\n",
      " 0.0979\n",
      " 0.2656\n",
      " 0.4631\n",
      " 0.3779\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 279\n",
      "p \n",
      "-10.5382\n",
      "-12.0548\n",
      "-16.2192\n",
      " -0.1420\n",
      "  0.4828\n",
      "  0.7277\n",
      "-13.0240\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9851233449071863\n",
      "accepted False\n",
      "q \n",
      " 0.1639\n",
      " 0.8363\n",
      "-0.0600\n",
      " 0.0979\n",
      " 0.2656\n",
      " 0.4631\n",
      " 0.3779\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 280\n",
      "p \n",
      " 9.3353\n",
      " 0.1358\n",
      "-5.0137\n",
      " 7.2602\n",
      " 5.0232\n",
      "-2.5556\n",
      " 8.3104\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9894482260726367\n",
      "accepted True\n",
      "q \n",
      " 0.3104\n",
      " 0.9286\n",
      "-0.1706\n",
      " 0.1252\n",
      " 0.4003\n",
      " 0.4247\n",
      " 0.3936\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 281\n",
      "p \n",
      "  7.2546\n",
      "  7.4565\n",
      " 26.6020\n",
      " -3.8994\n",
      "  4.7585\n",
      "-14.8909\n",
      "  9.9478\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3735\n",
      " 1.0324\n",
      " 0.1050\n",
      "-0.0606\n",
      " 0.5109\n",
      " 0.2740\n",
      " 0.3293\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 282\n",
      "p \n",
      "  4.5970\n",
      "  0.9506\n",
      " -5.5525\n",
      " -4.9634\n",
      "-12.2053\n",
      " -3.0389\n",
      " -9.2658\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5425\n",
      " 1.0890\n",
      " 0.0266\n",
      " 0.0436\n",
      " 0.3289\n",
      " 0.3315\n",
      " 0.0651\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 283\n",
      "p \n",
      "-13.8442\n",
      " 11.8079\n",
      " -4.2808\n",
      " -5.9149\n",
      "  0.6239\n",
      "-10.2387\n",
      " -4.0406\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2854\n",
      " 1.2273\n",
      "-0.0830\n",
      "-0.0564\n",
      " 0.4544\n",
      " 0.2573\n",
      " 0.2290\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 284\n",
      "p \n",
      "-10.3437\n",
      " 10.0747\n",
      "  3.8040\n",
      "  3.4617\n",
      "  5.6713\n",
      " -6.9784\n",
      " -1.4721\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1784\n",
      " 1.2789\n",
      "-0.0719\n",
      "-0.0135\n",
      " 0.5039\n",
      " 0.2587\n",
      " 0.2984\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 285\n",
      "p \n",
      "  8.6200\n",
      " -9.0979\n",
      "-10.2190\n",
      "  1.6892\n",
      " -7.0290\n",
      " -3.9548\n",
      "  5.2620\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3249\n",
      " 1.0444\n",
      "-0.1828\n",
      " 0.1191\n",
      " 0.3789\n",
      " 0.2915\n",
      " 0.3263\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 286\n",
      "p \n",
      "-11.2484\n",
      "-11.4418\n",
      " -4.0641\n",
      " -4.8833\n",
      "  0.1445\n",
      "  0.8839\n",
      "  0.4531\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9887538539211048\n",
      "accepted True\n",
      "q \n",
      " 0.1382\n",
      " 0.8852\n",
      "-0.1685\n",
      " 0.0135\n",
      " 0.4734\n",
      " 0.3527\n",
      " 0.4588\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 287\n",
      "p \n",
      "  2.2948\n",
      " -5.7101\n",
      "-14.7808\n",
      " -0.5033\n",
      "-13.0144\n",
      " -2.5676\n",
      " -2.1383\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9855701722002613\n",
      "accepted True\n",
      "q \n",
      " 0.2695\n",
      " 0.9187\n",
      "-0.2382\n",
      " 0.1625\n",
      " 0.2917\n",
      " 0.3612\n",
      " 0.3496\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 288\n",
      "p \n",
      "  9.7720\n",
      " 12.8519\n",
      "  7.4192\n",
      " -7.3630\n",
      "  0.2689\n",
      "-15.2002\n",
      "  8.0466\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9971826499448571\n",
      "accepted True\n",
      "q \n",
      " 0.4060\n",
      " 1.1313\n",
      "-0.1445\n",
      "-0.0422\n",
      " 0.4521\n",
      " 0.2348\n",
      " 0.3118\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 289\n",
      "p \n",
      " -0.7942\n",
      "  0.1187\n",
      "-13.1002\n",
      "  7.7338\n",
      "  6.7378\n",
      " -1.2710\n",
      "  7.9456\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2827\n",
      " 1.1028\n",
      "-0.3267\n",
      " 0.0513\n",
      " 0.5469\n",
      " 0.2979\n",
      " 0.5044\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 290\n",
      "p \n",
      " -3.3095\n",
      "  6.2207\n",
      " -0.6341\n",
      "  2.9706\n",
      " -0.8801\n",
      " 11.4450\n",
      " -8.0422\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3822\n",
      " 1.1846\n",
      "-0.1910\n",
      " 0.1145\n",
      " 0.4492\n",
      " 0.5124\n",
      " 0.2248\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 291\n",
      "p \n",
      "-12.8431\n",
      "  8.4091\n",
      " 15.0102\n",
      " 15.3178\n",
      "  9.0800\n",
      "-14.7622\n",
      " -1.5401\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1692\n",
      " 1.1863\n",
      "-0.0082\n",
      " 0.2592\n",
      " 0.3850\n",
      " 0.3012\n",
      " 0.2812\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 292\n",
      "p \n",
      " 25.8381\n",
      "  1.2829\n",
      "  4.3158\n",
      " 13.6883\n",
      "  6.2595\n",
      " -4.7784\n",
      " 22.6255\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4547\n",
      " 1.1320\n",
      "-0.1049\n",
      " 0.2935\n",
      " 0.4424\n",
      " 0.3141\n",
      " 0.3924\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 293\n",
      "p \n",
      "-10.6866\n",
      "  7.8927\n",
      " -2.1414\n",
      " -4.0487\n",
      " -1.2905\n",
      "  2.6835\n",
      " -1.8859\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2520\n",
      " 1.1992\n",
      "-0.1221\n",
      " 0.1200\n",
      " 0.4616\n",
      " 0.4026\n",
      " 0.4004\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 294\n",
      "p \n",
      " 15.8669\n",
      "-11.5350\n",
      "  4.9015\n",
      "  8.0099\n",
      " 14.7941\n",
      " -7.2985\n",
      " -0.0135\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5993\n",
      " 0.9681\n",
      "-0.0628\n",
      " 0.0349\n",
      " 0.6833\n",
      " 0.3487\n",
      " 0.1429\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 295\n",
      "p \n",
      " 10.1627\n",
      "  1.3722\n",
      "  2.5842\n",
      "  1.7576\n",
      " -9.3608\n",
      " -4.0196\n",
      "  0.8134\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6455\n",
      " 1.0389\n",
      "-0.0192\n",
      " 0.1643\n",
      " 0.3931\n",
      " 0.3563\n",
      " 0.0664\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 296\n",
      "p \n",
      " -9.8374\n",
      " -2.3155\n",
      " -5.6957\n",
      "-25.4539\n",
      " -7.2420\n",
      " 10.8205\n",
      " -8.5202\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4526\n",
      " 1.0372\n",
      "-0.0478\n",
      "-0.2368\n",
      " 0.5685\n",
      " 0.5185\n",
      " 0.1243\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 297\n",
      "p \n",
      "  0.7425\n",
      " 15.3521\n",
      " -3.8370\n",
      "  3.6658\n",
      "  3.9161\n",
      "-14.3224\n",
      "  2.0430\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4248\n",
      " 1.2498\n",
      "-0.1545\n",
      "-0.1200\n",
      " 0.5794\n",
      " 0.3254\n",
      " 0.1971\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 298\n",
      "p \n",
      " 5.4238\n",
      " 8.4631\n",
      " 1.6412\n",
      "-2.7782\n",
      "-5.2955\n",
      " 4.0208\n",
      " 3.9835\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4709\n",
      " 1.2967\n",
      "-0.1141\n",
      "-0.0541\n",
      " 0.4759\n",
      " 0.4385\n",
      " 0.1962\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 299\n",
      "p \n",
      "-13.4808\n",
      " -7.6130\n",
      "  6.5308\n",
      "-11.6901\n",
      "  6.0366\n",
      "  2.1982\n",
      "-12.2617\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3365\n",
      " 1.0637\n",
      " 0.0278\n",
      "-0.2553\n",
      " 0.6674\n",
      " 0.4635\n",
      " 0.1334\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 300\n",
      "p \n",
      " 11.8822\n",
      "  9.3032\n",
      "  0.0975\n",
      " -2.3927\n",
      "-15.6341\n",
      " -3.0503\n",
      " 14.3950\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3909\n",
      " 1.1711\n",
      "-0.0449\n",
      "-0.0316\n",
      " 0.3498\n",
      " 0.4194\n",
      " 0.2781\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 301\n",
      "p \n",
      " -2.2043\n",
      " -0.1858\n",
      " -6.6745\n",
      " 10.3012\n",
      "  6.4473\n",
      " -7.9743\n",
      " -0.8091\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3403\n",
      " 1.1087\n",
      "-0.1618\n",
      " 0.1153\n",
      " 0.4238\n",
      " 0.3304\n",
      " 0.3033\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 302\n",
      "p \n",
      "-17.6128\n",
      "  7.9300\n",
      "  4.3568\n",
      "-13.2153\n",
      "  2.3371\n",
      "  4.3195\n",
      " -9.4224\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1938\n",
      " 1.1934\n",
      "-0.0551\n",
      "-0.1614\n",
      " 0.5903\n",
      " 0.4333\n",
      " 0.2633\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 303\n",
      "p \n",
      "  5.7925\n",
      "-16.7832\n",
      " -8.4121\n",
      "-17.9489\n",
      " -0.6527\n",
      "  8.2725\n",
      "  1.0878\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9849644670097006\n",
      "accepted True\n",
      "q \n",
      " 0.3638\n",
      " 0.9298\n",
      "-0.1332\n",
      "-0.3552\n",
      " 0.7554\n",
      " 0.5276\n",
      " 0.2838\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 304\n",
      "p \n",
      "  8.3065\n",
      " -3.2058\n",
      " -0.5289\n",
      "  6.2248\n",
      "  9.2631\n",
      " 10.1795\n",
      "  6.4953\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9985439659015416\n",
      "accepted True\n",
      "q \n",
      " 0.4650\n",
      " 0.9474\n",
      "-0.1582\n",
      "-0.2046\n",
      " 0.7760\n",
      " 0.6188\n",
      " 0.2911\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 305\n",
      "p \n",
      "  0.9363\n",
      "-22.2789\n",
      "  0.9248\n",
      " -2.8866\n",
      " -1.7770\n",
      "  0.1733\n",
      "  9.7561\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9916716277422616\n",
      "accepted True\n",
      "q \n",
      " 0.2879\n",
      " 0.6790\n",
      "-0.1122\n",
      "-0.1088\n",
      " 0.6331\n",
      " 0.5074\n",
      " 0.4821\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 306\n",
      "p \n",
      " 10.6289\n",
      "  1.7203\n",
      " 15.0235\n",
      "  4.3764\n",
      " -2.6543\n",
      " -3.8055\n",
      "  5.9316\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4353\n",
      " 0.8424\n",
      " 0.0532\n",
      " 0.0391\n",
      " 0.4455\n",
      " 0.4465\n",
      " 0.2944\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 307\n",
      "p \n",
      " 15.5872\n",
      " -7.3734\n",
      " -7.8721\n",
      "  3.3352\n",
      " -9.7799\n",
      "  7.2358\n",
      "  5.1573\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9947493126577877\n",
      "accepted True\n",
      "q \n",
      " 0.5963\n",
      " 0.8761\n",
      "-0.0707\n",
      " 0.1884\n",
      " 0.3007\n",
      " 0.5354\n",
      " 0.2186\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 308\n",
      "p \n",
      " 11.2013\n",
      " 15.8877\n",
      "  7.3946\n",
      "  1.2423\n",
      " 13.8545\n",
      " -3.7702\n",
      " 15.9036\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5862\n",
      " 1.1420\n",
      "-0.1202\n",
      "-0.0435\n",
      " 0.6364\n",
      " 0.4683\n",
      " 0.3552\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 309\n",
      "p \n",
      " -6.8281\n",
      "  3.2662\n",
      "-10.3297\n",
      "-13.7624\n",
      " -4.2650\n",
      "  7.3998\n",
      " -0.5436\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3758\n",
      " 1.1712\n",
      "-0.2152\n",
      "-0.2001\n",
      " 0.6556\n",
      " 0.5405\n",
      " 0.4114\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 310\n",
      "p \n",
      " 3.0501\n",
      "-0.8501\n",
      " 4.4932\n",
      " 6.6978\n",
      " 3.5984\n",
      " 0.3706\n",
      " 9.6624\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3154\n",
      " 1.0776\n",
      "-0.1511\n",
      "-0.0221\n",
      " 0.5660\n",
      " 0.4944\n",
      " 0.4687\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 311\n",
      "p \n",
      " -8.6363\n",
      "  3.6630\n",
      " 10.5394\n",
      " -1.7282\n",
      "  1.4756\n",
      " -2.3066\n",
      " -7.1967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2875\n",
      " 1.0997\n",
      " 0.0278\n",
      "-0.0318\n",
      " 0.5166\n",
      " 0.4470\n",
      " 0.2605\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 312\n",
      "p \n",
      "-1.6637\n",
      " 1.9144\n",
      " 3.7260\n",
      " 7.2626\n",
      " 7.5685\n",
      " 7.3019\n",
      "-3.5886\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3602\n",
      " 1.1126\n",
      " 0.0174\n",
      " 0.0434\n",
      " 0.5470\n",
      " 0.5447\n",
      " 0.1713\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 313\n",
      "p \n",
      " 10.3481\n",
      " -2.8368\n",
      "-13.2521\n",
      "  3.0711\n",
      "  1.7421\n",
      " -3.3595\n",
      "  6.3015\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4665\n",
      " 1.0650\n",
      "-0.2160\n",
      " 0.0640\n",
      " 0.5729\n",
      " 0.4530\n",
      " 0.2708\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 314\n",
      "p \n",
      "  1.6774\n",
      "  8.6842\n",
      "  6.1863\n",
      "-16.0086\n",
      "  5.5225\n",
      "  1.6658\n",
      " -3.3057\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5501\n",
      " 1.2065\n",
      "-0.0923\n",
      "-0.3073\n",
      " 0.8139\n",
      " 0.4920\n",
      " 0.1416\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 315\n",
      "p \n",
      "  7.3816\n",
      " -8.7251\n",
      " 21.4980\n",
      "  6.0894\n",
      "  7.7427\n",
      "  1.8008\n",
      " 18.8983\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3870\n",
      " 0.9392\n",
      " 0.0862\n",
      "-0.1556\n",
      " 0.7130\n",
      " 0.4831\n",
      " 0.3926\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 316\n",
      "p \n",
      "  3.8667\n",
      "-16.6137\n",
      " -2.2776\n",
      "  0.6658\n",
      " -8.5453\n",
      " -4.9312\n",
      "  2.6779\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3629\n",
      " 0.7646\n",
      " 0.0070\n",
      " 0.0592\n",
      " 0.4258\n",
      " 0.3880\n",
      " 0.3604\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 317\n",
      "p \n",
      " 11.1486\n",
      "  7.6752\n",
      " 11.8264\n",
      "  3.9965\n",
      "-10.4826\n",
      " -1.4045\n",
      " -5.0853\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6100\n",
      " 1.0057\n",
      " 0.1478\n",
      " 0.2212\n",
      " 0.1900\n",
      " 0.4255\n",
      " 0.0093\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 318\n",
      "p \n",
      "-13.3047\n",
      " -1.5888\n",
      " -3.6294\n",
      "  1.3527\n",
      " -4.3948\n",
      " -1.4239\n",
      " -4.9905\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3040\n",
      " 0.9899\n",
      " 0.0267\n",
      " 0.2257\n",
      " 0.2090\n",
      " 0.4020\n",
      " 0.1818\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 319\n",
      "p \n",
      " 11.1832\n",
      "  9.9776\n",
      " 17.3617\n",
      "  9.2009\n",
      " 14.8310\n",
      "  6.8183\n",
      "  8.3409\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4826\n",
      " 1.1337\n",
      " 0.1009\n",
      " 0.1177\n",
      " 0.4662\n",
      " 0.5223\n",
      " 0.1430\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 320\n",
      "p \n",
      "-8.8244\n",
      " 6.0800\n",
      " 2.9866\n",
      "-0.0985\n",
      " 2.5822\n",
      " 6.6230\n",
      " 0.9571\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2861\n",
      " 1.1729\n",
      " 0.0328\n",
      " 0.0542\n",
      " 0.5001\n",
      " 0.5667\n",
      " 0.2763\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 321\n",
      "p \n",
      " 13.7644\n",
      " -5.7541\n",
      "-15.0072\n",
      "  7.1750\n",
      " -4.5478\n",
      " -1.3106\n",
      "  2.8308\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5078\n",
      " 1.0647\n",
      "-0.1927\n",
      " 0.2205\n",
      " 0.3804\n",
      " 0.4901\n",
      " 0.2223\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 322\n",
      "p \n",
      " -2.8022\n",
      " -0.0904\n",
      "-10.8989\n",
      " -4.8431\n",
      "-17.2251\n",
      " -9.5556\n",
      "  2.6902\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9920555509193068\n",
      "accepted True\n",
      "q \n",
      " 0.3184\n",
      " 1.0655\n",
      "-0.2300\n",
      " 0.2476\n",
      " 0.1873\n",
      " 0.3412\n",
      " 0.3556\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 323\n",
      "p \n",
      "-11.2094\n",
      "-14.5383\n",
      " -9.5398\n",
      "  2.0262\n",
      "  1.9122\n",
      "  8.7344\n",
      " -1.1145\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9912448399334731\n",
      "accepted True\n",
      "q \n",
      " 0.1489\n",
      " 0.8659\n",
      "-0.2481\n",
      " 0.1852\n",
      " 0.3409\n",
      " 0.4664\n",
      " 0.4612\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 324\n",
      "p \n",
      " 5.1352\n",
      " 3.3887\n",
      " 5.1667\n",
      "-2.0599\n",
      "-1.4049\n",
      "-5.8831\n",
      " 6.4992\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9958516810090988\n",
      "accepted True\n",
      "q \n",
      " 0.2617\n",
      " 0.9749\n",
      "-0.1439\n",
      " 0.0864\n",
      " 0.3937\n",
      " 0.3892\n",
      " 0.4050\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 325\n",
      "p \n",
      "-15.2856\n",
      " -3.5668\n",
      "-20.6056\n",
      "-11.4918\n",
      " -0.0847\n",
      "-13.5606\n",
      "-12.1516\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9761296060564146\n",
      "accepted True\n",
      "q \n",
      " 0.1768\n",
      " 0.9973\n",
      "-0.3004\n",
      "-0.1003\n",
      " 0.5774\n",
      " 0.2466\n",
      " 0.3787\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 326\n",
      "p \n",
      "  3.9094\n",
      "  4.6328\n",
      " -1.4625\n",
      "  2.4722\n",
      " 18.5476\n",
      "  7.2190\n",
      "  9.5768\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2602\n",
      " 1.0844\n",
      "-0.3283\n",
      "-0.2233\n",
      " 0.8787\n",
      " 0.4089\n",
      " 0.4725\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 327\n",
      "p \n",
      " -2.6077\n",
      " 14.2701\n",
      " 10.8622\n",
      " -0.3554\n",
      "  2.5912\n",
      " 11.0040\n",
      "  2.6494\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2813\n",
      " 1.2685\n",
      "-0.1259\n",
      "-0.1618\n",
      " 0.7290\n",
      " 0.5747\n",
      " 0.3631\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 328\n",
      "p \n",
      " 12.1651\n",
      " -8.8702\n",
      "  5.2715\n",
      " -0.4880\n",
      " -3.9115\n",
      "  9.8678\n",
      " 13.5085\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3820\n",
      " 1.0186\n",
      "-0.0639\n",
      "-0.0455\n",
      " 0.5527\n",
      " 0.6299\n",
      " 0.4097\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 329\n",
      "p \n",
      "  9.8035\n",
      "-11.1476\n",
      " -6.5556\n",
      "-20.6279\n",
      " -7.8791\n",
      "  4.6280\n",
      "  7.9013\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9977399654169206\n",
      "accepted True\n",
      "q \n",
      " 0.4595\n",
      " 0.9140\n",
      "-0.1353\n",
      "-0.2931\n",
      " 0.6539\n",
      " 0.5921\n",
      " 0.4271\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 330\n",
      "p \n",
      "  2.6468\n",
      "-15.2077\n",
      "  0.0436\n",
      " 10.0998\n",
      "  7.5736\n",
      " -7.0088\n",
      "  1.0618\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4207\n",
      " 0.7586\n",
      "-0.1145\n",
      "-0.0383\n",
      " 0.6004\n",
      " 0.4249\n",
      " 0.3539\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 331\n",
      "p \n",
      " 6.3292\n",
      "-0.7640\n",
      " 1.5933\n",
      " 3.9507\n",
      "-6.1073\n",
      "-4.9910\n",
      "-2.2093\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9982579640401578\n",
      "accepted True\n",
      "q \n",
      " 0.5094\n",
      " 0.8882\n",
      "-0.0542\n",
      " 0.1253\n",
      " 0.3895\n",
      " 0.3836\n",
      " 0.1784\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 332\n",
      "p \n",
      " -5.6703\n",
      " -1.6799\n",
      " 12.0485\n",
      " -3.6599\n",
      "  0.6924\n",
      " -5.5029\n",
      "  3.5471\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9950414263526327\n",
      "accepted True\n",
      "q \n",
      " 0.3121\n",
      " 0.9061\n",
      " 0.0510\n",
      " 0.0195\n",
      " 0.4386\n",
      " 0.3439\n",
      " 0.2940\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 333\n",
      "p \n",
      " -2.4037\n",
      " -0.4348\n",
      "  8.9980\n",
      "  2.8947\n",
      " -3.4008\n",
      " -4.5810\n",
      " 15.1237\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1174\n",
      " 0.9249\n",
      " 0.0377\n",
      " 0.1056\n",
      " 0.3467\n",
      " 0.3226\n",
      " 0.5516\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 334\n",
      "p \n",
      "  4.0572\n",
      " -8.1460\n",
      " -0.6745\n",
      " 13.8218\n",
      "  9.7170\n",
      " -7.6420\n",
      "  6.7951\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2105\n",
      " 0.8590\n",
      "-0.0732\n",
      " 0.2017\n",
      " 0.4472\n",
      " 0.2844\n",
      " 0.5160\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 335\n",
      "p \n",
      " -2.4320\n",
      "  2.1475\n",
      "  6.0426\n",
      "  2.9181\n",
      " 12.5249\n",
      " -3.7411\n",
      " -3.8147\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3120\n",
      " 0.9626\n",
      "-0.0300\n",
      " 0.0372\n",
      " 0.6400\n",
      " 0.3191\n",
      " 0.3189\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 336\n",
      "p \n",
      " -2.4160\n",
      "-14.1865\n",
      "  1.1236\n",
      " 20.1528\n",
      " 10.8031\n",
      "-18.9550\n",
      " 11.6811\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9812318288418158\n",
      "accepted True\n",
      "q \n",
      " 0.1230\n",
      " 0.7779\n",
      "-0.1186\n",
      " 0.2720\n",
      " 0.5432\n",
      " 0.1393\n",
      " 0.5803\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 337\n",
      "p \n",
      " 10.5712\n",
      " -2.5705\n",
      "  5.4204\n",
      "  1.7165\n",
      " -8.7322\n",
      "  5.4083\n",
      " -1.3532\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4219\n",
      " 0.8692\n",
      " 0.0045\n",
      " 0.2785\n",
      " 0.3248\n",
      " 0.3496\n",
      " 0.2264\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 338\n",
      "p \n",
      "  7.3409\n",
      "  1.4651\n",
      " -3.7007\n",
      " -2.8150\n",
      "-10.4862\n",
      "  8.0816\n",
      " 16.4456\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3383\n",
      " 0.9634\n",
      "-0.1077\n",
      " 0.2246\n",
      " 0.2678\n",
      " 0.4749\n",
      " 0.4557\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 339\n",
      "p \n",
      " -3.3840\n",
      " -5.7170\n",
      " 14.2986\n",
      " -9.0046\n",
      "  0.0108\n",
      "  2.2758\n",
      "  7.9824\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2130\n",
      " 0.8909\n",
      " 0.0457\n",
      "-0.0249\n",
      " 0.4264\n",
      " 0.4772\n",
      " 0.5032\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 340\n",
      "p \n",
      " -0.2182\n",
      "-17.7082\n",
      " -1.7871\n",
      "  2.8993\n",
      " -8.1073\n",
      "  5.5166\n",
      " -4.8745\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3077\n",
      " 0.7501\n",
      " 0.0348\n",
      " 0.1607\n",
      " 0.2709\n",
      " 0.5194\n",
      " 0.2971\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 341\n",
      "p \n",
      " 10.3122\n",
      "  1.8898\n",
      " 14.3550\n",
      " 11.9032\n",
      " -1.8218\n",
      " -9.2627\n",
      "  7.3561\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.998082690039042\n",
      "accepted True\n",
      "q \n",
      " 0.4127\n",
      " 0.8837\n",
      " 0.1169\n",
      " 0.3102\n",
      " 0.1803\n",
      " 0.3948\n",
      " 0.2320\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 342\n",
      "p \n",
      " 5.5576\n",
      " 7.2152\n",
      "-1.5618\n",
      " 4.5760\n",
      " 7.6262\n",
      " 0.4740\n",
      "-0.2363\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5186\n",
      " 1.0581\n",
      "-0.0156\n",
      " 0.1755\n",
      " 0.4110\n",
      " 0.4302\n",
      " 0.1596\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 343\n",
      "p \n",
      " -9.8286\n",
      "-12.3735\n",
      "-18.6110\n",
      " -0.7259\n",
      " -7.1617\n",
      "  4.1333\n",
      " -8.5039\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3291\n",
      " 0.9133\n",
      "-0.1912\n",
      " 0.2025\n",
      " 0.3411\n",
      " 0.4638\n",
      " 0.2393\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 344\n",
      "p \n",
      " -6.1261\n",
      "  4.3831\n",
      " -4.8014\n",
      "  3.7693\n",
      "  8.1831\n",
      " -9.2455\n",
      "-14.4811\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9925565179410766\n",
      "accepted True\n",
      "q \n",
      " 0.4096\n",
      " 1.0524\n",
      "-0.1754\n",
      " 0.1192\n",
      " 0.4929\n",
      " 0.3580\n",
      " 0.0642\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 345\n",
      "p \n",
      "-1.7393\n",
      "-1.7428\n",
      "-2.9967\n",
      " 3.2079\n",
      "-5.6696\n",
      "-2.7350\n",
      "-0.3738\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9984157726640294\n",
      "accepted True\n",
      "q \n",
      " 0.3486\n",
      " 1.0298\n",
      "-0.1481\n",
      " 0.2039\n",
      " 0.3492\n",
      " 0.3619\n",
      " 0.1625\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 346\n",
      "p \n",
      "-13.1704\n",
      " -6.6684\n",
      " -3.0948\n",
      " -0.8064\n",
      "  2.0854\n",
      "  3.7007\n",
      " -2.2368\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9921486276662117\n",
      "accepted True\n",
      "q \n",
      " 0.1610\n",
      " 0.9422\n",
      "-0.1417\n",
      " 0.1108\n",
      " 0.4375\n",
      " 0.4256\n",
      " 0.3207\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 347\n",
      "p \n",
      " 22.2675\n",
      " 18.2201\n",
      " 16.7152\n",
      "  9.5686\n",
      "  6.0167\n",
      " 17.2044\n",
      " 26.2910\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3848\n",
      " 1.2133\n",
      "-0.0679\n",
      " 0.1284\n",
      " 0.4792\n",
      " 0.6642\n",
      " 0.4232\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 348\n",
      "p \n",
      "  9.2515\n",
      "  2.0738\n",
      " 19.5558\n",
      " -0.5846\n",
      "  6.0298\n",
      "  5.2663\n",
      " 12.1857\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4479\n",
      " 1.1445\n",
      " 0.1065\n",
      "-0.0310\n",
      " 0.5929\n",
      " 0.6482\n",
      " 0.3779\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 349\n",
      "p \n",
      "  1.5699\n",
      "-15.5117\n",
      "  0.0826\n",
      " -7.3237\n",
      "  0.3899\n",
      " -4.8295\n",
      "  0.3923\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4051\n",
      " 0.8629\n",
      " 0.0284\n",
      "-0.1274\n",
      " 0.6224\n",
      " 0.4618\n",
      " 0.3360\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 350\n",
      "p \n",
      "  3.2402\n",
      " -0.4241\n",
      " -0.2663\n",
      " -0.3330\n",
      "  1.7978\n",
      "-12.3852\n",
      "  0.0196\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4358\n",
      " 0.9425\n",
      "-0.0339\n",
      "-0.0787\n",
      " 0.5950\n",
      " 0.3118\n",
      " 0.2702\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 351\n",
      "p \n",
      "  6.1594\n",
      "-11.2415\n",
      "  0.3248\n",
      " 24.9330\n",
      "  8.1255\n",
      " 12.7290\n",
      "-10.9142\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9960879514278596\n",
      "accepted True\n",
      "q \n",
      " 0.6229\n",
      " 0.8706\n",
      "-0.0096\n",
      " 0.3186\n",
      " 0.4171\n",
      " 0.5328\n",
      "-0.0220\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 352\n",
      "p \n",
      " -0.8741\n",
      " 11.5798\n",
      " -0.3614\n",
      " -2.7913\n",
      "  7.1603\n",
      "  1.7876\n",
      " 11.1904\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4188\n",
      " 1.0730\n",
      "-0.1244\n",
      " 0.0544\n",
      " 0.6194\n",
      " 0.5118\n",
      " 0.2796\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 353\n",
      "p \n",
      "  2.9729\n",
      "  3.4439\n",
      "  4.2408\n",
      "-17.9090\n",
      " -5.5310\n",
      "  1.4762\n",
      "  2.3234\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4468\n",
      " 1.1229\n",
      "-0.0460\n",
      "-0.2209\n",
      " 0.6519\n",
      " 0.5048\n",
      " 0.2496\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 354\n",
      "p \n",
      "  1.1253\n",
      "  0.9499\n",
      "-13.2973\n",
      "-12.3485\n",
      "  0.3380\n",
      "-18.4908\n",
      "  2.6888\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3886\n",
      " 1.1245\n",
      "-0.2413\n",
      "-0.3186\n",
      " 0.7564\n",
      " 0.2470\n",
      " 0.3757\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 355\n",
      "p \n",
      "-13.1214\n",
      "  2.9234\n",
      "  4.2118\n",
      "-13.5847\n",
      "  1.5433\n",
      "  2.7799\n",
      "-20.4756\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4078\n",
      " 1.1617\n",
      "-0.0413\n",
      "-0.3637\n",
      " 0.7437\n",
      " 0.3864\n",
      " 0.0536\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 356\n",
      "p \n",
      " -3.6486\n",
      " -6.7182\n",
      " -3.5849\n",
      " 11.1230\n",
      "  1.4944\n",
      "-17.6347\n",
      "  4.3951\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9878384385736096\n",
      "accepted True\n",
      "q \n",
      " 0.2484\n",
      " 0.9670\n",
      "-0.1210\n",
      "-0.0101\n",
      " 0.5279\n",
      " 0.1889\n",
      " 0.2852\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 357\n",
      "p \n",
      "  5.6326\n",
      "  0.3785\n",
      " -9.5754\n",
      "-15.2269\n",
      "-11.9964\n",
      " -2.9863\n",
      "  5.7818\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9925226784381393\n",
      "accepted True\n",
      "q \n",
      " 0.3241\n",
      " 1.0326\n",
      "-0.1975\n",
      "-0.1221\n",
      " 0.4943\n",
      " 0.2647\n",
      " 0.3511\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 358\n",
      "p \n",
      "  7.1632\n",
      "  4.6270\n",
      " -5.4143\n",
      " -1.9724\n",
      "-22.1420\n",
      "-12.8726\n",
      "  0.6655\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9796146221377764\n",
      "accepted True\n",
      "q \n",
      " 0.4200\n",
      " 1.1268\n",
      "-0.1547\n",
      " 0.1481\n",
      " 0.1416\n",
      " 0.2102\n",
      " 0.2360\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 359\n",
      "p \n",
      "  8.6807\n",
      "  1.8206\n",
      "-16.7017\n",
      " -5.3037\n",
      " -3.9940\n",
      "  0.9671\n",
      "  0.7997\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.998845052612803\n",
      "accepted True\n",
      "q \n",
      " 0.5393\n",
      " 1.1667\n",
      "-0.3023\n",
      " 0.0442\n",
      " 0.3370\n",
      " 0.3246\n",
      " 0.2162\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 360\n",
      "p \n",
      "-24.2395\n",
      "-11.6727\n",
      "-17.6510\n",
      "  1.9691\n",
      "  1.2514\n",
      " -6.5042\n",
      "-42.8414\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9822377179761341\n",
      "accepted True\n",
      "q \n",
      " 0.4738\n",
      " 1.0155\n",
      "-0.2164\n",
      " 0.1321\n",
      " 0.3664\n",
      " 0.3144\n",
      "-0.1975\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 361\n",
      "p \n",
      "-3.5253\n",
      " 3.0272\n",
      "-4.1242\n",
      "-2.3988\n",
      " 0.6280\n",
      "-3.6251\n",
      "-5.1451\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9938795580712241\n",
      "accepted True\n",
      "q \n",
      " 0.4299\n",
      " 1.0774\n",
      "-0.1896\n",
      " 0.0531\n",
      " 0.4466\n",
      " 0.3305\n",
      "-0.0494\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 362\n",
      "p \n",
      "-11.6567\n",
      "-15.3299\n",
      "  5.8155\n",
      "-10.5297\n",
      "  3.8224\n",
      "  8.9815\n",
      " -2.7663\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9803083022953977\n",
      "accepted True\n",
      "q \n",
      " 0.2436\n",
      " 0.8465\n",
      "-0.0465\n",
      "-0.1444\n",
      " 0.5984\n",
      " 0.4654\n",
      " 0.1665\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 363\n",
      "p \n",
      " -6.2553\n",
      " -0.7267\n",
      " -8.2733\n",
      "  0.8248\n",
      "-16.5204\n",
      " -8.8203\n",
      " -3.0543\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9648805331557653\n",
      "accepted True\n",
      "q \n",
      " 0.1975\n",
      " 0.9281\n",
      "-0.0997\n",
      " 0.1307\n",
      " 0.2501\n",
      " 0.3473\n",
      " 0.2250\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 364\n",
      "p \n",
      "  5.4478\n",
      "  8.6103\n",
      " 12.4915\n",
      "-13.3405\n",
      " -4.9535\n",
      " 18.9896\n",
      " 11.7404\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2749\n",
      " 1.0798\n",
      " 0.0139\n",
      "-0.0965\n",
      " 0.3775\n",
      " 0.6042\n",
      " 0.3044\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 365\n",
      "p \n",
      "-11.1825\n",
      " -8.8133\n",
      " -1.3617\n",
      " 15.8616\n",
      " 12.6678\n",
      "  1.0128\n",
      "-14.5721\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2822\n",
      " 0.9421\n",
      "-0.0141\n",
      " 0.1318\n",
      " 0.4471\n",
      " 0.5347\n",
      " 0.1376\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 366\n",
      "p \n",
      " 3.6165\n",
      "-1.1302\n",
      " 0.2957\n",
      "-2.7260\n",
      "-3.9818\n",
      " 1.5163\n",
      " 0.5587\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3752\n",
      " 0.9844\n",
      "-0.0277\n",
      " 0.0833\n",
      " 0.4217\n",
      " 0.5141\n",
      " 0.1482\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 367\n",
      "p \n",
      " -2.3293\n",
      "  0.2819\n",
      "-10.7399\n",
      "  6.0053\n",
      " -4.7452\n",
      "  9.4549\n",
      " -6.8339\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9986808663594902\n",
      "accepted True\n",
      "q \n",
      " 0.4032\n",
      " 1.0567\n",
      "-0.1321\n",
      " 0.2306\n",
      " 0.3115\n",
      " 0.5980\n",
      " 0.1115\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 368\n",
      "p \n",
      " 1.0127\n",
      " 2.2177\n",
      " 2.6507\n",
      " 6.4676\n",
      "-1.6097\n",
      " 5.8926\n",
      "-2.2147\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4362\n",
      " 1.0980\n",
      "-0.0660\n",
      " 0.2764\n",
      " 0.2747\n",
      " 0.6108\n",
      " 0.0861\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 369\n",
      "p \n",
      " 11.1255\n",
      "  1.9498\n",
      "  6.9559\n",
      "-12.2534\n",
      "-15.0017\n",
      "  6.1645\n",
      "  4.5613\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5580\n",
      " 1.1225\n",
      " 0.0441\n",
      " 0.1020\n",
      " 0.2295\n",
      " 0.6239\n",
      " 0.0641\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 370\n",
      "p \n",
      " 6.4593\n",
      " 3.8725\n",
      " 0.1035\n",
      " 1.7899\n",
      "-0.9978\n",
      " 5.1428\n",
      " 8.0918\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5120\n",
      " 1.1496\n",
      "-0.0448\n",
      " 0.1010\n",
      " 0.3220\n",
      " 0.6117\n",
      " 0.2047\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 371\n",
      "p \n",
      "  7.1003\n",
      " -2.5512\n",
      "  3.7735\n",
      "  4.4339\n",
      "  6.0060\n",
      "-18.4142\n",
      " 10.1981\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4355\n",
      " 1.0305\n",
      "-0.0821\n",
      " 0.0654\n",
      " 0.4670\n",
      " 0.2981\n",
      " 0.3485\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 372\n",
      "p \n",
      " -9.1410\n",
      "  0.9837\n",
      " -1.9259\n",
      "-12.4700\n",
      " -9.5371\n",
      " -3.2331\n",
      "-13.3273\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3885\n",
      " 1.0714\n",
      "-0.0233\n",
      "-0.0384\n",
      " 0.4059\n",
      " 0.3335\n",
      " 0.1480\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 373\n",
      "p \n",
      "  1.6239\n",
      " -7.9826\n",
      "  8.6031\n",
      "  8.3126\n",
      " 13.6339\n",
      " -4.2847\n",
      " -6.1215\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.992175121246537\n",
      "accepted True\n",
      "q \n",
      " 0.4764\n",
      " 0.9523\n",
      " 0.0431\n",
      "-0.0048\n",
      " 0.5681\n",
      " 0.3439\n",
      " 0.0521\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 374\n",
      "p \n",
      " -4.7236\n",
      "  5.5363\n",
      " 16.7696\n",
      "  0.9117\n",
      "  2.2150\n",
      "  5.8815\n",
      "  7.5162\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2968\n",
      " 1.0314\n",
      " 0.1421\n",
      "-0.0035\n",
      " 0.5146\n",
      " 0.4572\n",
      " 0.2308\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 375\n",
      "p \n",
      " -1.2824\n",
      "-24.2984\n",
      "  2.3931\n",
      " -4.2669\n",
      "  1.1950\n",
      " -6.3009\n",
      " -2.4108\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9728389302216918\n",
      "accepted True\n",
      "q \n",
      " 0.3003\n",
      " 0.7136\n",
      " 0.0897\n",
      "-0.0503\n",
      " 0.5512\n",
      " 0.3632\n",
      " 0.2553\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 376\n",
      "p \n",
      " 11.8694\n",
      "  9.7132\n",
      "  7.3897\n",
      "  8.6658\n",
      "  1.9409\n",
      " -7.1976\n",
      " 11.5304\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9836413633433577\n",
      "accepted True\n",
      "q \n",
      " 0.4107\n",
      " 0.9519\n",
      " 0.0396\n",
      " 0.0793\n",
      " 0.4704\n",
      " 0.3243\n",
      " 0.2796\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 377\n",
      "p \n",
      " 6.0825\n",
      "-0.8325\n",
      " 8.9509\n",
      " 3.8945\n",
      " 9.0586\n",
      "-2.3760\n",
      " 9.9623\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4041\n",
      " 0.9658\n",
      " 0.0249\n",
      " 0.0091\n",
      " 0.6016\n",
      " 0.3532\n",
      " 0.3559\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 378\n",
      "p \n",
      " -2.7266\n",
      " -2.5227\n",
      "-14.0508\n",
      " -5.2838\n",
      " -2.6653\n",
      "  4.9844\n",
      "  3.4972\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2950\n",
      " 0.9844\n",
      "-0.1922\n",
      "-0.0352\n",
      " 0.5868\n",
      " 0.4380\n",
      " 0.4640\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 379\n",
      "p \n",
      "-10.1162\n",
      "  3.2173\n",
      "  8.6947\n",
      " -3.7408\n",
      " -8.1184\n",
      "  9.4689\n",
      " -9.8853\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2785\n",
      " 1.0579\n",
      " 0.0245\n",
      " 0.0415\n",
      " 0.3676\n",
      " 0.5573\n",
      " 0.2141\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 380\n",
      "p \n",
      " -1.8891\n",
      " -6.9500\n",
      "  6.0891\n",
      "  8.7714\n",
      " -0.5023\n",
      "-18.1708\n",
      " -4.5248\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9870003465262891\n",
      "accepted True\n",
      "q \n",
      " 0.3007\n",
      " 0.9394\n",
      " 0.0629\n",
      " 0.2048\n",
      " 0.2838\n",
      " 0.2891\n",
      " 0.1619\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 381\n",
      "p \n",
      " -5.2310\n",
      "  5.9229\n",
      " 13.5943\n",
      " 12.8516\n",
      " 20.4233\n",
      "  2.5890\n",
      "  4.5026\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2337\n",
      " 1.0268\n",
      " 0.0748\n",
      " 0.1263\n",
      " 0.5547\n",
      " 0.3841\n",
      " 0.2725\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 382\n",
      "p \n",
      "  4.7838\n",
      " -2.2391\n",
      " -0.0078\n",
      "  5.4805\n",
      "  1.7502\n",
      " 10.4366\n",
      "  3.2401\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3516\n",
      " 1.0137\n",
      "-0.0069\n",
      " 0.1579\n",
      " 0.5006\n",
      " 0.5397\n",
      " 0.2542\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 383\n",
      "p \n",
      " 10.4658\n",
      "  3.9418\n",
      "  5.2203\n",
      "  0.0202\n",
      " -6.5275\n",
      "-19.3744\n",
      "  2.6911\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4919\n",
      " 1.0787\n",
      " 0.0152\n",
      " 0.1604\n",
      " 0.3635\n",
      " 0.2707\n",
      " 0.1606\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 384\n",
      "p \n",
      "-2.4379\n",
      " 8.6187\n",
      "-6.5316\n",
      " 6.2072\n",
      " 8.8698\n",
      "-1.5067\n",
      "-7.0530\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5002\n",
      " 1.2088\n",
      "-0.1153\n",
      " 0.1181\n",
      " 0.5192\n",
      " 0.3375\n",
      " 0.1015\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 385\n",
      "p \n",
      "-11.1068\n",
      "-20.2803\n",
      "  3.5319\n",
      " -8.4798\n",
      "  2.2908\n",
      "  5.9467\n",
      " -6.4980\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2957\n",
      " 0.8307\n",
      "-0.0015\n",
      "-0.0714\n",
      " 0.5959\n",
      " 0.4416\n",
      " 0.1981\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 386\n",
      "p \n",
      " 18.4814\n",
      " 20.1467\n",
      "  2.4459\n",
      " -9.1005\n",
      " -0.9421\n",
      "  4.6431\n",
      " 15.9686\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5189\n",
      " 1.1968\n",
      "-0.0839\n",
      "-0.2220\n",
      " 0.6800\n",
      " 0.5196\n",
      " 0.2549\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 387\n",
      "p \n",
      "-10.9544\n",
      "  7.9745\n",
      "  3.3581\n",
      " -2.4021\n",
      "  6.6228\n",
      " -0.9206\n",
      " -3.4036\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3190\n",
      " 1.2393\n",
      "-0.0627\n",
      "-0.2156\n",
      " 0.7139\n",
      " 0.4746\n",
      " 0.2873\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 388\n",
      "p \n",
      " -2.4818\n",
      " -1.8427\n",
      "-11.2711\n",
      " -2.1980\n",
      "  1.8054\n",
      " -4.7701\n",
      "  1.2237\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2775\n",
      " 1.1324\n",
      "-0.2194\n",
      "-0.1472\n",
      " 0.6847\n",
      " 0.3895\n",
      " 0.3805\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 389\n",
      "p \n",
      " -2.0545\n",
      "-11.3745\n",
      "  2.8568\n",
      " 10.0953\n",
      " -2.9268\n",
      " -0.4231\n",
      " -2.2650\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2798\n",
      " 0.9137\n",
      "-0.0840\n",
      " 0.1656\n",
      " 0.3904\n",
      " 0.4002\n",
      " 0.2834\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 390\n",
      "p \n",
      "-0.9933\n",
      "-8.3154\n",
      "-9.3216\n",
      " 9.1762\n",
      " 0.4037\n",
      " 3.2464\n",
      " 0.4346\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.993773020933003\n",
      "accepted True\n",
      "q \n",
      " 0.2792\n",
      " 0.8813\n",
      "-0.1801\n",
      " 0.2676\n",
      " 0.3626\n",
      " 0.4492\n",
      " 0.3275\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 391\n",
      "p \n",
      "-13.9075\n",
      " -4.5980\n",
      "  3.4545\n",
      " 18.9346\n",
      " 15.8470\n",
      " -4.7541\n",
      "-13.3671\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9905895920548223\n",
      "accepted True\n",
      "q \n",
      " 0.2320\n",
      " 0.8905\n",
      "-0.0913\n",
      " 0.3385\n",
      " 0.4479\n",
      " 0.3938\n",
      " 0.1936\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 392\n",
      "p \n",
      "-1.2326\n",
      " 1.1399\n",
      " 5.7278\n",
      "-3.0162\n",
      "-3.8915\n",
      " 0.3670\n",
      " 3.9687\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2335\n",
      " 0.9584\n",
      "-0.0262\n",
      " 0.1908\n",
      " 0.4044\n",
      " 0.4166\n",
      " 0.2665\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 393\n",
      "p \n",
      "-5.5628\n",
      "-5.1000\n",
      "-2.0853\n",
      "-0.6495\n",
      " 5.3732\n",
      " 3.7192\n",
      " 9.0927\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1074\n",
      " 0.9154\n",
      "-0.1216\n",
      " 0.0533\n",
      " 0.5514\n",
      " 0.4548\n",
      " 0.5090\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 394\n",
      "p \n",
      " 12.5705\n",
      " -1.2190\n",
      " -5.0100\n",
      " -7.2159\n",
      "-13.1029\n",
      " 18.6684\n",
      "  6.4267\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3743\n",
      " 0.9940\n",
      "-0.1352\n",
      " 0.0528\n",
      " 0.3978\n",
      " 0.6786\n",
      " 0.3610\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 395\n",
      "p \n",
      " -7.9963\n",
      " -4.9420\n",
      "-11.3971\n",
      "  1.4158\n",
      " -2.1374\n",
      "-10.1682\n",
      "  0.3965\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1950\n",
      " 0.9462\n",
      "-0.2366\n",
      " 0.1093\n",
      " 0.3933\n",
      " 0.4179\n",
      " 0.4659\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 396\n",
      "p \n",
      " -6.4363\n",
      " -7.8544\n",
      " -0.9185\n",
      " -5.4541\n",
      "-12.1591\n",
      " -1.2112\n",
      "  2.9063\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9878091757667097\n",
      "accepted True\n",
      "q \n",
      " 0.1108\n",
      " 0.8862\n",
      "-0.1414\n",
      " 0.1243\n",
      " 0.2697\n",
      " 0.4013\n",
      " 0.4973\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 397\n",
      "p \n",
      " -4.1398\n",
      " -4.6296\n",
      " 10.5901\n",
      " -0.5122\n",
      "  5.3210\n",
      " -6.0688\n",
      "  9.9381\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.99420386022283\n",
      "accepted True\n",
      "q \n",
      " 0.0477\n",
      " 0.8614\n",
      "-0.0521\n",
      " 0.0174\n",
      " 0.4331\n",
      " 0.3391\n",
      " 0.5991\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 398\n",
      "p \n",
      "  9.9619\n",
      "  1.8952\n",
      "-16.4371\n",
      " 11.6046\n",
      " -8.6099\n",
      "  8.8527\n",
      "  0.9518\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3304\n",
      " 1.0030\n",
      "-0.2263\n",
      " 0.3165\n",
      " 0.2262\n",
      " 0.4906\n",
      " 0.3709\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 399\n",
      "p \n",
      "  9.5292\n",
      "  8.5509\n",
      "  5.3783\n",
      " -3.0946\n",
      "  6.1513\n",
      "  1.4143\n",
      " 12.0184\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4160\n",
      " 1.1306\n",
      "-0.1813\n",
      " 0.0468\n",
      " 0.4937\n",
      " 0.4949\n",
      " 0.4044\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 400\n",
      "p \n",
      " 11.9621\n",
      " -3.1310\n",
      " -3.3546\n",
      "  3.0110\n",
      "  8.1205\n",
      "  2.2176\n",
      "  0.8243\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6271\n",
      " 1.0810\n",
      "-0.1926\n",
      "-0.0136\n",
      " 0.6523\n",
      " 0.5153\n",
      " 0.2192\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 401\n",
      "p \n",
      "  9.7091\n",
      "  8.2747\n",
      "  0.9734\n",
      " -2.7990\n",
      " -7.2083\n",
      " -2.5945\n",
      " 12.3725\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5480\n",
      " 1.1858\n",
      "-0.1743\n",
      " 0.0193\n",
      " 0.4905\n",
      " 0.4564\n",
      " 0.3344\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 402\n",
      "p \n",
      " -4.3878\n",
      " -3.0300\n",
      " 12.8235\n",
      " -6.9046\n",
      "  8.2879\n",
      "  0.7174\n",
      " -1.5649\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4268\n",
      " 1.0532\n",
      " 0.0145\n",
      "-0.1918\n",
      " 0.6787\n",
      " 0.4604\n",
      " 0.2668\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 403\n",
      "p \n",
      "-2.3185\n",
      " 1.1420\n",
      "-4.2886\n",
      " 3.6741\n",
      " 6.5067\n",
      " 1.2092\n",
      "-0.1059\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3741\n",
      " 1.0727\n",
      "-0.1005\n",
      "-0.0956\n",
      " 0.6785\n",
      " 0.4659\n",
      " 0.2946\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 404\n",
      "p \n",
      " -1.9344\n",
      " -3.4756\n",
      "  6.7175\n",
      " 13.5597\n",
      " 11.8407\n",
      " 11.2397\n",
      "  4.9979\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3026\n",
      " 0.9985\n",
      "-0.0603\n",
      " 0.0671\n",
      " 0.6508\n",
      " 0.5939\n",
      " 0.3559\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 405\n",
      "p \n",
      " -1.6357\n",
      " 11.8644\n",
      " -5.7961\n",
      " -2.9970\n",
      " -0.2960\n",
      " -7.8629\n",
      "  0.8979\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3061\n",
      " 1.1962\n",
      "-0.1676\n",
      "-0.0013\n",
      " 0.6090\n",
      " 0.4283\n",
      " 0.3497\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 406\n",
      "p \n",
      " -0.3330\n",
      "-10.5082\n",
      " -1.5265\n",
      " -5.9685\n",
      " -4.4806\n",
      " -2.0531\n",
      " -2.9815\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3458\n",
      " 0.9760\n",
      "-0.0971\n",
      "-0.0270\n",
      " 0.5210\n",
      " 0.4018\n",
      " 0.2644\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 407\n",
      "p \n",
      " 11.6660\n",
      " -0.8012\n",
      "  5.6519\n",
      "  0.2354\n",
      "-10.1351\n",
      "-11.7809\n",
      "  5.9280\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9907389839827762\n",
      "accepted True\n",
      "q \n",
      " 0.4635\n",
      " 0.9963\n",
      "-0.0219\n",
      " 0.1020\n",
      " 0.3209\n",
      " 0.2941\n",
      " 0.2134\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 408\n",
      "p \n",
      "-11.6988\n",
      "  2.2930\n",
      " -0.3267\n",
      "  3.0007\n",
      " 19.6015\n",
      " 19.0259\n",
      "  8.9757\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1747\n",
      " 1.0201\n",
      "-0.1437\n",
      "-0.0914\n",
      " 0.7074\n",
      " 0.5578\n",
      " 0.5220\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 409\n",
      "p \n",
      " 12.6851\n",
      "  3.5617\n",
      " 23.0293\n",
      "  0.2118\n",
      "  8.3694\n",
      " -0.4445\n",
      " 23.3450\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2454\n",
      " 1.0389\n",
      " 0.0343\n",
      "-0.1776\n",
      " 0.7656\n",
      " 0.5139\n",
      " 0.6315\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 410\n",
      "p \n",
      " -2.0811\n",
      " -1.3766\n",
      "  8.7661\n",
      " -8.6827\n",
      "-10.4282\n",
      " 12.5693\n",
      "  5.9333\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2047\n",
      " 1.0154\n",
      " 0.0983\n",
      "-0.1082\n",
      " 0.4919\n",
      " 0.6312\n",
      " 0.5325\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 411\n",
      "p \n",
      " 10.0224\n",
      "  6.0489\n",
      " 18.4128\n",
      " 13.0894\n",
      "  5.8984\n",
      "  2.8367\n",
      "  6.3885\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4145\n",
      " 1.0972\n",
      " 0.1977\n",
      " 0.1056\n",
      " 0.4189\n",
      " 0.6118\n",
      " 0.2935\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 412\n",
      "p \n",
      " -0.1754\n",
      "  1.0068\n",
      " -1.1221\n",
      "  1.7440\n",
      " -0.9694\n",
      " -8.2364\n",
      " 14.0480\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2009\n",
      " 1.0515\n",
      "-0.0240\n",
      " 0.1066\n",
      " 0.4160\n",
      " 0.4036\n",
      " 0.5762\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 413\n",
      "p \n",
      "  4.5950\n",
      "  1.3424\n",
      "  0.5059\n",
      " -1.2904\n",
      "-14.4571\n",
      " -4.9893\n",
      " 13.8046\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1659\n",
      " 1.0622\n",
      "-0.0671\n",
      " 0.2058\n",
      " 0.2010\n",
      " 0.3532\n",
      " 0.6452\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 414\n",
      "p \n",
      " 7.7933\n",
      "-6.4206\n",
      " 4.9316\n",
      " 2.6230\n",
      " 2.0363\n",
      "-3.9208\n",
      " 6.0146\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3284\n",
      " 0.9544\n",
      "-0.0357\n",
      " 0.1390\n",
      " 0.3428\n",
      " 0.3505\n",
      " 0.4591\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 415\n",
      "p \n",
      "  7.2891\n",
      "  3.8215\n",
      " 16.8988\n",
      "-10.4456\n",
      "-12.3327\n",
      " 17.9028\n",
      "  5.8578\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4415\n",
      " 1.0531\n",
      " 0.1649\n",
      " 0.0323\n",
      " 0.2596\n",
      " 0.6225\n",
      " 0.2794\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 416\n",
      "p \n",
      "-4.6318\n",
      "-6.4950\n",
      "-0.8729\n",
      " 0.4039\n",
      "-7.5956\n",
      "-2.3761\n",
      " 1.3038\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2775\n",
      " 0.9479\n",
      " 0.0549\n",
      " 0.1376\n",
      " 0.2115\n",
      " 0.4893\n",
      " 0.3502\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 417\n",
      "p \n",
      " -1.3406\n",
      "-10.2269\n",
      " -2.1975\n",
      "  0.9418\n",
      " -0.9208\n",
      "  7.2376\n",
      "  8.0877\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9991296743024222\n",
      "accepted True\n",
      "q \n",
      " 0.1957\n",
      " 0.8528\n",
      "-0.0481\n",
      " 0.1195\n",
      " 0.3205\n",
      " 0.5366\n",
      " 0.4904\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 418\n",
      "p \n",
      " 8.1987\n",
      " 0.3726\n",
      " 4.3608\n",
      "-5.7368\n",
      "-2.0163\n",
      " 7.8405\n",
      " 1.0621\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4230\n",
      " 0.9594\n",
      "-0.0021\n",
      "-0.0057\n",
      " 0.4199\n",
      " 0.6005\n",
      " 0.2721\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 419\n",
      "p \n",
      "  7.0665\n",
      "  5.5030\n",
      " -5.0862\n",
      " 14.9860\n",
      " 17.2570\n",
      " -8.4970\n",
      " 11.1242\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4147\n",
      " 1.0605\n",
      "-0.2080\n",
      " 0.0605\n",
      " 0.6431\n",
      " 0.4303\n",
      " 0.4192\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 420\n",
      "p \n",
      "-21.0827\n",
      " -1.9898\n",
      "  4.1218\n",
      " 16.5475\n",
      " 11.1068\n",
      "  1.7539\n",
      " -7.4253\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0986\n",
      " 0.9954\n",
      "-0.1057\n",
      " 0.2520\n",
      " 0.5216\n",
      " 0.4444\n",
      " 0.4161\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 421\n",
      "p \n",
      "  2.4966\n",
      "  0.6157\n",
      " 12.2667\n",
      " -9.8608\n",
      " -7.8510\n",
      "  5.8601\n",
      "  6.0322\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2100\n",
      " 1.0088\n",
      " 0.0548\n",
      " 0.0549\n",
      " 0.4376\n",
      " 0.5131\n",
      " 0.3559\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 422\n",
      "p \n",
      " -3.2406\n",
      " -6.9320\n",
      "  3.6257\n",
      "-11.8251\n",
      "-13.3383\n",
      " -4.5261\n",
      "-10.2004\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9965598288527594\n",
      "accepted True\n",
      "q \n",
      " 0.3249\n",
      " 0.9500\n",
      " 0.1190\n",
      " 0.0066\n",
      " 0.3112\n",
      " 0.4282\n",
      " 0.1344\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 423\n",
      "p \n",
      " -0.1099\n",
      "  2.0818\n",
      " -9.2766\n",
      " -6.1109\n",
      " -2.9998\n",
      " 12.4313\n",
      "  5.5262\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9982737913814441\n",
      "accepted True\n",
      "q \n",
      " 0.3002\n",
      " 1.0342\n",
      "-0.0809\n",
      "-0.0558\n",
      " 0.4261\n",
      " 0.5675\n",
      " 0.3006\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 424\n",
      "p \n",
      "  1.8210\n",
      "-11.0043\n",
      " -3.7621\n",
      " -4.8891\n",
      " -5.1328\n",
      "  1.3566\n",
      "-10.2685\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.993546064127391\n",
      "accepted True\n",
      "q \n",
      " 0.4583\n",
      " 0.9266\n",
      "-0.0474\n",
      "-0.0230\n",
      " 0.4111\n",
      " 0.5271\n",
      " 0.0899\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 425\n",
      "p \n",
      "  6.2215\n",
      " -8.9768\n",
      " -5.7861\n",
      " -5.1215\n",
      "-24.4397\n",
      "  0.8354\n",
      " 12.5818\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.963665968138622\n",
      "accepted True\n",
      "q \n",
      " 0.3402\n",
      " 0.8705\n",
      "-0.0901\n",
      " 0.1684\n",
      " 0.1069\n",
      " 0.4844\n",
      " 0.3310\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 426\n",
      "p \n",
      " -1.6764\n",
      "-12.8438\n",
      "-13.8537\n",
      "-13.1221\n",
      "-16.0044\n",
      " 13.1720\n",
      " -7.6273\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9868695177114358\n",
      "accepted True\n",
      "q \n",
      " 0.3891\n",
      " 0.8444\n",
      "-0.1363\n",
      " 0.0754\n",
      " 0.1708\n",
      " 0.6103\n",
      " 0.2234\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 427\n",
      "p \n",
      " -0.3228\n",
      " 10.2647\n",
      " 13.7462\n",
      " -9.1760\n",
      "  7.8855\n",
      "  0.4203\n",
      "  7.4196\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9872352230503968\n",
      "accepted True\n",
      "q \n",
      " 0.3420\n",
      " 1.0274\n",
      "-0.0285\n",
      "-0.1867\n",
      " 0.4908\n",
      " 0.5442\n",
      " 0.3071\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 428\n",
      "p \n",
      "-10.5980\n",
      "  6.3737\n",
      "  3.5880\n",
      " -5.5794\n",
      " -1.7219\n",
      "  1.0727\n",
      " -1.4595\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2056\n",
      " 1.1183\n",
      "-0.0116\n",
      "-0.1560\n",
      " 0.4852\n",
      " 0.5087\n",
      " 0.3412\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 429\n",
      "p \n",
      " -2.0475\n",
      " -6.2740\n",
      "-18.6207\n",
      "-15.3589\n",
      " -5.2776\n",
      "  0.4464\n",
      " -6.6635\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.994698323120358\n",
      "accepted True\n",
      "q \n",
      " 0.3151\n",
      " 1.0518\n",
      "-0.2053\n",
      "-0.2520\n",
      " 0.5938\n",
      " 0.4762\n",
      " 0.2845\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 430\n",
      "p \n",
      " 16.2088\n",
      " -6.8199\n",
      " 13.2532\n",
      "  4.3619\n",
      " -2.1073\n",
      "  2.4889\n",
      " 16.2182\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4294\n",
      " 0.9256\n",
      "-0.0421\n",
      "-0.0565\n",
      " 0.4627\n",
      " 0.4911\n",
      " 0.3352\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 431\n",
      "p \n",
      " 15.6622\n",
      "  4.9892\n",
      " -0.2083\n",
      "  1.3990\n",
      " -3.0413\n",
      " -5.5982\n",
      "  4.6885\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.6291\n",
      " 1.0696\n",
      "-0.0759\n",
      " 0.0195\n",
      " 0.4315\n",
      " 0.4230\n",
      " 0.1937\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 432\n",
      "p \n",
      "  1.1716\n",
      " -4.3050\n",
      " 18.5869\n",
      "  2.8610\n",
      "  3.1545\n",
      "  4.1587\n",
      "  2.6328\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5074\n",
      " 0.9740\n",
      " 0.1287\n",
      " 0.0390\n",
      " 0.4292\n",
      " 0.4893\n",
      " 0.1762\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 433\n",
      "p \n",
      "  7.7734\n",
      " -2.6444\n",
      " 17.0336\n",
      " 10.5410\n",
      " 10.2505\n",
      "  8.4423\n",
      "  9.6134\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5047\n",
      " 0.9551\n",
      " 0.1801\n",
      " 0.0890\n",
      " 0.5105\n",
      " 0.5874\n",
      " 0.2239\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 434\n",
      "p \n",
      " 12.2080\n",
      " -7.0951\n",
      " -2.8673\n",
      " -1.1732\n",
      " -9.6369\n",
      " -4.4548\n",
      " 10.9642\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4975\n",
      " 0.9006\n",
      " 0.0083\n",
      " 0.1392\n",
      " 0.3541\n",
      " 0.4528\n",
      " 0.3273\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 435\n",
      "p \n",
      " 20.3958\n",
      " -6.9681\n",
      " 13.5636\n",
      " -0.5599\n",
      " -0.5536\n",
      " -8.2827\n",
      "  6.0133\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.7298\n",
      " 0.8884\n",
      " 0.1141\n",
      " 0.0619\n",
      " 0.4184\n",
      " 0.3765\n",
      " 0.1320\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 436\n",
      "p \n",
      "-13.3256\n",
      "-11.6689\n",
      " -1.6375\n",
      "  7.5620\n",
      "  5.6705\n",
      " -2.3911\n",
      " -7.4413\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3685\n",
      " 0.7894\n",
      " 0.0234\n",
      " 0.1430\n",
      " 0.4334\n",
      " 0.3612\n",
      " 0.2255\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 437\n",
      "p \n",
      "  3.9849\n",
      "  8.7072\n",
      " 19.6582\n",
      "  3.2234\n",
      " 13.5699\n",
      " -9.2161\n",
      " 10.4899\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3600\n",
      " 0.9699\n",
      " 0.1090\n",
      "-0.0163\n",
      " 0.6330\n",
      " 0.3025\n",
      " 0.3022\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 438\n",
      "p \n",
      "  6.9683\n",
      " 11.6675\n",
      " -7.3867\n",
      "  0.1133\n",
      " -1.8629\n",
      " 13.7085\n",
      " -3.3110\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5652\n",
      " 1.2076\n",
      "-0.0482\n",
      " 0.0199\n",
      " 0.5560\n",
      " 0.5458\n",
      " 0.1124\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 439\n",
      "p \n",
      " 11.8932\n",
      "  5.1118\n",
      " -8.6742\n",
      " 12.7943\n",
      "  6.8791\n",
      " 12.2627\n",
      "  1.5481\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.7202\n",
      " 1.2774\n",
      "-0.2029\n",
      " 0.1649\n",
      " 0.5724\n",
      " 0.6855\n",
      " 0.0683\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 440\n",
      "p \n",
      "-3.4914\n",
      " 1.2990\n",
      " 7.0117\n",
      " 5.8838\n",
      "-2.5252\n",
      " 5.7089\n",
      "-2.3701\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5038\n",
      " 1.1696\n",
      "-0.0352\n",
      " 0.2501\n",
      " 0.3624\n",
      " 0.6394\n",
      " 0.0970\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 441\n",
      "p \n",
      " 19.6328\n",
      "  6.7592\n",
      " 15.5290\n",
      " -4.9079\n",
      "-15.1654\n",
      "  2.3997\n",
      " 26.2191\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5036\n",
      " 1.1887\n",
      " 0.0670\n",
      " 0.2004\n",
      " 0.1896\n",
      " 0.5933\n",
      " 0.3481\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 442\n",
      "p \n",
      "  3.4145\n",
      "-10.3934\n",
      "  2.4923\n",
      " 18.7001\n",
      "  7.6243\n",
      "-18.4443\n",
      "  1.1259\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4356\n",
      " 0.9364\n",
      "-0.0035\n",
      " 0.3711\n",
      " 0.2600\n",
      " 0.2785\n",
      " 0.2963\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 443\n",
      "p \n",
      " 8.0953\n",
      "-4.7132\n",
      "-2.6208\n",
      " 0.8595\n",
      "-6.0335\n",
      " 2.6981\n",
      " 8.1341\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4395\n",
      " 0.9307\n",
      "-0.0745\n",
      " 0.2883\n",
      " 0.2690\n",
      " 0.3822\n",
      " 0.3437\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 444\n",
      "p \n",
      " -3.2404\n",
      "  3.8185\n",
      " -7.7805\n",
      "  0.5963\n",
      " -0.1098\n",
      " -0.8266\n",
      "-15.5433\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5317\n",
      " 1.0715\n",
      "-0.1078\n",
      " 0.1963\n",
      " 0.3542\n",
      " 0.4118\n",
      " 0.0533\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 445\n",
      "p \n",
      " -9.6664\n",
      "-12.4267\n",
      "  3.1832\n",
      " -1.9518\n",
      " -5.8379\n",
      " -0.7243\n",
      " -5.1673\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9943207261700722\n",
      "accepted True\n",
      "q \n",
      " 0.3144\n",
      " 0.8817\n",
      "-0.0050\n",
      " 0.1695\n",
      " 0.2950\n",
      " 0.4057\n",
      " 0.1593\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 446\n",
      "p \n",
      " -5.3920\n",
      "  9.7240\n",
      " 13.7485\n",
      " 14.5075\n",
      " 16.0299\n",
      "-10.5936\n",
      "  5.2414\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2156\n",
      " 1.0322\n",
      " 0.0303\n",
      " 0.1817\n",
      " 0.4571\n",
      " 0.3047\n",
      " 0.2862\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 447\n",
      "p \n",
      " -4.0894\n",
      "  2.7275\n",
      " -0.1849\n",
      " -9.5177\n",
      " -6.2477\n",
      "-10.5111\n",
      "  5.4027\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1486\n",
      " 1.0644\n",
      "-0.0397\n",
      " 0.0177\n",
      " 0.4529\n",
      " 0.2366\n",
      " 0.4234\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 448\n",
      "p \n",
      " 4.1017\n",
      " 1.1029\n",
      " 5.9379\n",
      " 3.9736\n",
      " 2.5875\n",
      " 1.7231\n",
      " 0.2148\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3273\n",
      " 1.0686\n",
      " 0.0038\n",
      " 0.0609\n",
      " 0.4560\n",
      " 0.3576\n",
      " 0.2597\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 449\n",
      "p \n",
      " -1.9367\n",
      " -4.6850\n",
      " -1.8828\n",
      "  1.2982\n",
      "  1.1906\n",
      "-18.6032\n",
      "  4.4510\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9856499505414719\n",
      "accepted True\n",
      "q \n",
      " 0.2369\n",
      " 0.9803\n",
      "-0.0846\n",
      " 0.0619\n",
      " 0.4780\n",
      " 0.1716\n",
      " 0.3961\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 450\n",
      "p \n",
      "  9.5398\n",
      " -7.2593\n",
      " 11.8575\n",
      "  6.7805\n",
      "  2.6030\n",
      "  5.8211\n",
      "  9.7554\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9976868007104372\n",
      "accepted True\n",
      "q \n",
      " 0.3505\n",
      " 0.8924\n",
      " 0.0202\n",
      " 0.1225\n",
      " 0.4430\n",
      " 0.3608\n",
      " 0.3563\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 451\n",
      "p \n",
      "-16.2157\n",
      " 11.4450\n",
      "  1.3823\n",
      " -6.0930\n",
      "  3.0596\n",
      "-10.2138\n",
      "-15.9638\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2798\n",
      " 1.1190\n",
      " 0.0245\n",
      "-0.0343\n",
      " 0.5321\n",
      " 0.2862\n",
      " 0.1655\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 452\n",
      "p \n",
      "  8.6686\n",
      " -1.6279\n",
      " 14.9322\n",
      "  0.6596\n",
      "  2.1994\n",
      " 10.3683\n",
      "  8.9069\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3920\n",
      " 1.0497\n",
      " 0.1209\n",
      "-0.0345\n",
      " 0.5258\n",
      " 0.4862\n",
      " 0.1965\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 453\n",
      "p \n",
      "-13.5085\n",
      "  1.5479\n",
      " -9.8399\n",
      " -6.4803\n",
      " -8.1882\n",
      "  9.3390\n",
      "-19.4197\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3661\n",
      " 1.1166\n",
      " 0.0131\n",
      " 0.0128\n",
      " 0.3986\n",
      " 0.5793\n",
      " 0.0233\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 454\n",
      "p \n",
      "  1.4616\n",
      "  6.3859\n",
      " -5.1444\n",
      " -3.1927\n",
      "  0.7480\n",
      " -5.1649\n",
      "-15.3933\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5722\n",
      " 1.2294\n",
      "-0.0401\n",
      "-0.0314\n",
      " 0.4848\n",
      " 0.4818\n",
      "-0.1624\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 455\n",
      "p \n",
      " 23.2448\n",
      "-11.7005\n",
      "-10.8385\n",
      " -5.7171\n",
      " -7.1778\n",
      "  4.9119\n",
      "  5.0297\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.8126\n",
      " 1.0409\n",
      "-0.1581\n",
      "-0.0354\n",
      " 0.4898\n",
      " 0.5310\n",
      "-0.0804\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 456\n",
      "p \n",
      "-11.5092\n",
      "  9.8390\n",
      " -3.3268\n",
      "  5.4618\n",
      " -9.5289\n",
      "  8.8558\n",
      "-12.1188\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5432\n",
      " 1.1972\n",
      "-0.0980\n",
      " 0.2124\n",
      " 0.2175\n",
      " 0.6022\n",
      "-0.0716\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 457\n",
      "p \n",
      " 11.5359\n",
      " -5.3161\n",
      " -0.5460\n",
      "-26.6568\n",
      "-18.6614\n",
      " -0.1192\n",
      "  7.7899\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5664\n",
      " 1.0708\n",
      "-0.0530\n",
      "-0.1425\n",
      " 0.3237\n",
      " 0.5226\n",
      " 0.1015\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 458\n",
      "p \n",
      " -0.3392\n",
      " -7.7973\n",
      " -8.1886\n",
      "  2.1946\n",
      " -3.1731\n",
      "-10.7060\n",
      "  7.1689\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3520\n",
      " 0.9368\n",
      "-0.1707\n",
      " 0.0114\n",
      " 0.3448\n",
      " 0.3401\n",
      " 0.3518\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 459\n",
      "p \n",
      "-10.2340\n",
      "  0.8693\n",
      " -9.6782\n",
      "-15.2708\n",
      " -7.3821\n",
      " -5.5908\n",
      " -3.4012\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9889447016726964\n",
      "accepted True\n",
      "q \n",
      " 0.2228\n",
      " 1.0171\n",
      "-0.2085\n",
      "-0.1373\n",
      " 0.4425\n",
      " 0.3146\n",
      " 0.3981\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 460\n",
      "p \n",
      "  3.4411\n",
      "  7.5585\n",
      " 12.0678\n",
      "  3.0184\n",
      " -1.0297\n",
      " -1.0861\n",
      "  5.5116\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9941723348453274\n",
      "accepted True\n",
      "q \n",
      " 0.2947\n",
      " 1.1077\n",
      "-0.0499\n",
      "-0.0143\n",
      " 0.3792\n",
      " 0.3639\n",
      " 0.3268\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 461\n",
      "p \n",
      "  0.9368\n",
      "  1.0720\n",
      "  6.1633\n",
      " -1.3114\n",
      " -5.1661\n",
      " -0.2800\n",
      " 13.4689\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.1869\n",
      " 1.0732\n",
      "-0.0368\n",
      " 0.0315\n",
      " 0.3392\n",
      " 0.3874\n",
      " 0.5127\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 462\n",
      "p \n",
      " 4.3195\n",
      "-5.3915\n",
      " 1.6572\n",
      "-2.8373\n",
      "-6.7790\n",
      "-1.0543\n",
      " 3.6999\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2939\n",
      " 0.9883\n",
      "-0.0231\n",
      " 0.0568\n",
      " 0.3159\n",
      " 0.4006\n",
      " 0.3975\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 463\n",
      "p \n",
      " 3.2435\n",
      " 0.2089\n",
      "-3.3869\n",
      " 7.7363\n",
      " 3.1529\n",
      "-2.5855\n",
      "-0.3854\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3863\n",
      " 1.0259\n",
      "-0.0962\n",
      " 0.1455\n",
      " 0.3729\n",
      " 0.3935\n",
      " 0.2901\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 464\n",
      "p \n",
      " -6.1431\n",
      "-17.6646\n",
      "  3.7260\n",
      "  1.4979\n",
      " -1.7784\n",
      " 11.8541\n",
      "-15.3011\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9748560221933059\n",
      "accepted True\n",
      "q \n",
      " 0.4248\n",
      " 0.8233\n",
      " 0.0516\n",
      " 0.1627\n",
      " 0.3393\n",
      " 0.5563\n",
      " 0.0479\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 465\n",
      "p \n",
      " -6.7052\n",
      " -1.3845\n",
      " -4.0066\n",
      "  5.0579\n",
      " 11.0969\n",
      "  8.1478\n",
      " -6.0440\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9949586343064709\n",
      "accepted True\n",
      "q \n",
      " 0.3767\n",
      " 0.9141\n",
      "-0.0538\n",
      " 0.0860\n",
      " 0.5401\n",
      " 0.6009\n",
      " 0.1087\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 466\n",
      "p \n",
      "  4.9764\n",
      "-10.0802\n",
      " -6.6811\n",
      " -5.4125\n",
      " -1.4689\n",
      "-10.6468\n",
      " -0.4887\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9996507777738981\n",
      "accepted True\n",
      "q \n",
      " 0.4377\n",
      " 0.8562\n",
      "-0.1248\n",
      "-0.0103\n",
      " 0.5647\n",
      " 0.3940\n",
      " 0.1644\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 467\n",
      "p \n",
      " -7.9781\n",
      "  1.9939\n",
      "  5.5634\n",
      "  1.0775\n",
      "  8.3877\n",
      " 23.8041\n",
      "  1.9613\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3034\n",
      " 0.9600\n",
      "-0.0690\n",
      "-0.0608\n",
      " 0.6497\n",
      " 0.6897\n",
      " 0.2723\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 468\n",
      "p \n",
      " -2.3898\n",
      "  5.7293\n",
      "  9.2025\n",
      " 12.6068\n",
      "  0.1289\n",
      " -6.2020\n",
      "  5.5826\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2197\n",
      " 1.0377\n",
      "-0.0049\n",
      " 0.2003\n",
      " 0.3946\n",
      " 0.4971\n",
      " 0.3335\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 469\n",
      "p \n",
      " 16.0782\n",
      "-10.1751\n",
      " -3.2680\n",
      " -1.9673\n",
      "  1.9736\n",
      "  1.9147\n",
      "  4.6609\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5137\n",
      " 0.9254\n",
      "-0.0813\n",
      " 0.0465\n",
      " 0.5395\n",
      " 0.4997\n",
      " 0.2267\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 470\n",
      "p \n",
      " -8.3267\n",
      "  7.0798\n",
      "-18.5547\n",
      "-10.2476\n",
      " -9.1165\n",
      " -2.4729\n",
      " -9.1082\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3992\n",
      " 1.1169\n",
      "-0.2441\n",
      "-0.0147\n",
      " 0.4761\n",
      " 0.4389\n",
      " 0.2148\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 471\n",
      "p \n",
      " 14.5290\n",
      " -4.9497\n",
      "-13.1164\n",
      "  4.4664\n",
      " -4.3020\n",
      "-14.4536\n",
      " 12.7966\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9960234760998451\n",
      "accepted True\n",
      "q \n",
      " 0.4573\n",
      " 1.0341\n",
      "-0.3554\n",
      " 0.1155\n",
      " 0.4275\n",
      " 0.2665\n",
      " 0.3777\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 472\n",
      "p \n",
      " -1.5954\n",
      " 12.0325\n",
      "  2.9461\n",
      " -9.9773\n",
      "  6.2284\n",
      " -2.1921\n",
      "  2.2144\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4103\n",
      " 1.2041\n",
      "-0.2517\n",
      "-0.1730\n",
      " 0.6636\n",
      " 0.3232\n",
      " 0.3582\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 473\n",
      "p \n",
      "  6.2128\n",
      "  9.8174\n",
      " 24.8170\n",
      " -0.3607\n",
      "  1.5874\n",
      "-19.1489\n",
      "  1.4979\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5007\n",
      " 1.2386\n",
      " 0.0914\n",
      "-0.1202\n",
      " 0.5534\n",
      " 0.1729\n",
      " 0.1524\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 474\n",
      "p \n",
      "-4.4355\n",
      "-6.9343\n",
      "-5.7062\n",
      "-5.4764\n",
      " 7.9749\n",
      " 0.4520\n",
      "-1.1676\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3771\n",
      " 1.0497\n",
      "-0.0658\n",
      "-0.2209\n",
      " 0.7359\n",
      " 0.2951\n",
      " 0.2710\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 475\n",
      "p \n",
      " -1.8863\n",
      " -3.4536\n",
      "-12.1140\n",
      " -1.7154\n",
      "  2.3428\n",
      "  6.5464\n",
      "-13.9787\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5043\n",
      " 1.0529\n",
      "-0.1544\n",
      "-0.1354\n",
      " 0.6928\n",
      " 0.4471\n",
      " 0.0649\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 476\n",
      "p \n",
      "  2.0719\n",
      " -3.1458\n",
      " -9.7858\n",
      "  9.7031\n",
      " 16.8682\n",
      " 12.0375\n",
      " -3.4391\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5594\n",
      " 1.0548\n",
      "-0.2656\n",
      "-0.0829\n",
      " 0.8573\n",
      " 0.6010\n",
      " 0.0965\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 477\n",
      "p \n",
      "  0.6910\n",
      "  4.5483\n",
      " 10.7072\n",
      " -2.5193\n",
      "  2.7994\n",
      " -6.8857\n",
      "  9.7720\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3833\n",
      " 1.0698\n",
      "-0.1051\n",
      "-0.1176\n",
      " 0.7347\n",
      " 0.4381\n",
      " 0.2908\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 478\n",
      "p \n",
      " -7.7067\n",
      "  6.1850\n",
      " -5.8682\n",
      "  5.0523\n",
      "  4.2202\n",
      " 12.7494\n",
      "  4.4991\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2151\n",
      " 1.1560\n",
      "-0.2082\n",
      "-0.0052\n",
      " 0.6565\n",
      " 0.5912\n",
      " 0.4476\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 479\n",
      "p \n",
      "-1.0769\n",
      "-5.4956\n",
      " 5.7821\n",
      " 3.2465\n",
      " 0.0293\n",
      "-2.8558\n",
      "-1.3409\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2753\n",
      " 1.0033\n",
      "-0.0595\n",
      " 0.0782\n",
      " 0.5031\n",
      " 0.4769\n",
      " 0.3095\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 480\n",
      "p \n",
      "  7.5558\n",
      "  8.2826\n",
      " 14.0095\n",
      "  8.1685\n",
      "  2.4773\n",
      " -1.9122\n",
      "  1.2347\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4535\n",
      " 1.1322\n",
      " 0.0737\n",
      " 0.1602\n",
      " 0.4216\n",
      " 0.4637\n",
      " 0.1351\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 481\n",
      "p \n",
      "-16.1509\n",
      " -5.6845\n",
      "-11.7124\n",
      "-14.6411\n",
      "  0.7632\n",
      "  0.5394\n",
      "-15.1318\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3010\n",
      " 1.0361\n",
      "-0.0752\n",
      "-0.1364\n",
      " 0.6183\n",
      " 0.4454\n",
      " 0.1508\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 482\n",
      "p \n",
      "-13.0507\n",
      " -0.3309\n",
      " -6.9798\n",
      " 16.7000\n",
      " -1.4084\n",
      " -6.8201\n",
      "-21.4767\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.979348285079004\n",
      "accepted True\n",
      "q \n",
      " 0.3175\n",
      " 1.0589\n",
      "-0.0777\n",
      " 0.2731\n",
      " 0.3140\n",
      " 0.3708\n",
      "-0.0396\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 483\n",
      "p \n",
      "  7.7317\n",
      "  2.4250\n",
      " 12.2124\n",
      " -7.3826\n",
      " -8.7336\n",
      " -1.2150\n",
      "  9.8270\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9998947437371558\n",
      "accepted True\n",
      "q \n",
      " 0.3675\n",
      " 1.0595\n",
      " 0.0475\n",
      " 0.1191\n",
      " 0.2941\n",
      " 0.3921\n",
      " 0.1151\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 484\n",
      "p \n",
      "-15.1544\n",
      "  0.1660\n",
      "  2.7915\n",
      "-13.5834\n",
      " -0.9035\n",
      "  8.5537\n",
      " -9.7491\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9924643494159434\n",
      "accepted True\n",
      "q \n",
      " 0.2453\n",
      " 1.0679\n",
      " 0.0641\n",
      "-0.1173\n",
      " 0.4680\n",
      " 0.5120\n",
      " 0.1424\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 485\n",
      "p \n",
      " 15.1147\n",
      " 13.4771\n",
      "  7.6585\n",
      "-16.0334\n",
      " -8.3528\n",
      " 13.1315\n",
      " 13.5208\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.4572\n",
      " 1.2762\n",
      " 0.0576\n",
      "-0.2783\n",
      " 0.5210\n",
      " 0.6675\n",
      " 0.1991\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 486\n",
      "p \n",
      " -0.9153\n",
      " -9.6836\n",
      "-11.9450\n",
      "-17.8091\n",
      " -8.1765\n",
      "  1.2236\n",
      "-10.9925\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.5041\n",
      " 1.0757\n",
      "-0.0682\n",
      "-0.3093\n",
      " 0.5573\n",
      " 0.5646\n",
      " 0.0967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 487\n",
      "p \n",
      "  9.8214\n",
      " -6.2074\n",
      " -4.0607\n",
      "  0.3973\n",
      " -0.0967\n",
      "-10.7347\n",
      "  5.8173\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9997581536010578\n",
      "accepted True\n",
      "q \n",
      " 0.5260\n",
      " 0.9756\n",
      "-0.1340\n",
      "-0.1558\n",
      " 0.5484\n",
      " 0.3783\n",
      " 0.1958\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 488\n",
      "p \n",
      "-20.1040\n",
      " -3.7893\n",
      " -6.9078\n",
      " -2.4351\n",
      " -4.1592\n",
      " 11.1395\n",
      "  0.4430\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9889962215543774\n",
      "accepted True\n",
      "q \n",
      " 0.1039\n",
      " 0.9420\n",
      "-0.1722\n",
      "-0.0421\n",
      " 0.4501\n",
      " 0.5057\n",
      " 0.4622\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 489\n",
      "p \n",
      "  1.1268\n",
      " 16.0328\n",
      "  2.5665\n",
      "  9.4564\n",
      " 12.6595\n",
      "  5.8642\n",
      " -5.1446\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3369\n",
      " 1.2174\n",
      "-0.1443\n",
      " 0.0058\n",
      " 0.5788\n",
      " 0.5742\n",
      " 0.2104\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 490\n",
      "p \n",
      "-7.5976\n",
      " 2.5952\n",
      "-3.9479\n",
      "-6.1761\n",
      "-9.2139\n",
      "-5.8185\n",
      "-9.6926\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3154\n",
      " 1.1854\n",
      "-0.1001\n",
      " 0.0344\n",
      " 0.4034\n",
      " 0.4374\n",
      " 0.1338\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 491\n",
      "p \n",
      "-8.4514\n",
      "-1.4962\n",
      " 2.4400\n",
      " 2.0630\n",
      "-0.4369\n",
      "-1.7192\n",
      "-2.9383\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2248\n",
      " 1.0896\n",
      "-0.0507\n",
      " 0.0893\n",
      " 0.3797\n",
      " 0.4141\n",
      " 0.2109\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 492\n",
      "p \n",
      " -1.4119\n",
      "  7.3304\n",
      " 10.4727\n",
      "  4.5261\n",
      "  9.2268\n",
      " -6.9556\n",
      " -1.3756\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.3015\n",
      " 1.1592\n",
      " 0.0227\n",
      " 0.0371\n",
      " 0.5111\n",
      " 0.3585\n",
      " 0.1665\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 493\n",
      "p \n",
      " -5.6161\n",
      "  9.7923\n",
      " -1.5221\n",
      " -2.6297\n",
      " -2.3881\n",
      "-21.1311\n",
      " -4.0645\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9987836135521497\n",
      "accepted True\n",
      "q \n",
      " 0.2747\n",
      " 1.2493\n",
      "-0.0479\n",
      " 0.0238\n",
      " 0.4689\n",
      " 0.1530\n",
      " 0.1967\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 494\n",
      "p \n",
      "-29.4908\n",
      " -9.5563\n",
      " -3.3220\n",
      " -7.9462\n",
      " 10.6450\n",
      " -4.7189\n",
      "-32.0820\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.982145453923605\n",
      "accepted True\n",
      "q \n",
      " 0.1802\n",
      " 1.0484\n",
      " 0.0049\n",
      "-0.1621\n",
      " 0.6878\n",
      " 0.2442\n",
      "-0.0028\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 495\n",
      "p \n",
      " -4.3336\n",
      "  4.7234\n",
      " -3.6705\n",
      " 12.0054\n",
      "  6.2712\n",
      "  9.4138\n",
      " -7.6476\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9930444792778519\n",
      "accepted True\n",
      "q \n",
      " 0.2876\n",
      " 1.1195\n",
      "-0.0641\n",
      " 0.0579\n",
      " 0.5737\n",
      " 0.4385\n",
      "-0.0049\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 496\n",
      "p \n",
      "-11.6053\n",
      " -4.8207\n",
      " -2.5431\n",
      " -0.1792\n",
      " -5.3172\n",
      " -6.2605\n",
      "-12.4604\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.2448\n",
      " 1.0283\n",
      "-0.0365\n",
      " 0.1315\n",
      " 0.3992\n",
      " 0.3636\n",
      " 0.0284\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 497\n",
      "p \n",
      " -3.8175\n",
      "-11.6032\n",
      "-16.4108\n",
      "-12.0029\n",
      " -6.3366\n",
      " -8.4862\n",
      " -4.3593\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9834201201404519\n",
      "accepted True\n",
      "q \n",
      " 0.2610\n",
      " 0.9129\n",
      "-0.1906\n",
      "-0.0262\n",
      " 0.4830\n",
      " 0.2922\n",
      " 0.1832\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 498\n",
      "p \n",
      "-13.5387\n",
      "  3.8295\n",
      " -3.3017\n",
      " 13.5134\n",
      "  7.0737\n",
      " 16.0921\n",
      " -7.5257\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 0.9928285773999057\n",
      "accepted True\n",
      "q \n",
      " 0.1863\n",
      " 1.0239\n",
      "-0.1779\n",
      " 0.1652\n",
      " 0.4398\n",
      " 0.5291\n",
      " 0.1987\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "round 499\n",
      "p \n",
      "-20.5241\n",
      "  1.2208\n",
      " -0.8461\n",
      " 20.4855\n",
      " 17.0164\n",
      " -7.7243\n",
      "-12.9172\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "accepted_rate 1.0\n",
      "accepted True\n",
      "q \n",
      " 0.0690\n",
      " 1.0466\n",
      "-0.1580\n",
      " 0.3054\n",
      " 0.5000\n",
      " 0.3999\n",
      " 0.2141\n",
      "[torch.FloatTensor of size 7]\n",
      "\n",
      "length of chain is 500\n",
      "burn in is 100\n",
      "total time is 577.5597121715546\n",
      "alpha is 1000000.0\n",
      "sd is [0.13728609 0.12557814 0.10835697 0.14433066 0.15573635 0.12750871\n",
      " 0.14992589]\n",
      "mean is [ 0.34780452  1.0452683  -0.07335814  0.021197    0.48926464  0.44132707\n",
      "  0.26363876]\n"
     ]
    }
   ],
   "source": [
    "%run -i \"newtestgen_leapfrog_logit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'-.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run - i \"newtestgleapfrog_nuts_logit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiulau/miniconda2/envs/py36/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n",
      "round 101\n",
      "round 102\n",
      "round 103\n",
      "round 104\n",
      "round 105\n",
      "round 106\n",
      "round 107\n",
      "round 108\n",
      "round 109\n",
      "round 110\n",
      "round 111\n",
      "round 112\n",
      "round 113\n",
      "round 114\n",
      "round 115\n",
      "round 116\n",
      "round 117\n",
      "round 118\n",
      "round 119\n",
      "round 120\n",
      "round 121\n",
      "round 122\n",
      "round 123\n",
      "round 124\n",
      "round 125\n",
      "round 126\n",
      "round 127\n",
      "round 128\n",
      "round 129\n",
      "round 130\n",
      "round 131\n",
      "round 132\n",
      "round 133\n",
      "round 134\n",
      "round 135\n",
      "round 136\n",
      "round 137\n",
      "round 138\n",
      "round 139\n",
      "round 140\n",
      "round 141\n",
      "round 142\n",
      "round 143\n",
      "round 144\n",
      "round 145\n",
      "round 146\n",
      "round 147\n",
      "round 148\n",
      "round 149\n",
      "round 150\n",
      "round 151\n",
      "round 152\n",
      "round 153\n",
      "round 154\n",
      "round 155\n",
      "round 156\n",
      "round 157\n",
      "round 158\n",
      "round 159\n",
      "round 160\n",
      "round 161\n",
      "round 162\n",
      "round 163\n",
      "round 164\n",
      "round 165\n",
      "round 166\n",
      "round 167\n",
      "round 168\n",
      "round 169\n",
      "round 170\n",
      "round 171\n",
      "round 172\n",
      "round 173\n",
      "round 174\n",
      "round 175\n",
      "round 176\n",
      "round 177\n",
      "round 178\n",
      "round 179\n",
      "round 180\n",
      "round 181\n",
      "round 182\n",
      "round 183\n",
      "round 184\n",
      "round 185\n",
      "round 186\n",
      "round 187\n",
      "round 188\n",
      "round 189\n",
      "round 190\n",
      "round 191\n",
      "round 192\n",
      "round 193\n",
      "round 194\n",
      "round 195\n",
      "round 196\n",
      "round 197\n",
      "round 198\n",
      "round 199\n",
      "round 200\n",
      "round 201\n",
      "round 202\n",
      "round 203\n",
      "round 204\n",
      "round 205\n",
      "round 206\n",
      "round 207\n",
      "round 208\n",
      "round 209\n",
      "round 210\n",
      "round 211\n",
      "round 212\n",
      "round 213\n",
      "round 214\n",
      "round 215\n",
      "round 216\n",
      "round 217\n",
      "round 218\n",
      "round 219\n",
      "round 220\n",
      "round 221\n",
      "round 222\n",
      "round 223\n",
      "round 224\n",
      "round 225\n",
      "round 226\n",
      "round 227\n",
      "round 228\n",
      "round 229\n",
      "round 230\n",
      "round 231\n",
      "round 232\n",
      "round 233\n",
      "round 234\n",
      "round 235\n",
      "round 236\n",
      "round 237\n",
      "round 238\n",
      "round 239\n",
      "round 240\n",
      "round 241\n",
      "round 242\n",
      "round 243\n",
      "round 244\n",
      "round 245\n",
      "round 246\n",
      "round 247\n",
      "round 248\n",
      "round 249\n",
      "round 250\n",
      "round 251\n",
      "round 252\n",
      "round 253\n",
      "round 254\n",
      "round 255\n",
      "round 256\n",
      "round 257\n",
      "round 258\n",
      "round 259\n",
      "round 260\n",
      "round 261\n",
      "round 262\n",
      "round 263\n",
      "round 264\n",
      "round 265\n",
      "round 266\n",
      "round 267\n",
      "round 268\n",
      "round 269\n",
      "round 270\n",
      "round 271\n",
      "round 272\n",
      "round 273\n",
      "round 274\n",
      "round 275\n",
      "round 276\n",
      "round 277\n",
      "round 278\n",
      "round 279\n",
      "round 280\n",
      "round 281\n",
      "round 282\n",
      "round 283\n",
      "round 284\n",
      "round 285\n",
      "round 286\n",
      "round 287\n",
      "round 288\n",
      "round 289\n",
      "round 290\n",
      "round 291\n",
      "round 292\n",
      "round 293\n",
      "round 294\n",
      "round 295\n",
      "round 296\n",
      "round 297\n",
      "round 298\n",
      "round 299\n",
      "round 300\n",
      "round 301\n",
      "round 302\n",
      "round 303\n",
      "round 304\n",
      "round 305\n",
      "round 306\n",
      "round 307\n",
      "round 308\n",
      "round 309\n",
      "round 310\n",
      "round 311\n",
      "round 312\n",
      "round 313\n",
      "round 314\n",
      "round 315\n",
      "round 316\n",
      "round 317\n",
      "round 318\n",
      "round 319\n",
      "round 320\n",
      "round 321\n",
      "round 322\n",
      "round 323\n",
      "round 324\n",
      "round 325\n",
      "round 326\n",
      "round 327\n",
      "round 328\n",
      "round 329\n",
      "round 330\n",
      "round 331\n",
      "round 332\n",
      "round 333\n",
      "round 334\n",
      "round 335\n",
      "round 336\n",
      "round 337\n",
      "round 338\n",
      "round 339\n",
      "round 340\n",
      "round 341\n",
      "round 342\n",
      "round 343\n",
      "round 344\n",
      "round 345\n",
      "round 346\n",
      "round 347\n",
      "round 348\n",
      "round 349\n",
      "round 350\n",
      "round 351\n",
      "round 352\n",
      "round 353\n",
      "round 354\n",
      "round 355\n",
      "round 356\n",
      "round 357\n",
      "round 358\n",
      "round 359\n",
      "round 360\n",
      "round 361\n",
      "round 362\n",
      "round 363\n",
      "round 364\n",
      "round 365\n",
      "round 366\n",
      "round 367\n",
      "round 368\n",
      "round 369\n",
      "round 370\n",
      "round 371\n",
      "round 372\n",
      "round 373\n",
      "round 374\n",
      "round 375\n",
      "round 376\n",
      "round 377\n",
      "round 378\n",
      "round 379\n",
      "round 380\n",
      "round 381\n",
      "round 382\n",
      "round 383\n",
      "round 384\n",
      "round 385\n",
      "round 386\n",
      "round 387\n",
      "round 388\n",
      "round 389\n",
      "round 390\n",
      "round 391\n",
      "round 392\n",
      "round 393\n",
      "round 394\n",
      "round 395\n",
      "round 396\n",
      "round 397\n",
      "round 398\n",
      "round 399\n",
      "round 400\n",
      "round 401\n",
      "round 402\n",
      "round 403\n",
      "round 404\n",
      "round 405\n",
      "round 406\n",
      "round 407\n",
      "round 408\n",
      "round 409\n",
      "round 410\n",
      "round 411\n",
      "round 412\n",
      "round 413\n",
      "round 414\n",
      "round 415\n",
      "round 416\n",
      "round 417\n",
      "round 418\n",
      "round 419\n",
      "round 420\n",
      "round 421\n",
      "round 422\n",
      "round 423\n",
      "round 424\n",
      "round 425\n",
      "round 426\n",
      "round 427\n",
      "round 428\n",
      "round 429\n",
      "round 430\n",
      "round 431\n",
      "round 432\n",
      "round 433\n",
      "round 434\n",
      "round 435\n",
      "round 436\n",
      "round 437\n",
      "round 438\n",
      "round 439\n",
      "round 440\n",
      "round 441\n",
      "round 442\n",
      "round 443\n",
      "round 444\n",
      "round 445\n",
      "round 446\n",
      "round 447\n",
      "round 448\n",
      "round 449\n",
      "round 450\n",
      "round 451\n",
      "round 452\n",
      "round 453\n",
      "round 454\n",
      "round 455\n",
      "round 456\n",
      "round 457\n",
      "round 458\n",
      "round 459\n",
      "round 460\n",
      "round 461\n",
      "round 462\n",
      "round 463\n",
      "round 464\n",
      "round 465\n",
      "round 466\n",
      "round 467\n",
      "round 468\n",
      "round 469\n",
      "round 470\n",
      "round 471\n",
      "round 472\n",
      "round 473\n",
      "round 474\n",
      "round 475\n",
      "round 476\n",
      "round 477\n",
      "round 478\n",
      "round 479\n",
      "round 480\n",
      "round 481\n",
      "round 482\n",
      "round 483\n",
      "round 484\n",
      "round 485\n",
      "round 486\n",
      "round 487\n",
      "round 488\n",
      "round 489\n",
      "round 490\n",
      "round 491\n",
      "round 492\n",
      "round 493\n",
      "round 494\n",
      "round 495\n",
      "round 496\n",
      "round 497\n",
      "round 498\n",
      "round 499\n",
      "round 500\n",
      "round 501\n",
      "round 502\n",
      "round 503\n",
      "round 504\n",
      "round 505\n",
      "round 506\n",
      "round 507\n",
      "round 508\n",
      "round 509\n",
      "round 510\n",
      "round 511\n",
      "round 512\n",
      "round 513\n",
      "round 514\n",
      "round 515\n",
      "round 516\n",
      "round 517\n",
      "round 518\n",
      "round 519\n",
      "round 520\n",
      "round 521\n",
      "round 522\n",
      "round 523\n",
      "round 524\n",
      "round 525\n",
      "round 526\n",
      "round 527\n",
      "round 528\n",
      "round 529\n",
      "round 530\n",
      "round 531\n",
      "round 532\n",
      "round 533\n",
      "round 534\n",
      "round 535\n",
      "round 536\n",
      "round 537\n",
      "round 538\n",
      "round 539\n",
      "round 540\n",
      "round 541\n",
      "round 542\n",
      "round 543\n",
      "round 544\n",
      "round 545\n",
      "round 546\n",
      "round 547\n",
      "round 548\n",
      "round 549\n",
      "round 550\n",
      "round 551\n",
      "round 552\n",
      "round 553\n",
      "round 554\n",
      "round 555\n",
      "round 556\n",
      "round 557\n",
      "round 558\n",
      "round 559\n",
      "round 560\n",
      "round 561\n",
      "round 562\n",
      "round 563\n",
      "round 564\n",
      "round 565\n",
      "round 566\n",
      "round 567\n",
      "round 568\n",
      "round 569\n",
      "round 570\n",
      "round 571\n",
      "round 572\n",
      "round 573\n",
      "round 574\n",
      "round 575\n",
      "round 576\n",
      "round 577\n",
      "round 578\n",
      "round 579\n",
      "round 580\n",
      "round 581\n",
      "round 582\n",
      "round 583\n",
      "round 584\n",
      "round 585\n",
      "round 586\n",
      "round 587\n",
      "round 588\n",
      "round 589\n",
      "round 590\n",
      "round 591\n",
      "round 592\n",
      "round 593\n",
      "round 594\n",
      "round 595\n",
      "round 596\n",
      "round 597\n",
      "round 598\n",
      "round 599\n",
      "round 600\n",
      "round 601\n",
      "round 602\n",
      "round 603\n",
      "round 604\n",
      "round 605\n",
      "round 606\n",
      "round 607\n",
      "round 608\n",
      "round 609\n",
      "round 610\n",
      "round 611\n",
      "round 612\n",
      "round 613\n",
      "round 614\n",
      "round 615\n",
      "round 616\n",
      "round 617\n",
      "round 618\n",
      "round 619\n",
      "round 620\n",
      "round 621\n",
      "round 622\n",
      "round 623\n",
      "round 624\n",
      "round 625\n",
      "round 626\n",
      "round 627\n",
      "round 628\n",
      "round 629\n",
      "round 630\n",
      "round 631\n",
      "round 632\n",
      "round 633\n",
      "round 634\n",
      "round 635\n",
      "round 636\n",
      "round 637\n",
      "round 638\n",
      "round 639\n",
      "round 640\n",
      "round 641\n",
      "round 642\n",
      "round 643\n",
      "round 644\n",
      "round 645\n",
      "round 646\n",
      "round 647\n",
      "round 648\n",
      "round 649\n",
      "round 650\n",
      "round 651\n",
      "round 652\n",
      "round 653\n",
      "round 654\n",
      "round 655\n",
      "round 656\n",
      "round 657\n",
      "round 658\n",
      "round 659\n",
      "round 660\n",
      "round 661\n",
      "round 662\n",
      "round 663\n",
      "round 664\n",
      "round 665\n",
      "round 666\n",
      "round 667\n",
      "round 668\n",
      "round 669\n",
      "round 670\n",
      "round 671\n",
      "round 672\n",
      "round 673\n",
      "round 674\n",
      "round 675\n",
      "round 676\n",
      "round 677\n",
      "round 678\n",
      "round 679\n",
      "round 680\n",
      "round 681\n",
      "round 682\n",
      "round 683\n",
      "round 684\n",
      "round 685\n",
      "round 686\n",
      "round 687\n",
      "round 688\n",
      "round 689\n",
      "round 690\n",
      "round 691\n",
      "round 692\n",
      "round 693\n",
      "round 694\n",
      "round 695\n",
      "round 696\n",
      "round 697\n",
      "round 698\n",
      "round 699\n",
      "round 700\n",
      "round 701\n",
      "round 702\n",
      "round 703\n",
      "round 704\n",
      "round 705\n",
      "round 706\n",
      "round 707\n",
      "round 708\n",
      "round 709\n",
      "round 710\n",
      "round 711\n",
      "round 712\n",
      "round 713\n",
      "round 714\n",
      "round 715\n",
      "round 716\n",
      "round 717\n",
      "round 718\n",
      "round 719\n",
      "round 720\n",
      "round 721\n",
      "round 722\n",
      "round 723\n",
      "round 724\n",
      "round 725\n",
      "round 726\n",
      "round 727\n",
      "round 728\n",
      "round 729\n",
      "round 730\n",
      "round 731\n",
      "round 732\n",
      "round 733\n",
      "round 734\n",
      "round 735\n",
      "round 736\n",
      "round 737\n",
      "round 738\n",
      "round 739\n",
      "round 740\n",
      "round 741\n",
      "round 742\n",
      "round 743\n",
      "round 744\n",
      "round 745\n",
      "round 746\n",
      "round 747\n",
      "round 748\n",
      "round 749\n",
      "round 750\n",
      "round 751\n",
      "round 752\n",
      "round 753\n",
      "round 754\n",
      "round 755\n",
      "round 756\n",
      "round 757\n",
      "round 758\n",
      "round 759\n",
      "round 760\n",
      "round 761\n",
      "round 762\n",
      "round 763\n",
      "round 764\n",
      "round 765\n",
      "round 766\n",
      "round 767\n",
      "round 768\n",
      "round 769\n",
      "round 770\n",
      "round 771\n",
      "round 772\n",
      "round 773\n",
      "round 774\n",
      "round 775\n",
      "round 776\n",
      "round 777\n",
      "round 778\n",
      "round 779\n",
      "round 780\n",
      "round 781\n",
      "round 782\n",
      "round 783\n",
      "round 784\n",
      "round 785\n",
      "round 786\n",
      "round 787\n",
      "round 788\n",
      "round 789\n",
      "round 790\n",
      "round 791\n",
      "round 792\n",
      "round 793\n",
      "round 794\n",
      "round 795\n",
      "round 796\n",
      "round 797\n",
      "round 798\n",
      "round 799\n",
      "round 800\n",
      "round 801\n",
      "round 802\n",
      "round 803\n",
      "round 804\n",
      "round 805\n",
      "round 806\n",
      "round 807\n",
      "round 808\n",
      "round 809\n",
      "round 810\n",
      "round 811\n",
      "round 812\n",
      "round 813\n",
      "round 814\n",
      "round 815\n",
      "round 816\n",
      "round 817\n",
      "round 818\n",
      "round 819\n",
      "round 820\n",
      "round 821\n",
      "round 822\n",
      "round 823\n",
      "round 824\n",
      "round 825\n",
      "round 826\n",
      "round 827\n",
      "round 828\n",
      "round 829\n",
      "round 830\n",
      "round 831\n",
      "round 832\n",
      "round 833\n",
      "round 834\n",
      "round 835\n",
      "round 836\n",
      "round 837\n",
      "round 838\n",
      "round 839\n",
      "round 840\n",
      "round 841\n",
      "round 842\n",
      "round 843\n",
      "round 844\n",
      "round 845\n",
      "round 846\n",
      "round 847\n",
      "round 848\n",
      "round 849\n",
      "round 850\n",
      "round 851\n",
      "round 852\n",
      "round 853\n",
      "round 854\n",
      "round 855\n",
      "round 856\n",
      "round 857\n",
      "round 858\n",
      "round 859\n",
      "round 860\n",
      "round 861\n",
      "round 862\n",
      "round 863\n",
      "round 864\n",
      "round 865\n",
      "round 866\n",
      "round 867\n",
      "round 868\n",
      "round 869\n",
      "round 870\n",
      "round 871\n",
      "round 872\n",
      "round 873\n",
      "round 874\n",
      "round 875\n",
      "round 876\n",
      "round 877\n",
      "round 878\n",
      "round 879\n",
      "round 880\n",
      "round 881\n",
      "round 882\n",
      "round 883\n",
      "round 884\n",
      "round 885\n",
      "round 886\n",
      "round 887\n",
      "round 888\n",
      "round 889\n",
      "round 890\n",
      "round 891\n",
      "round 892\n",
      "round 893\n",
      "round 894\n",
      "round 895\n",
      "round 896\n",
      "round 897\n",
      "round 898\n",
      "round 899\n",
      "round 900\n",
      "round 901\n",
      "round 902\n",
      "round 903\n",
      "round 904\n",
      "round 905\n",
      "round 906\n",
      "round 907\n",
      "round 908\n",
      "round 909\n",
      "round 910\n",
      "round 911\n",
      "round 912\n",
      "round 913\n",
      "round 914\n",
      "round 915\n",
      "round 916\n",
      "round 917\n",
      "round 918\n",
      "round 919\n",
      "round 920\n",
      "round 921\n",
      "round 922\n",
      "round 923\n",
      "round 924\n",
      "round 925\n",
      "round 926\n",
      "round 927\n",
      "round 928\n",
      "round 929\n",
      "round 930\n",
      "round 931\n",
      "round 932\n",
      "round 933\n",
      "round 934\n",
      "round 935\n",
      "round 936\n",
      "round 937\n",
      "round 938\n",
      "round 939\n",
      "round 940\n",
      "round 941\n",
      "round 942\n",
      "round 943\n",
      "round 944\n",
      "round 945\n",
      "round 946\n",
      "round 947\n",
      "round 948\n",
      "round 949\n",
      "round 950\n",
      "round 951\n",
      "round 952\n",
      "round 953\n",
      "round 954\n",
      "round 955\n",
      "round 956\n",
      "round 957\n",
      "round 958\n",
      "round 959\n",
      "round 960\n",
      "round 961\n",
      "round 962\n",
      "round 963\n",
      "round 964\n",
      "round 965\n",
      "round 966\n",
      "round 967\n",
      "round 968\n",
      "round 969\n",
      "round 970\n",
      "round 971\n",
      "round 972\n",
      "round 973\n",
      "round 974\n",
      "round 975\n",
      "round 976\n",
      "round 977\n",
      "round 978\n",
      "round 979\n",
      "round 980\n",
      "round 981\n",
      "round 982\n",
      "round 983\n",
      "round 984\n",
      "round 985\n",
      "round 986\n",
      "round 987\n",
      "round 988\n",
      "round 989\n",
      "round 990\n",
      "round 991\n",
      "round 992\n",
      "round 993\n",
      "round 994\n",
      "round 995\n",
      "round 996\n",
      "round 997\n",
      "round 998\n",
      "round 999\n",
      "total time is 19.68930983543396\n",
      "length of chain is 1000\n",
      "length of burn in is 100\n",
      "Use logit\n",
      "store is [[ 0.5545919   0.94290936  0.12283002 ...  0.4516154   0.35805783\n",
      "  -0.06817137]\n",
      " [ 0.13235012  0.885137   -0.01747383 ...  0.6286382   0.21571127\n",
      "   0.38853145]\n",
      " [ 0.6748328   0.9824591   0.03488395 ...  0.54253095  0.28727958\n",
      "   0.08141981]\n",
      " ...\n",
      " [ 0.53569496  0.9345211   0.09749886 ...  0.5132469   0.4516472\n",
      "   0.10385858]\n",
      " [ 0.48245606  1.2063515  -0.18794864 ...  0.5342562   0.4678578\n",
      "   0.17232323]\n",
      " [ 0.48245606  1.2063515  -0.18794864 ...  0.5342562   0.4678578\n",
      "   0.17232323]]\n",
      "sd is [0.1488344  0.16448209 0.13828941 0.15002802 0.15334743 0.14542078\n",
      " 0.16253107]\n",
      "mean is [ 0.3863887   1.0631996  -0.07397731  0.03689421  0.48102185  0.44703105\n",
      "  0.22126147]\n",
      "Inference for Stan model: anon_model_4bac8359d39f32cfa57c3e3acae076d2.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "          mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "beta[0]   0.38  2.4e-3   0.14    0.1   0.28   0.38   0.48   0.67   3495    1.0\n",
      "beta[1]   1.06  2.0e-3   0.13   0.82   0.98   1.06   1.14   1.32   4000    1.0\n",
      "beta[2]  -0.08  1.9e-3   0.12  -0.31  -0.16  -0.08 3.9e-3   0.16   4000    1.0\n",
      "beta[3]   0.04  2.2e-3   0.14  -0.24  -0.06   0.03   0.13   0.31   4000    1.0\n",
      "beta[4]   0.48  2.4e-3   0.15   0.19   0.38   0.48   0.58   0.78   3833    1.0\n",
      "beta[5]   0.45  1.9e-3   0.12   0.21   0.37   0.45   0.52   0.69   4000    1.0\n",
      "beta[6]   0.23  2.6e-3   0.15  -0.07   0.13   0.23   0.33   0.52   3278    1.0\n",
      "lp__    -275.6    0.04   1.83 -279.8 -276.7 -275.3 -274.2 -272.9   1804    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed May 23 04:02:22 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "%run -i \"newtestgnuts_logit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yiulau/miniconda2/envs/py36/lib/python3.6/site-packages/pystan/misc.py:399: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif np.issubdtype(np.asarray(v).dtype, float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n",
      "round 101\n",
      "round 102\n",
      "round 103\n",
      "round 104\n",
      "round 105\n",
      "round 106\n",
      "round 107\n",
      "round 108\n",
      "round 109\n",
      "round 110\n",
      "round 111\n",
      "round 112\n",
      "round 113\n",
      "round 114\n",
      "round 115\n",
      "round 116\n",
      "round 117\n",
      "round 118\n",
      "round 119\n",
      "round 120\n",
      "round 121\n",
      "round 122\n",
      "round 123\n",
      "round 124\n",
      "round 125\n",
      "round 126\n",
      "round 127\n",
      "round 128\n",
      "round 129\n",
      "round 130\n",
      "round 131\n",
      "round 132\n",
      "round 133\n",
      "round 134\n",
      "round 135\n",
      "round 136\n",
      "round 137\n",
      "round 138\n",
      "round 139\n",
      "round 140\n",
      "round 141\n",
      "round 142\n",
      "round 143\n",
      "round 144\n",
      "round 145\n",
      "round 146\n",
      "round 147\n",
      "round 148\n",
      "round 149\n",
      "round 150\n",
      "round 151\n",
      "round 152\n",
      "round 153\n",
      "round 154\n",
      "round 155\n",
      "round 156\n",
      "round 157\n",
      "round 158\n",
      "round 159\n",
      "round 160\n",
      "round 161\n",
      "round 162\n",
      "round 163\n",
      "round 164\n",
      "round 165\n",
      "round 166\n",
      "round 167\n",
      "round 168\n",
      "round 169\n",
      "round 170\n",
      "round 171\n",
      "round 172\n",
      "round 173\n",
      "round 174\n",
      "round 175\n",
      "round 176\n",
      "round 177\n",
      "round 178\n",
      "round 179\n",
      "round 180\n",
      "round 181\n",
      "round 182\n",
      "round 183\n",
      "round 184\n",
      "round 185\n",
      "round 186\n",
      "round 187\n",
      "round 188\n",
      "round 189\n",
      "round 190\n",
      "round 191\n",
      "round 192\n",
      "round 193\n",
      "round 194\n",
      "round 195\n",
      "round 196\n",
      "round 197\n",
      "round 198\n",
      "round 199\n",
      "round 200\n",
      "round 201\n",
      "round 202\n",
      "round 203\n",
      "round 204\n",
      "round 205\n",
      "round 206\n",
      "round 207\n",
      "round 208\n",
      "round 209\n",
      "round 210\n",
      "round 211\n",
      "round 212\n",
      "round 213\n",
      "round 214\n",
      "round 215\n",
      "round 216\n",
      "round 217\n",
      "round 218\n",
      "round 219\n",
      "round 220\n",
      "round 221\n",
      "round 222\n",
      "round 223\n",
      "round 224\n",
      "round 225\n",
      "round 226\n",
      "round 227\n",
      "round 228\n",
      "round 229\n",
      "round 230\n",
      "round 231\n",
      "round 232\n",
      "round 233\n",
      "round 234\n",
      "round 235\n",
      "round 236\n",
      "round 237\n",
      "round 238\n",
      "round 239\n",
      "round 240\n",
      "round 241\n",
      "round 242\n",
      "round 243\n",
      "round 244\n",
      "round 245\n",
      "round 246\n",
      "round 247\n",
      "round 248\n",
      "round 249\n",
      "round 250\n",
      "round 251\n",
      "round 252\n",
      "round 253\n",
      "round 254\n",
      "round 255\n",
      "round 256\n",
      "round 257\n",
      "round 258\n",
      "round 259\n",
      "round 260\n",
      "round 261\n",
      "round 262\n",
      "round 263\n",
      "round 264\n",
      "round 265\n",
      "round 266\n",
      "round 267\n",
      "round 268\n",
      "round 269\n",
      "round 270\n",
      "round 271\n",
      "round 272\n",
      "round 273\n",
      "round 274\n",
      "round 275\n",
      "round 276\n",
      "round 277\n",
      "round 278\n",
      "round 279\n",
      "round 280\n",
      "round 281\n",
      "round 282\n",
      "round 283\n",
      "round 284\n",
      "round 285\n",
      "round 286\n",
      "round 287\n",
      "round 288\n",
      "round 289\n",
      "round 290\n",
      "round 291\n",
      "round 292\n",
      "round 293\n",
      "round 294\n",
      "round 295\n",
      "round 296\n",
      "round 297\n",
      "round 298\n",
      "round 299\n",
      "round 300\n",
      "round 301\n",
      "round 302\n",
      "round 303\n",
      "round 304\n",
      "round 305\n",
      "round 306\n",
      "round 307\n",
      "round 308\n",
      "round 309\n",
      "round 310\n",
      "round 311\n",
      "round 312\n",
      "round 313\n",
      "round 314\n",
      "round 315\n",
      "round 316\n",
      "round 317\n",
      "round 318\n",
      "round 319\n",
      "round 320\n",
      "round 321\n",
      "round 322\n",
      "round 323\n",
      "round 324\n",
      "round 325\n",
      "round 326\n",
      "round 327\n",
      "round 328\n",
      "round 329\n",
      "round 330\n",
      "round 331\n",
      "round 332\n",
      "round 333\n",
      "round 334\n",
      "round 335\n",
      "round 336\n",
      "round 337\n",
      "round 338\n",
      "round 339\n",
      "round 340\n",
      "round 341\n",
      "round 342\n",
      "round 343\n",
      "round 344\n",
      "round 345\n",
      "round 346\n",
      "round 347\n",
      "round 348\n",
      "round 349\n",
      "round 350\n",
      "round 351\n",
      "round 352\n",
      "round 353\n",
      "round 354\n",
      "round 355\n",
      "round 356\n",
      "round 357\n",
      "round 358\n",
      "round 359\n",
      "round 360\n",
      "round 361\n",
      "round 362\n",
      "round 363\n",
      "round 364\n",
      "round 365\n",
      "round 366\n",
      "round 367\n",
      "round 368\n",
      "round 369\n",
      "round 370\n",
      "round 371\n",
      "round 372\n",
      "round 373\n",
      "round 374\n",
      "round 375\n",
      "round 376\n",
      "round 377\n",
      "round 378\n",
      "round 379\n",
      "round 380\n",
      "round 381\n",
      "round 382\n",
      "round 383\n",
      "round 384\n",
      "round 385\n",
      "round 386\n",
      "round 387\n",
      "round 388\n",
      "round 389\n",
      "round 390\n",
      "round 391\n",
      "round 392\n",
      "round 393\n",
      "round 394\n",
      "round 395\n",
      "round 396\n",
      "round 397\n",
      "round 398\n",
      "round 399\n",
      "round 400\n",
      "round 401\n",
      "round 402\n",
      "round 403\n",
      "round 404\n",
      "round 405\n",
      "round 406\n",
      "round 407\n",
      "round 408\n",
      "round 409\n",
      "round 410\n",
      "round 411\n",
      "round 412\n",
      "round 413\n",
      "round 414\n",
      "round 415\n",
      "round 416\n",
      "round 417\n",
      "round 418\n",
      "round 419\n",
      "round 420\n",
      "round 421\n",
      "round 422\n",
      "round 423\n",
      "round 424\n",
      "round 425\n",
      "round 426\n",
      "round 427\n",
      "round 428\n",
      "round 429\n",
      "round 430\n",
      "round 431\n",
      "round 432\n",
      "round 433\n",
      "round 434\n",
      "round 435\n",
      "round 436\n",
      "round 437\n",
      "round 438\n",
      "round 439\n",
      "round 440\n",
      "round 441\n",
      "round 442\n",
      "round 443\n",
      "round 444\n",
      "round 445\n",
      "round 446\n",
      "round 447\n",
      "round 448\n",
      "round 449\n",
      "round 450\n",
      "round 451\n",
      "round 452\n",
      "round 453\n",
      "round 454\n",
      "round 455\n",
      "round 456\n",
      "round 457\n",
      "round 458\n",
      "round 459\n",
      "round 460\n",
      "round 461\n",
      "round 462\n",
      "round 463\n",
      "round 464\n",
      "round 465\n",
      "round 466\n",
      "round 467\n",
      "round 468\n",
      "round 469\n",
      "round 470\n",
      "round 471\n",
      "round 472\n",
      "round 473\n",
      "round 474\n",
      "round 475\n",
      "round 476\n",
      "round 477\n",
      "round 478\n",
      "round 479\n",
      "round 480\n",
      "round 481\n",
      "round 482\n",
      "round 483\n",
      "round 484\n",
      "round 485\n",
      "round 486\n",
      "round 487\n",
      "round 488\n",
      "round 489\n",
      "round 490\n",
      "round 491\n",
      "round 492\n",
      "round 493\n",
      "round 494\n",
      "round 495\n",
      "round 496\n",
      "round 497\n",
      "round 498\n",
      "round 499\n",
      "round 500\n",
      "round 501\n",
      "round 502\n",
      "round 503\n",
      "round 504\n",
      "round 505\n",
      "round 506\n",
      "round 507\n",
      "round 508\n",
      "round 509\n",
      "round 510\n",
      "round 511\n",
      "round 512\n",
      "round 513\n",
      "round 514\n",
      "round 515\n",
      "round 516\n",
      "round 517\n",
      "round 518\n",
      "round 519\n",
      "round 520\n",
      "round 521\n",
      "round 522\n",
      "round 523\n",
      "round 524\n",
      "round 525\n",
      "round 526\n",
      "round 527\n",
      "round 528\n",
      "round 529\n",
      "round 530\n",
      "round 531\n",
      "round 532\n",
      "round 533\n",
      "round 534\n",
      "round 535\n",
      "round 536\n",
      "round 537\n",
      "round 538\n",
      "round 539\n",
      "round 540\n",
      "round 541\n",
      "round 542\n",
      "round 543\n",
      "round 544\n",
      "round 545\n",
      "round 546\n",
      "round 547\n",
      "round 548\n",
      "round 549\n",
      "round 550\n",
      "round 551\n",
      "round 552\n",
      "round 553\n",
      "round 554\n",
      "round 555\n",
      "round 556\n",
      "round 557\n",
      "round 558\n",
      "round 559\n",
      "round 560\n",
      "round 561\n",
      "round 562\n",
      "round 563\n",
      "round 564\n",
      "round 565\n",
      "round 566\n",
      "round 567\n",
      "round 568\n",
      "round 569\n",
      "round 570\n",
      "round 571\n",
      "round 572\n",
      "round 573\n",
      "round 574\n",
      "round 575\n",
      "round 576\n",
      "round 577\n",
      "round 578\n",
      "round 579\n",
      "round 580\n",
      "round 581\n",
      "round 582\n",
      "round 583\n",
      "round 584\n",
      "round 585\n",
      "round 586\n",
      "round 587\n",
      "round 588\n",
      "round 589\n",
      "round 590\n",
      "round 591\n",
      "round 592\n",
      "round 593\n",
      "round 594\n",
      "round 595\n",
      "round 596\n",
      "round 597\n",
      "round 598\n",
      "round 599\n",
      "round 600\n",
      "round 601\n",
      "round 602\n",
      "round 603\n",
      "round 604\n",
      "round 605\n",
      "round 606\n",
      "round 607\n",
      "round 608\n",
      "round 609\n",
      "round 610\n",
      "round 611\n",
      "round 612\n",
      "round 613\n",
      "round 614\n",
      "round 615\n",
      "round 616\n",
      "round 617\n",
      "round 618\n",
      "round 619\n",
      "round 620\n",
      "round 621\n",
      "round 622\n",
      "round 623\n",
      "round 624\n",
      "round 625\n",
      "round 626\n",
      "round 627\n",
      "round 628\n",
      "round 629\n",
      "round 630\n",
      "round 631\n",
      "round 632\n",
      "round 633\n",
      "round 634\n",
      "round 635\n",
      "round 636\n",
      "round 637\n",
      "round 638\n",
      "round 639\n",
      "round 640\n",
      "round 641\n",
      "round 642\n",
      "round 643\n",
      "round 644\n",
      "round 645\n",
      "round 646\n",
      "round 647\n",
      "round 648\n",
      "round 649\n",
      "round 650\n",
      "round 651\n",
      "round 652\n",
      "round 653\n",
      "round 654\n",
      "round 655\n",
      "round 656\n",
      "round 657\n",
      "round 658\n",
      "round 659\n",
      "round 660\n",
      "round 661\n",
      "round 662\n",
      "round 663\n",
      "round 664\n",
      "round 665\n",
      "round 666\n",
      "round 667\n",
      "round 668\n",
      "round 669\n",
      "round 670\n",
      "round 671\n",
      "round 672\n",
      "round 673\n",
      "round 674\n",
      "round 675\n",
      "round 676\n",
      "round 677\n",
      "round 678\n",
      "round 679\n",
      "round 680\n",
      "round 681\n",
      "round 682\n",
      "round 683\n",
      "round 684\n",
      "round 685\n",
      "round 686\n",
      "round 687\n",
      "round 688\n",
      "round 689\n",
      "round 690\n",
      "round 691\n",
      "round 692\n",
      "round 693\n",
      "round 694\n",
      "round 695\n",
      "round 696\n",
      "round 697\n",
      "round 698\n",
      "round 699\n",
      "round 700\n",
      "round 701\n",
      "round 702\n",
      "round 703\n",
      "round 704\n",
      "round 705\n",
      "round 706\n",
      "round 707\n",
      "round 708\n",
      "round 709\n",
      "round 710\n",
      "round 711\n",
      "round 712\n",
      "round 713\n",
      "round 714\n",
      "round 715\n",
      "round 716\n",
      "round 717\n",
      "round 718\n",
      "round 719\n",
      "round 720\n",
      "round 721\n",
      "round 722\n",
      "round 723\n",
      "round 724\n",
      "round 725\n",
      "round 726\n",
      "round 727\n",
      "round 728\n",
      "round 729\n",
      "round 730\n",
      "round 731\n",
      "round 732\n",
      "round 733\n",
      "round 734\n",
      "round 735\n",
      "round 736\n",
      "round 737\n",
      "round 738\n",
      "round 739\n",
      "round 740\n",
      "round 741\n",
      "round 742\n",
      "round 743\n",
      "round 744\n",
      "round 745\n",
      "round 746\n",
      "round 747\n",
      "round 748\n",
      "round 749\n",
      "round 750\n",
      "round 751\n",
      "round 752\n",
      "round 753\n",
      "round 754\n",
      "round 755\n",
      "round 756\n",
      "round 757\n",
      "round 758\n",
      "round 759\n",
      "round 760\n",
      "round 761\n",
      "round 762\n",
      "round 763\n",
      "round 764\n",
      "round 765\n",
      "round 766\n",
      "round 767\n",
      "round 768\n",
      "round 769\n",
      "round 770\n",
      "round 771\n",
      "round 772\n",
      "round 773\n",
      "round 774\n",
      "round 775\n",
      "round 776\n",
      "round 777\n",
      "round 778\n",
      "round 779\n",
      "round 780\n",
      "round 781\n",
      "round 782\n",
      "round 783\n",
      "round 784\n",
      "round 785\n",
      "round 786\n",
      "round 787\n",
      "round 788\n",
      "round 789\n",
      "round 790\n",
      "round 791\n",
      "round 792\n",
      "round 793\n",
      "round 794\n",
      "round 795\n",
      "round 796\n",
      "round 797\n",
      "round 798\n",
      "round 799\n",
      "round 800\n",
      "round 801\n",
      "round 802\n",
      "round 803\n",
      "round 804\n",
      "round 805\n",
      "round 806\n",
      "round 807\n",
      "round 808\n",
      "round 809\n",
      "round 810\n",
      "round 811\n",
      "round 812\n",
      "round 813\n",
      "round 814\n",
      "round 815\n",
      "round 816\n",
      "round 817\n",
      "round 818\n",
      "round 819\n",
      "round 820\n",
      "round 821\n",
      "round 822\n",
      "round 823\n",
      "round 824\n",
      "round 825\n",
      "round 826\n",
      "round 827\n",
      "round 828\n",
      "round 829\n",
      "round 830\n",
      "round 831\n",
      "round 832\n",
      "round 833\n",
      "round 834\n",
      "round 835\n",
      "round 836\n",
      "round 837\n",
      "round 838\n",
      "round 839\n",
      "round 840\n",
      "round 841\n",
      "round 842\n",
      "round 843\n",
      "round 844\n",
      "round 845\n",
      "round 846\n",
      "round 847\n",
      "round 848\n",
      "round 849\n",
      "round 850\n",
      "round 851\n",
      "round 852\n",
      "round 853\n",
      "round 854\n",
      "round 855\n",
      "round 856\n",
      "round 857\n",
      "round 858\n",
      "round 859\n",
      "round 860\n",
      "round 861\n",
      "round 862\n",
      "round 863\n",
      "round 864\n",
      "round 865\n",
      "round 866\n",
      "round 867\n",
      "round 868\n",
      "round 869\n",
      "round 870\n",
      "round 871\n",
      "round 872\n",
      "round 873\n",
      "round 874\n",
      "round 875\n",
      "round 876\n",
      "round 877\n",
      "round 878\n",
      "round 879\n",
      "round 880\n",
      "round 881\n",
      "round 882\n",
      "round 883\n",
      "round 884\n",
      "round 885\n",
      "round 886\n",
      "round 887\n",
      "round 888\n",
      "round 889\n",
      "round 890\n",
      "round 891\n",
      "round 892\n",
      "round 893\n",
      "round 894\n",
      "round 895\n",
      "round 896\n",
      "round 897\n",
      "round 898\n",
      "round 899\n",
      "round 900\n",
      "round 901\n",
      "round 902\n",
      "round 903\n",
      "round 904\n",
      "round 905\n",
      "round 906\n",
      "round 907\n",
      "round 908\n",
      "round 909\n",
      "round 910\n",
      "round 911\n",
      "round 912\n",
      "round 913\n",
      "round 914\n",
      "round 915\n",
      "round 916\n",
      "round 917\n",
      "round 918\n",
      "round 919\n",
      "round 920\n",
      "round 921\n",
      "round 922\n",
      "round 923\n",
      "round 924\n",
      "round 925\n",
      "round 926\n",
      "round 927\n",
      "round 928\n",
      "round 929\n",
      "round 930\n",
      "round 931\n",
      "round 932\n",
      "round 933\n",
      "round 934\n",
      "round 935\n",
      "round 936\n",
      "round 937\n",
      "round 938\n",
      "round 939\n",
      "round 940\n",
      "round 941\n",
      "round 942\n",
      "round 943\n",
      "round 944\n",
      "round 945\n",
      "round 946\n",
      "round 947\n",
      "round 948\n",
      "round 949\n",
      "round 950\n",
      "round 951\n",
      "round 952\n",
      "round 953\n",
      "round 954\n",
      "round 955\n",
      "round 956\n",
      "round 957\n",
      "round 958\n",
      "round 959\n",
      "round 960\n",
      "round 961\n",
      "round 962\n",
      "round 963\n",
      "round 964\n",
      "round 965\n",
      "round 966\n",
      "round 967\n",
      "round 968\n",
      "round 969\n",
      "round 970\n",
      "round 971\n",
      "round 972\n",
      "round 973\n",
      "round 974\n",
      "round 975\n",
      "round 976\n",
      "round 977\n",
      "round 978\n",
      "round 979\n",
      "round 980\n",
      "round 981\n",
      "round 982\n",
      "round 983\n",
      "round 984\n",
      "round 985\n",
      "round 986\n",
      "round 987\n",
      "round 988\n",
      "round 989\n",
      "round 990\n",
      "round 991\n",
      "round 992\n",
      "round 993\n",
      "round 994\n",
      "round 995\n",
      "round 996\n",
      "round 997\n",
      "round 998\n",
      "round 999\n",
      "total time is 204.51971197128296\n",
      "length of chain is 1000\n",
      "length of burn in is 100\n",
      "Use logit\n",
      "sd is [0.16858246 0.15795726 0.14688041 0.18840669 0.19468309 0.13468624\n",
      " 0.16897973]\n",
      "mean is [ 0.38772336  1.0705019  -0.08112004  0.03989254  0.46787357  0.44921958\n",
      "  0.22835797]\n",
      "Inference for Stan model: anon_model_4bac8359d39f32cfa57c3e3acae076d2.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "          mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "beta[0]   0.38  2.3e-3   0.15   0.09   0.28   0.38   0.48   0.67   4000    1.0\n",
      "beta[1]   1.06  2.1e-3   0.13   0.81   0.97   1.06   1.14   1.32   4000    1.0\n",
      "beta[2]  -0.08  1.9e-3   0.12  -0.31  -0.16  -0.08 2.6e-4   0.15   4000    1.0\n",
      "beta[3]   0.04  2.3e-3   0.14  -0.24  -0.06   0.03   0.13   0.32   4000    1.0\n",
      "beta[4]   0.47  2.3e-3   0.15   0.19   0.38   0.48   0.57   0.76   4000    1.0\n",
      "beta[5]   0.44  1.9e-3   0.12   0.21   0.36   0.45   0.53   0.69   4000    1.0\n",
      "beta[6]   0.23  2.5e-3   0.15  -0.06   0.12   0.23   0.33   0.54   3594    1.0\n",
      "lp__    -275.6    0.04   1.88 -280.2 -276.6 -275.3 -274.3 -272.9   1813    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed May 23 04:02:46 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "%run -i \"newtestnuts_logit.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n",
      "round 101\n",
      "round 102\n",
      "round 103\n",
      "round 104\n",
      "round 105\n",
      "round 106\n",
      "round 107\n",
      "round 108\n",
      "round 109\n",
      "round 110\n",
      "round 111\n",
      "round 112\n",
      "round 113\n",
      "round 114\n",
      "round 115\n",
      "round 116\n",
      "round 117\n",
      "round 118\n",
      "round 119\n",
      "round 120\n",
      "round 121\n",
      "round 122\n",
      "round 123\n",
      "round 124\n",
      "round 125\n",
      "round 126\n",
      "round 127\n",
      "round 128\n",
      "round 129\n",
      "round 130\n",
      "round 131\n",
      "round 132\n",
      "round 133\n",
      "round 134\n",
      "round 135\n",
      "round 136\n",
      "round 137\n",
      "round 138\n",
      "round 139\n",
      "round 140\n",
      "round 141\n",
      "round 142\n",
      "round 143\n",
      "round 144\n",
      "round 145\n",
      "round 146\n",
      "round 147\n",
      "round 148\n",
      "round 149\n",
      "round 150\n",
      "round 151\n",
      "round 152\n",
      "round 153\n",
      "round 154\n",
      "round 155\n",
      "round 156\n",
      "round 157\n",
      "round 158\n",
      "round 159\n",
      "round 160\n",
      "round 161\n",
      "round 162\n",
      "round 163\n",
      "round 164\n",
      "round 165\n",
      "round 166\n",
      "round 167\n",
      "round 168\n",
      "round 169\n",
      "round 170\n",
      "round 171\n",
      "round 172\n",
      "round 173\n",
      "round 174\n",
      "round 175\n",
      "round 176\n",
      "round 177\n",
      "round 178\n",
      "round 179\n",
      "round 180\n",
      "round 181\n",
      "round 182\n",
      "round 183\n",
      "round 184\n",
      "round 185\n",
      "round 186\n",
      "round 187\n",
      "round 188\n",
      "round 189\n",
      "round 190\n",
      "round 191\n",
      "round 192\n",
      "round 193\n",
      "round 194\n",
      "round 195\n",
      "round 196\n",
      "round 197\n",
      "round 198\n",
      "round 199\n",
      "round 200\n",
      "round 201\n",
      "round 202\n",
      "round 203\n",
      "round 204\n",
      "round 205\n",
      "round 206\n",
      "round 207\n",
      "round 208\n",
      "round 209\n",
      "round 210\n",
      "round 211\n",
      "round 212\n",
      "round 213\n",
      "round 214\n",
      "round 215\n",
      "round 216\n",
      "round 217\n",
      "round 218\n",
      "round 219\n",
      "round 220\n",
      "round 221\n",
      "round 222\n",
      "round 223\n",
      "round 224\n",
      "round 225\n",
      "round 226\n",
      "round 227\n",
      "round 228\n",
      "round 229\n",
      "round 230\n",
      "round 231\n",
      "round 232\n",
      "round 233\n",
      "round 234\n",
      "round 235\n",
      "round 236\n",
      "round 237\n",
      "round 238\n",
      "round 239\n",
      "round 240\n",
      "round 241\n",
      "round 242\n",
      "round 243\n",
      "round 244\n",
      "round 245\n",
      "round 246\n",
      "round 247\n",
      "round 248\n",
      "round 249\n",
      "round 250\n",
      "round 251\n",
      "round 252\n",
      "round 253\n",
      "round 254\n",
      "round 255\n",
      "round 256\n",
      "round 257\n",
      "round 258\n",
      "round 259\n",
      "round 260\n",
      "round 261\n",
      "round 262\n",
      "round 263\n",
      "round 264\n",
      "round 265\n",
      "round 266\n",
      "round 267\n",
      "round 268\n",
      "round 269\n",
      "round 270\n",
      "round 271\n",
      "round 272\n",
      "round 273\n",
      "round 274\n",
      "round 275\n",
      "round 276\n",
      "round 277\n",
      "round 278\n",
      "round 279\n",
      "round 280\n",
      "round 281\n",
      "round 282\n",
      "round 283\n",
      "round 284\n",
      "round 285\n",
      "round 286\n",
      "round 287\n",
      "round 288\n",
      "round 289\n",
      "round 290\n",
      "round 291\n",
      "round 292\n",
      "round 293\n",
      "round 294\n",
      "round 295\n",
      "round 296\n",
      "round 297\n",
      "round 298\n",
      "round 299\n",
      "round 300\n",
      "round 301\n",
      "round 302\n",
      "round 303\n",
      "round 304\n",
      "round 305\n",
      "round 306\n",
      "round 307\n",
      "round 308\n",
      "round 309\n",
      "round 310\n",
      "round 311\n",
      "round 312\n",
      "round 313\n",
      "round 314\n",
      "round 315\n",
      "round 316\n",
      "round 317\n",
      "round 318\n",
      "round 319\n",
      "round 320\n",
      "round 321\n",
      "round 322\n",
      "round 323\n",
      "round 324\n",
      "round 325\n",
      "round 326\n",
      "round 327\n",
      "round 328\n",
      "round 329\n",
      "round 330\n",
      "round 331\n",
      "round 332\n",
      "round 333\n",
      "round 334\n",
      "round 335\n",
      "round 336\n",
      "round 337\n",
      "round 338\n",
      "round 339\n",
      "round 340\n",
      "round 341\n",
      "round 342\n",
      "round 343\n",
      "round 344\n",
      "round 345\n",
      "round 346\n",
      "round 347\n",
      "round 348\n",
      "round 349\n",
      "round 350\n",
      "round 351\n",
      "round 352\n",
      "round 353\n",
      "round 354\n",
      "round 355\n",
      "round 356\n",
      "round 357\n",
      "round 358\n",
      "round 359\n",
      "round 360\n",
      "round 361\n",
      "round 362\n",
      "round 363\n",
      "round 364\n",
      "round 365\n",
      "round 366\n",
      "round 367\n",
      "round 368\n",
      "round 369\n",
      "round 370\n",
      "round 371\n",
      "round 372\n",
      "round 373\n",
      "round 374\n",
      "round 375\n",
      "round 376\n",
      "round 377\n",
      "round 378\n",
      "round 379\n",
      "round 380\n",
      "round 381\n",
      "round 382\n",
      "round 383\n",
      "round 384\n",
      "round 385\n",
      "round 386\n",
      "round 387\n",
      "round 388\n",
      "round 389\n",
      "round 390\n",
      "round 391\n",
      "round 392\n",
      "round 393\n",
      "round 394\n",
      "round 395\n",
      "round 396\n",
      "round 397\n",
      "round 398\n",
      "round 399\n",
      "round 400\n",
      "round 401\n",
      "round 402\n",
      "round 403\n",
      "round 404\n",
      "round 405\n",
      "round 406\n",
      "round 407\n",
      "round 408\n",
      "round 409\n",
      "round 410\n",
      "round 411\n",
      "round 412\n",
      "round 413\n",
      "round 414\n",
      "round 415\n",
      "round 416\n",
      "round 417\n",
      "round 418\n",
      "round 419\n",
      "round 420\n",
      "round 421\n",
      "round 422\n",
      "round 423\n",
      "round 424\n",
      "round 425\n",
      "round 426\n",
      "round 427\n",
      "round 428\n",
      "round 429\n",
      "round 430\n",
      "round 431\n",
      "round 432\n",
      "round 433\n",
      "round 434\n",
      "round 435\n",
      "round 436\n",
      "round 437\n",
      "round 438\n",
      "round 439\n",
      "round 440\n",
      "round 441\n",
      "round 442\n",
      "round 443\n",
      "round 444\n",
      "round 445\n",
      "round 446\n",
      "round 447\n",
      "round 448\n",
      "round 449\n",
      "round 450\n",
      "round 451\n",
      "round 452\n",
      "round 453\n",
      "round 454\n",
      "round 455\n",
      "round 456\n",
      "round 457\n",
      "round 458\n",
      "round 459\n",
      "round 460\n",
      "round 461\n",
      "round 462\n",
      "round 463\n",
      "round 464\n",
      "round 465\n",
      "round 466\n",
      "round 467\n",
      "round 468\n",
      "round 469\n",
      "round 470\n",
      "round 471\n",
      "round 472\n",
      "round 473\n",
      "round 474\n",
      "round 475\n",
      "round 476\n",
      "round 477\n",
      "round 478\n",
      "round 479\n",
      "round 480\n",
      "round 481\n",
      "round 482\n",
      "round 483\n",
      "round 484\n",
      "round 485\n",
      "round 486\n",
      "round 487\n",
      "round 488\n",
      "round 489\n",
      "round 490\n",
      "round 491\n",
      "round 492\n",
      "round 493\n",
      "round 494\n",
      "round 495\n",
      "round 496\n",
      "round 497\n",
      "round 498\n",
      "round 499\n",
      "round 500\n",
      "round 501\n",
      "round 502\n",
      "round 503\n",
      "round 504\n",
      "round 505\n",
      "round 506\n",
      "round 507\n",
      "round 508\n",
      "round 509\n",
      "round 510\n",
      "round 511\n",
      "round 512\n",
      "round 513\n",
      "round 514\n",
      "round 515\n",
      "round 516\n",
      "round 517\n",
      "round 518\n",
      "round 519\n",
      "round 520\n",
      "round 521\n",
      "round 522\n",
      "round 523\n",
      "round 524\n",
      "round 525\n",
      "round 526\n",
      "round 527\n",
      "round 528\n",
      "round 529\n",
      "round 530\n",
      "round 531\n",
      "round 532\n",
      "round 533\n",
      "round 534\n",
      "round 535\n",
      "round 536\n",
      "round 537\n",
      "round 538\n",
      "round 539\n",
      "round 540\n",
      "round 541\n",
      "round 542\n",
      "round 543\n",
      "round 544\n",
      "round 545\n",
      "round 546\n",
      "round 547\n",
      "round 548\n",
      "round 549\n",
      "round 550\n",
      "round 551\n",
      "round 552\n",
      "round 553\n",
      "round 554\n",
      "round 555\n",
      "round 556\n",
      "round 557\n",
      "round 558\n",
      "round 559\n",
      "round 560\n",
      "round 561\n",
      "round 562\n",
      "round 563\n",
      "round 564\n",
      "round 565\n",
      "round 566\n",
      "round 567\n",
      "round 568\n",
      "round 569\n",
      "round 570\n",
      "round 571\n",
      "round 572\n",
      "round 573\n",
      "round 574\n",
      "round 575\n",
      "round 576\n",
      "round 577\n",
      "round 578\n",
      "round 579\n",
      "round 580\n",
      "round 581\n",
      "round 582\n",
      "round 583\n",
      "round 584\n",
      "round 585\n",
      "round 586\n",
      "round 587\n",
      "round 588\n",
      "round 589\n",
      "round 590\n",
      "round 591\n",
      "round 592\n",
      "round 593\n",
      "round 594\n",
      "round 595\n",
      "round 596\n",
      "round 597\n",
      "round 598\n",
      "round 599\n",
      "round 600\n",
      "round 601\n",
      "round 602\n",
      "round 603\n",
      "round 604\n",
      "round 605\n",
      "round 606\n",
      "round 607\n",
      "round 608\n",
      "round 609\n",
      "round 610\n",
      "round 611\n",
      "round 612\n",
      "round 613\n",
      "round 614\n",
      "round 615\n",
      "round 616\n",
      "round 617\n",
      "round 618\n",
      "round 619\n",
      "round 620\n",
      "round 621\n",
      "round 622\n",
      "round 623\n",
      "round 624\n",
      "round 625\n",
      "round 626\n",
      "round 627\n",
      "round 628\n",
      "round 629\n",
      "round 630\n",
      "round 631\n",
      "round 632\n",
      "round 633\n",
      "round 634\n",
      "round 635\n",
      "round 636\n",
      "round 637\n",
      "round 638\n",
      "round 639\n",
      "round 640\n",
      "round 641\n",
      "round 642\n",
      "round 643\n",
      "round 644\n",
      "round 645\n",
      "round 646\n",
      "round 647\n",
      "round 648\n",
      "round 649\n",
      "round 650\n",
      "round 651\n",
      "round 652\n",
      "round 653\n",
      "round 654\n",
      "round 655\n",
      "round 656\n",
      "round 657\n",
      "round 658\n",
      "round 659\n",
      "round 660\n",
      "round 661\n",
      "round 662\n",
      "round 663\n",
      "round 664\n",
      "round 665\n",
      "round 666\n",
      "round 667\n",
      "round 668\n",
      "round 669\n",
      "round 670\n",
      "round 671\n",
      "round 672\n",
      "round 673\n",
      "round 674\n",
      "round 675\n",
      "round 676\n",
      "round 677\n",
      "round 678\n",
      "round 679\n",
      "round 680\n",
      "round 681\n",
      "round 682\n",
      "round 683\n",
      "round 684\n",
      "round 685\n",
      "round 686\n",
      "round 687\n",
      "round 688\n",
      "round 689\n",
      "round 690\n",
      "round 691\n",
      "round 692\n",
      "round 693\n",
      "round 694\n",
      "round 695\n",
      "round 696\n",
      "round 697\n",
      "round 698\n",
      "round 699\n",
      "round 700\n",
      "round 701\n",
      "round 702\n",
      "round 703\n",
      "round 704\n",
      "round 705\n",
      "round 706\n",
      "round 707\n",
      "round 708\n",
      "round 709\n",
      "round 710\n",
      "round 711\n",
      "round 712\n",
      "round 713\n",
      "round 714\n",
      "round 715\n",
      "round 716\n",
      "round 717\n",
      "round 718\n",
      "round 719\n",
      "round 720\n",
      "round 721\n",
      "round 722\n",
      "round 723\n",
      "round 724\n",
      "round 725\n",
      "round 726\n",
      "round 727\n",
      "round 728\n",
      "round 729\n",
      "round 730\n",
      "round 731\n",
      "round 732\n",
      "round 733\n",
      "round 734\n",
      "round 735\n",
      "round 736\n",
      "round 737\n",
      "round 738\n",
      "round 739\n",
      "round 740\n",
      "round 741\n",
      "round 742\n",
      "round 743\n",
      "round 744\n",
      "round 745\n",
      "round 746\n",
      "round 747\n",
      "round 748\n",
      "round 749\n",
      "round 750\n",
      "round 751\n",
      "round 752\n",
      "round 753\n",
      "round 754\n",
      "round 755\n",
      "round 756\n",
      "round 757\n",
      "round 758\n",
      "round 759\n",
      "round 760\n",
      "round 761\n",
      "round 762\n",
      "round 763\n",
      "round 764\n",
      "round 765\n",
      "round 766\n",
      "round 767\n",
      "round 768\n",
      "round 769\n",
      "round 770\n",
      "round 771\n",
      "round 772\n",
      "round 773\n",
      "round 774\n",
      "round 775\n",
      "round 776\n",
      "round 777\n",
      "round 778\n",
      "round 779\n",
      "round 780\n",
      "round 781\n",
      "round 782\n",
      "round 783\n",
      "round 784\n",
      "round 785\n",
      "round 786\n",
      "round 787\n",
      "round 788\n",
      "round 789\n",
      "round 790\n",
      "round 791\n",
      "round 792\n",
      "round 793\n",
      "round 794\n",
      "round 795\n",
      "round 796\n",
      "round 797\n",
      "round 798\n",
      "round 799\n",
      "round 800\n",
      "round 801\n",
      "round 802\n",
      "round 803\n",
      "round 804\n",
      "round 805\n",
      "round 806\n",
      "round 807\n",
      "round 808\n",
      "round 809\n",
      "round 810\n",
      "round 811\n",
      "round 812\n",
      "round 813\n",
      "round 814\n",
      "round 815\n",
      "round 816\n",
      "round 817\n",
      "round 818\n",
      "round 819\n",
      "round 820\n",
      "round 821\n",
      "round 822\n",
      "round 823\n",
      "round 824\n",
      "round 825\n",
      "round 826\n",
      "round 827\n",
      "round 828\n",
      "round 829\n",
      "round 830\n",
      "round 831\n",
      "round 832\n",
      "round 833\n",
      "round 834\n",
      "round 835\n",
      "round 836\n",
      "round 837\n",
      "round 838\n",
      "round 839\n",
      "round 840\n",
      "round 841\n",
      "round 842\n",
      "round 843\n",
      "round 844\n",
      "round 845\n",
      "round 846\n",
      "round 847\n",
      "round 848\n",
      "round 849\n",
      "round 850\n",
      "round 851\n",
      "round 852\n",
      "round 853\n",
      "round 854\n",
      "round 855\n",
      "round 856\n",
      "round 857\n",
      "round 858\n",
      "round 859\n",
      "round 860\n",
      "round 861\n",
      "round 862\n",
      "round 863\n",
      "round 864\n",
      "round 865\n",
      "round 866\n",
      "round 867\n",
      "round 868\n",
      "round 869\n",
      "round 870\n",
      "round 871\n",
      "round 872\n",
      "round 873\n",
      "round 874\n",
      "round 875\n",
      "round 876\n",
      "round 877\n",
      "round 878\n",
      "round 879\n",
      "round 880\n",
      "round 881\n",
      "round 882\n",
      "round 883\n",
      "round 884\n",
      "round 885\n",
      "round 886\n",
      "round 887\n",
      "round 888\n",
      "round 889\n",
      "round 890\n",
      "round 891\n",
      "round 892\n",
      "round 893\n",
      "round 894\n",
      "round 895\n",
      "round 896\n",
      "round 897\n",
      "round 898\n",
      "round 899\n",
      "round 900\n",
      "round 901\n",
      "round 902\n",
      "round 903\n",
      "round 904\n",
      "round 905\n",
      "round 906\n",
      "round 907\n",
      "round 908\n",
      "round 909\n",
      "round 910\n",
      "round 911\n",
      "round 912\n",
      "round 913\n",
      "round 914\n",
      "round 915\n",
      "round 916\n",
      "round 917\n",
      "round 918\n",
      "round 919\n",
      "round 920\n",
      "round 921\n",
      "round 922\n",
      "round 923\n",
      "round 924\n",
      "round 925\n",
      "round 926\n",
      "round 927\n",
      "round 928\n",
      "round 929\n",
      "round 930\n",
      "round 931\n",
      "round 932\n",
      "round 933\n",
      "round 934\n",
      "round 935\n",
      "round 936\n",
      "round 937\n",
      "round 938\n",
      "round 939\n",
      "round 940\n",
      "round 941\n",
      "round 942\n",
      "round 943\n",
      "round 944\n",
      "round 945\n",
      "round 946\n",
      "round 947\n",
      "round 948\n",
      "round 949\n",
      "round 950\n",
      "round 951\n",
      "round 952\n",
      "round 953\n",
      "round 954\n",
      "round 955\n",
      "round 956\n",
      "round 957\n",
      "round 958\n",
      "round 959\n",
      "round 960\n",
      "round 961\n",
      "round 962\n",
      "round 963\n",
      "round 964\n",
      "round 965\n",
      "round 966\n",
      "round 967\n",
      "round 968\n",
      "round 969\n",
      "round 970\n",
      "round 971\n",
      "round 972\n",
      "round 973\n",
      "round 974\n",
      "round 975\n",
      "round 976\n",
      "round 977\n",
      "round 978\n",
      "round 979\n",
      "round 980\n",
      "round 981\n",
      "round 982\n",
      "round 983\n",
      "round 984\n",
      "round 985\n",
      "round 986\n",
      "round 987\n",
      "round 988\n",
      "round 989\n",
      "round 990\n",
      "round 991\n",
      "round 992\n",
      "round 993\n",
      "round 994\n",
      "round 995\n",
      "round 996\n",
      "round 997\n",
      "round 998\n",
      "round 999\n",
      "length of chain is 1000\n",
      "burn in is 100\n",
      "total time is 13.53831434249878\n",
      "sd is [0.16449406 0.14158544 0.13222733 0.15391546 0.1530106  0.12377058\n",
      " 0.16951694]\n",
      "mean is [ 0.3682487   1.0685315  -0.0826544   0.04812541  0.49378964  0.45017347\n",
      "  0.21361074]\n",
      "Inference for Stan model: anon_model_4bac8359d39f32cfa57c3e3acae076d2.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "          mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "beta[0]   0.38  2.3e-3   0.15   0.09   0.28   0.38   0.48   0.67   4000    1.0\n",
      "beta[1]   1.06  2.1e-3   0.13   0.81   0.97   1.06   1.14   1.32   4000    1.0\n",
      "beta[2]  -0.08  1.9e-3   0.12  -0.31  -0.16  -0.08 2.6e-4   0.15   4000    1.0\n",
      "beta[3]   0.04  2.3e-3   0.14  -0.24  -0.06   0.03   0.13   0.32   4000    1.0\n",
      "beta[4]   0.47  2.3e-3   0.15   0.19   0.38   0.48   0.57   0.76   4000    1.0\n",
      "beta[5]   0.44  1.9e-3   0.12   0.21   0.36   0.45   0.53   0.69   4000    1.0\n",
      "beta[6]   0.23  2.5e-3   0.15  -0.06   0.12   0.23   0.33   0.54   3594    1.0\n",
      "lp__    -275.6    0.04   1.88 -280.2 -276.6 -275.3 -274.3 -272.9   1813    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed May 23 04:02:46 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "%run -i \"newtestwindowed_hmc.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round 0\n",
      "round 1\n",
      "round 2\n",
      "round 3\n",
      "round 4\n",
      "round 5\n",
      "round 6\n",
      "round 7\n",
      "round 8\n",
      "round 9\n",
      "round 10\n",
      "round 11\n",
      "round 12\n",
      "round 13\n",
      "round 14\n",
      "round 15\n",
      "round 16\n",
      "round 17\n",
      "round 18\n",
      "round 19\n",
      "round 20\n",
      "round 21\n",
      "round 22\n",
      "round 23\n",
      "round 24\n",
      "round 25\n",
      "round 26\n",
      "round 27\n",
      "round 28\n",
      "round 29\n",
      "round 30\n",
      "round 31\n",
      "round 32\n",
      "round 33\n",
      "round 34\n",
      "round 35\n",
      "round 36\n",
      "round 37\n",
      "round 38\n",
      "round 39\n",
      "round 40\n",
      "round 41\n",
      "round 42\n",
      "round 43\n",
      "round 44\n",
      "round 45\n",
      "round 46\n",
      "round 47\n",
      "round 48\n",
      "round 49\n",
      "round 50\n",
      "round 51\n",
      "round 52\n",
      "round 53\n",
      "round 54\n",
      "round 55\n",
      "round 56\n",
      "round 57\n",
      "round 58\n",
      "round 59\n",
      "round 60\n",
      "round 61\n",
      "round 62\n",
      "round 63\n",
      "round 64\n",
      "round 65\n",
      "round 66\n",
      "round 67\n",
      "round 68\n",
      "round 69\n",
      "round 70\n",
      "round 71\n",
      "round 72\n",
      "round 73\n",
      "round 74\n",
      "round 75\n",
      "round 76\n",
      "round 77\n",
      "round 78\n",
      "round 79\n",
      "round 80\n",
      "round 81\n",
      "round 82\n",
      "round 83\n",
      "round 84\n",
      "round 85\n",
      "round 86\n",
      "round 87\n",
      "round 88\n",
      "round 89\n",
      "round 90\n",
      "round 91\n",
      "round 92\n",
      "round 93\n",
      "round 94\n",
      "round 95\n",
      "round 96\n",
      "round 97\n",
      "round 98\n",
      "round 99\n",
      "round 100\n",
      "round 101\n",
      "round 102\n",
      "round 103\n",
      "round 104\n",
      "round 105\n",
      "round 106\n",
      "round 107\n",
      "round 108\n",
      "round 109\n",
      "round 110\n",
      "round 111\n",
      "round 112\n",
      "round 113\n",
      "round 114\n",
      "round 115\n",
      "round 116\n",
      "round 117\n",
      "round 118\n",
      "round 119\n",
      "round 120\n",
      "round 121\n",
      "round 122\n",
      "round 123\n",
      "round 124\n",
      "round 125\n",
      "round 126\n",
      "round 127\n",
      "round 128\n",
      "round 129\n",
      "round 130\n",
      "round 131\n",
      "round 132\n",
      "round 133\n",
      "round 134\n",
      "round 135\n",
      "round 136\n",
      "round 137\n",
      "round 138\n",
      "round 139\n",
      "round 140\n",
      "round 141\n",
      "round 142\n",
      "round 143\n",
      "round 144\n",
      "round 145\n",
      "round 146\n",
      "round 147\n",
      "round 148\n",
      "round 149\n",
      "round 150\n",
      "round 151\n",
      "round 152\n",
      "round 153\n",
      "round 154\n",
      "round 155\n",
      "round 156\n",
      "round 157\n",
      "round 158\n",
      "round 159\n",
      "round 160\n",
      "round 161\n",
      "round 162\n",
      "round 163\n",
      "round 164\n",
      "round 165\n",
      "round 166\n",
      "round 167\n",
      "round 168\n",
      "round 169\n",
      "round 170\n",
      "round 171\n",
      "round 172\n",
      "round 173\n",
      "round 174\n",
      "round 175\n",
      "round 176\n",
      "round 177\n",
      "round 178\n",
      "round 179\n",
      "round 180\n",
      "round 181\n",
      "round 182\n",
      "round 183\n",
      "round 184\n",
      "round 185\n",
      "round 186\n",
      "round 187\n",
      "round 188\n",
      "round 189\n",
      "round 190\n",
      "round 191\n",
      "round 192\n",
      "round 193\n",
      "round 194\n",
      "round 195\n",
      "round 196\n",
      "round 197\n",
      "round 198\n",
      "round 199\n",
      "round 200\n",
      "round 201\n",
      "round 202\n",
      "round 203\n",
      "round 204\n",
      "round 205\n",
      "round 206\n",
      "round 207\n",
      "round 208\n",
      "round 209\n",
      "round 210\n",
      "round 211\n",
      "round 212\n",
      "round 213\n",
      "round 214\n",
      "round 215\n",
      "round 216\n",
      "round 217\n",
      "round 218\n",
      "round 219\n",
      "round 220\n",
      "round 221\n",
      "round 222\n",
      "round 223\n",
      "round 224\n",
      "round 225\n",
      "round 226\n",
      "round 227\n",
      "round 228\n",
      "round 229\n",
      "round 230\n",
      "round 231\n",
      "round 232\n",
      "round 233\n",
      "round 234\n",
      "round 235\n",
      "round 236\n",
      "round 237\n",
      "round 238\n",
      "round 239\n",
      "round 240\n",
      "round 241\n",
      "round 242\n",
      "round 243\n",
      "round 244\n",
      "round 245\n",
      "round 246\n",
      "round 247\n",
      "round 248\n",
      "round 249\n",
      "round 250\n",
      "round 251\n",
      "round 252\n",
      "round 253\n",
      "round 254\n",
      "round 255\n",
      "round 256\n",
      "round 257\n",
      "round 258\n",
      "round 259\n",
      "round 260\n",
      "round 261\n",
      "round 262\n",
      "round 263\n",
      "round 264\n",
      "round 265\n",
      "round 266\n",
      "round 267\n",
      "round 268\n",
      "round 269\n",
      "round 270\n",
      "round 271\n",
      "round 272\n",
      "round 273\n",
      "round 274\n",
      "round 275\n",
      "round 276\n",
      "round 277\n",
      "round 278\n",
      "round 279\n",
      "round 280\n",
      "round 281\n",
      "round 282\n",
      "round 283\n",
      "round 284\n",
      "round 285\n",
      "round 286\n",
      "round 287\n",
      "round 288\n",
      "round 289\n",
      "round 290\n",
      "round 291\n",
      "round 292\n",
      "round 293\n",
      "round 294\n",
      "round 295\n",
      "round 296\n",
      "round 297\n",
      "round 298\n",
      "round 299\n",
      "round 300\n",
      "round 301\n",
      "round 302\n",
      "round 303\n",
      "round 304\n",
      "round 305\n",
      "round 306\n",
      "round 307\n",
      "round 308\n",
      "round 309\n",
      "round 310\n",
      "round 311\n",
      "round 312\n",
      "round 313\n",
      "round 314\n",
      "round 315\n",
      "round 316\n",
      "round 317\n",
      "round 318\n",
      "round 319\n",
      "round 320\n",
      "round 321\n",
      "round 322\n",
      "round 323\n",
      "round 324\n",
      "round 325\n",
      "round 326\n",
      "round 327\n",
      "round 328\n",
      "round 329\n",
      "round 330\n",
      "round 331\n",
      "round 332\n",
      "round 333\n",
      "round 334\n",
      "round 335\n",
      "round 336\n",
      "round 337\n",
      "round 338\n",
      "round 339\n",
      "round 340\n",
      "round 341\n",
      "round 342\n",
      "round 343\n",
      "round 344\n",
      "round 345\n",
      "round 346\n",
      "round 347\n",
      "round 348\n",
      "round 349\n",
      "round 350\n",
      "round 351\n",
      "round 352\n",
      "round 353\n",
      "round 354\n",
      "round 355\n",
      "round 356\n",
      "round 357\n",
      "round 358\n",
      "round 359\n",
      "round 360\n",
      "round 361\n",
      "round 362\n",
      "round 363\n",
      "round 364\n",
      "round 365\n",
      "round 366\n",
      "round 367\n",
      "round 368\n",
      "round 369\n",
      "round 370\n",
      "round 371\n",
      "round 372\n",
      "round 373\n",
      "round 374\n",
      "round 375\n",
      "round 376\n",
      "round 377\n",
      "round 378\n",
      "round 379\n",
      "round 380\n",
      "round 381\n",
      "round 382\n",
      "round 383\n",
      "round 384\n",
      "round 385\n",
      "round 386\n",
      "round 387\n",
      "round 388\n",
      "round 389\n",
      "round 390\n",
      "round 391\n",
      "round 392\n",
      "round 393\n",
      "round 394\n",
      "round 395\n",
      "round 396\n",
      "round 397\n",
      "round 398\n",
      "round 399\n",
      "round 400\n",
      "round 401\n",
      "round 402\n",
      "round 403\n",
      "round 404\n",
      "round 405\n",
      "round 406\n",
      "round 407\n",
      "round 408\n",
      "round 409\n",
      "round 410\n",
      "round 411\n",
      "round 412\n",
      "round 413\n",
      "round 414\n",
      "round 415\n",
      "round 416\n",
      "round 417\n",
      "round 418\n",
      "round 419\n",
      "round 420\n",
      "round 421\n",
      "round 422\n",
      "round 423\n",
      "round 424\n",
      "round 425\n",
      "round 426\n",
      "round 427\n",
      "round 428\n",
      "round 429\n",
      "round 430\n",
      "round 431\n",
      "round 432\n",
      "round 433\n",
      "round 434\n",
      "round 435\n",
      "round 436\n",
      "round 437\n",
      "round 438\n",
      "round 439\n",
      "round 440\n",
      "round 441\n",
      "round 442\n",
      "round 443\n",
      "round 444\n",
      "round 445\n",
      "round 446\n",
      "round 447\n",
      "round 448\n",
      "round 449\n",
      "round 450\n",
      "round 451\n",
      "round 452\n",
      "round 453\n",
      "round 454\n",
      "round 455\n",
      "round 456\n",
      "round 457\n",
      "round 458\n",
      "round 459\n",
      "round 460\n",
      "round 461\n",
      "round 462\n",
      "round 463\n",
      "round 464\n",
      "round 465\n",
      "round 466\n",
      "round 467\n",
      "round 468\n",
      "round 469\n",
      "round 470\n",
      "round 471\n",
      "round 472\n",
      "round 473\n",
      "round 474\n",
      "round 475\n",
      "round 476\n",
      "round 477\n",
      "round 478\n",
      "round 479\n",
      "round 480\n",
      "round 481\n",
      "round 482\n",
      "round 483\n",
      "round 484\n",
      "round 485\n",
      "round 486\n",
      "round 487\n",
      "round 488\n",
      "round 489\n",
      "round 490\n",
      "round 491\n",
      "round 492\n",
      "round 493\n",
      "round 494\n",
      "round 495\n",
      "round 496\n",
      "round 497\n",
      "round 498\n",
      "round 499\n",
      "round 500\n",
      "round 501\n",
      "round 502\n",
      "round 503\n",
      "round 504\n",
      "round 505\n",
      "round 506\n",
      "round 507\n",
      "round 508\n",
      "round 509\n",
      "round 510\n",
      "round 511\n",
      "round 512\n",
      "round 513\n",
      "round 514\n",
      "round 515\n",
      "round 516\n",
      "round 517\n",
      "round 518\n",
      "round 519\n",
      "round 520\n",
      "round 521\n",
      "round 522\n",
      "round 523\n",
      "round 524\n",
      "round 525\n",
      "round 526\n",
      "round 527\n",
      "round 528\n",
      "round 529\n",
      "round 530\n",
      "round 531\n",
      "round 532\n",
      "round 533\n",
      "round 534\n",
      "round 535\n",
      "round 536\n",
      "round 537\n",
      "round 538\n",
      "round 539\n",
      "round 540\n",
      "round 541\n",
      "round 542\n",
      "round 543\n",
      "round 544\n",
      "round 545\n",
      "round 546\n",
      "round 547\n",
      "round 548\n",
      "round 549\n",
      "round 550\n",
      "round 551\n",
      "round 552\n",
      "round 553\n",
      "round 554\n",
      "round 555\n",
      "round 556\n",
      "round 557\n",
      "round 558\n",
      "round 559\n",
      "round 560\n",
      "round 561\n",
      "round 562\n",
      "round 563\n",
      "round 564\n",
      "round 565\n",
      "round 566\n",
      "round 567\n",
      "round 568\n",
      "round 569\n",
      "round 570\n",
      "round 571\n",
      "round 572\n",
      "round 573\n",
      "round 574\n",
      "round 575\n",
      "round 576\n",
      "round 577\n",
      "round 578\n",
      "round 579\n",
      "round 580\n",
      "round 581\n",
      "round 582\n",
      "round 583\n",
      "round 584\n",
      "round 585\n",
      "round 586\n",
      "round 587\n",
      "round 588\n",
      "round 589\n",
      "round 590\n",
      "round 591\n",
      "round 592\n",
      "round 593\n",
      "round 594\n",
      "round 595\n",
      "round 596\n",
      "round 597\n",
      "round 598\n",
      "round 599\n",
      "round 600\n",
      "round 601\n",
      "round 602\n",
      "round 603\n",
      "round 604\n",
      "round 605\n",
      "round 606\n",
      "round 607\n",
      "round 608\n",
      "round 609\n",
      "round 610\n",
      "round 611\n",
      "round 612\n",
      "round 613\n",
      "round 614\n",
      "round 615\n",
      "round 616\n",
      "round 617\n",
      "round 618\n",
      "round 619\n",
      "round 620\n",
      "round 621\n",
      "round 622\n",
      "round 623\n",
      "round 624\n",
      "round 625\n",
      "round 626\n",
      "round 627\n",
      "round 628\n",
      "round 629\n",
      "round 630\n",
      "round 631\n",
      "round 632\n",
      "round 633\n",
      "round 634\n",
      "round 635\n",
      "round 636\n",
      "round 637\n",
      "round 638\n",
      "round 639\n",
      "round 640\n",
      "round 641\n",
      "round 642\n",
      "round 643\n",
      "round 644\n",
      "round 645\n",
      "round 646\n",
      "round 647\n",
      "round 648\n",
      "round 649\n",
      "round 650\n",
      "round 651\n",
      "round 652\n",
      "round 653\n",
      "round 654\n",
      "round 655\n",
      "round 656\n",
      "round 657\n",
      "round 658\n",
      "round 659\n",
      "round 660\n",
      "round 661\n",
      "round 662\n",
      "round 663\n",
      "round 664\n",
      "round 665\n",
      "round 666\n",
      "round 667\n",
      "round 668\n",
      "round 669\n",
      "round 670\n",
      "round 671\n",
      "round 672\n",
      "round 673\n",
      "round 674\n",
      "round 675\n",
      "round 676\n",
      "round 677\n",
      "round 678\n",
      "round 679\n",
      "round 680\n",
      "round 681\n",
      "round 682\n",
      "round 683\n",
      "round 684\n",
      "round 685\n",
      "round 686\n",
      "round 687\n",
      "round 688\n",
      "round 689\n",
      "round 690\n",
      "round 691\n",
      "round 692\n",
      "round 693\n",
      "round 694\n",
      "round 695\n",
      "round 696\n",
      "round 697\n",
      "round 698\n",
      "round 699\n",
      "round 700\n",
      "round 701\n",
      "round 702\n",
      "round 703\n",
      "round 704\n",
      "round 705\n",
      "round 706\n",
      "round 707\n",
      "round 708\n",
      "round 709\n",
      "round 710\n",
      "round 711\n",
      "round 712\n",
      "round 713\n",
      "round 714\n",
      "round 715\n",
      "round 716\n",
      "round 717\n",
      "round 718\n",
      "round 719\n",
      "round 720\n",
      "round 721\n",
      "round 722\n",
      "round 723\n",
      "round 724\n",
      "round 725\n",
      "round 726\n",
      "round 727\n",
      "round 728\n",
      "round 729\n",
      "round 730\n",
      "round 731\n",
      "round 732\n",
      "round 733\n",
      "round 734\n",
      "round 735\n",
      "round 736\n",
      "round 737\n",
      "round 738\n",
      "round 739\n",
      "round 740\n",
      "round 741\n",
      "round 742\n",
      "round 743\n",
      "round 744\n",
      "round 745\n",
      "round 746\n",
      "round 747\n",
      "round 748\n",
      "round 749\n",
      "round 750\n",
      "round 751\n",
      "round 752\n",
      "round 753\n",
      "round 754\n",
      "round 755\n",
      "round 756\n",
      "round 757\n",
      "round 758\n",
      "round 759\n",
      "round 760\n",
      "round 761\n",
      "round 762\n",
      "round 763\n",
      "round 764\n",
      "round 765\n",
      "round 766\n",
      "round 767\n",
      "round 768\n",
      "round 769\n",
      "round 770\n",
      "round 771\n",
      "round 772\n",
      "round 773\n",
      "round 774\n",
      "round 775\n",
      "round 776\n",
      "round 777\n",
      "round 778\n",
      "round 779\n",
      "round 780\n",
      "round 781\n",
      "round 782\n",
      "round 783\n",
      "round 784\n",
      "round 785\n",
      "round 786\n",
      "round 787\n",
      "round 788\n",
      "round 789\n",
      "round 790\n",
      "round 791\n",
      "round 792\n",
      "round 793\n",
      "round 794\n",
      "round 795\n",
      "round 796\n",
      "round 797\n",
      "round 798\n",
      "round 799\n",
      "round 800\n",
      "round 801\n",
      "round 802\n",
      "round 803\n",
      "round 804\n",
      "round 805\n",
      "round 806\n",
      "round 807\n",
      "round 808\n",
      "round 809\n",
      "round 810\n",
      "round 811\n",
      "round 812\n",
      "round 813\n",
      "round 814\n",
      "round 815\n",
      "round 816\n",
      "round 817\n",
      "round 818\n",
      "round 819\n",
      "round 820\n",
      "round 821\n",
      "round 822\n",
      "round 823\n",
      "round 824\n",
      "round 825\n",
      "round 826\n",
      "round 827\n",
      "round 828\n",
      "round 829\n",
      "round 830\n",
      "round 831\n",
      "round 832\n",
      "round 833\n",
      "round 834\n",
      "round 835\n",
      "round 836\n",
      "round 837\n",
      "round 838\n",
      "round 839\n",
      "round 840\n",
      "round 841\n",
      "round 842\n",
      "round 843\n",
      "round 844\n",
      "round 845\n",
      "round 846\n",
      "round 847\n",
      "round 848\n",
      "round 849\n",
      "round 850\n",
      "round 851\n",
      "round 852\n",
      "round 853\n",
      "round 854\n",
      "round 855\n",
      "round 856\n",
      "round 857\n",
      "round 858\n",
      "round 859\n",
      "round 860\n",
      "round 861\n",
      "round 862\n",
      "round 863\n",
      "round 864\n",
      "round 865\n",
      "round 866\n",
      "round 867\n",
      "round 868\n",
      "round 869\n",
      "round 870\n",
      "round 871\n",
      "round 872\n",
      "round 873\n",
      "round 874\n",
      "round 875\n",
      "round 876\n",
      "round 877\n",
      "round 878\n",
      "round 879\n",
      "round 880\n",
      "round 881\n",
      "round 882\n",
      "round 883\n",
      "round 884\n",
      "round 885\n",
      "round 886\n",
      "round 887\n",
      "round 888\n",
      "round 889\n",
      "round 890\n",
      "round 891\n",
      "round 892\n",
      "round 893\n",
      "round 894\n",
      "round 895\n",
      "round 896\n",
      "round 897\n",
      "round 898\n",
      "round 899\n",
      "round 900\n",
      "round 901\n",
      "round 902\n",
      "round 903\n",
      "round 904\n",
      "round 905\n",
      "round 906\n",
      "round 907\n",
      "round 908\n",
      "round 909\n",
      "round 910\n",
      "round 911\n",
      "round 912\n",
      "round 913\n",
      "round 914\n",
      "round 915\n",
      "round 916\n",
      "round 917\n",
      "round 918\n",
      "round 919\n",
      "round 920\n",
      "round 921\n",
      "round 922\n",
      "round 923\n",
      "round 924\n",
      "round 925\n",
      "round 926\n",
      "round 927\n",
      "round 928\n",
      "round 929\n",
      "round 930\n",
      "round 931\n",
      "round 932\n",
      "round 933\n",
      "round 934\n",
      "round 935\n",
      "round 936\n",
      "round 937\n",
      "round 938\n",
      "round 939\n",
      "round 940\n",
      "round 941\n",
      "round 942\n",
      "round 943\n",
      "round 944\n",
      "round 945\n",
      "round 946\n",
      "round 947\n",
      "round 948\n",
      "round 949\n",
      "round 950\n",
      "round 951\n",
      "round 952\n",
      "round 953\n",
      "round 954\n",
      "round 955\n",
      "round 956\n",
      "round 957\n",
      "round 958\n",
      "round 959\n",
      "round 960\n",
      "round 961\n",
      "round 962\n",
      "round 963\n",
      "round 964\n",
      "round 965\n",
      "round 966\n",
      "round 967\n",
      "round 968\n",
      "round 969\n",
      "round 970\n",
      "round 971\n",
      "round 972\n",
      "round 973\n",
      "round 974\n",
      "round 975\n",
      "round 976\n",
      "round 977\n",
      "round 978\n",
      "round 979\n",
      "round 980\n",
      "round 981\n",
      "round 982\n",
      "round 983\n",
      "round 984\n",
      "round 985\n",
      "round 986\n",
      "round 987\n",
      "round 988\n",
      "round 989\n",
      "round 990\n",
      "round 991\n",
      "round 992\n",
      "round 993\n",
      "round 994\n",
      "round 995\n",
      "round 996\n",
      "round 997\n",
      "round 998\n",
      "round 999\n",
      "total time is 47.37447166442871\n",
      "length of chain is 1000\n",
      "length of burn in is 100\n",
      "Use logit\n",
      "store is [[ 0.5177562   0.79744285  0.03885843 ...  0.56665087  0.521879\n",
      "   0.1481319 ]\n",
      " [ 0.3545807   1.2311702  -0.25005943 ...  0.2620788   0.6383617\n",
      "   0.44278225]\n",
      " [ 0.39905804  1.0878277  -0.02581217 ...  0.646456    0.5849493\n",
      "   0.07706516]\n",
      " ...\n",
      " [ 0.63847935  1.0666878  -0.07573105 ...  0.3664987   0.5570908\n",
      "   0.18873864]\n",
      " [ 0.20999324  0.9727893  -0.37215683 ...  0.56179154  0.51153815\n",
      "   0.42806122]\n",
      " [ 0.02976325  0.88493115 -0.00165281 ...  0.6027199   0.39228755\n",
      "   0.32626402]]\n",
      "sd is [0.16633213 0.14177378 0.14440744 0.16666833 0.17850699 0.13392106\n",
      " 0.16555072]\n",
      "mean is [ 0.37839845  1.0659151  -0.08942618  0.04039779  0.47849792  0.46158576\n",
      "  0.23939937]\n",
      "Inference for Stan model: anon_model_4bac8359d39f32cfa57c3e3acae076d2.\n",
      "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
      "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
      "\n",
      "          mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "beta[0]   0.38  2.3e-3   0.15   0.09   0.28   0.38   0.48   0.67   4000    1.0\n",
      "beta[1]   1.06  2.1e-3   0.13   0.81   0.97   1.06   1.14   1.32   4000    1.0\n",
      "beta[2]  -0.08  1.9e-3   0.12  -0.31  -0.16  -0.08 2.6e-4   0.15   4000    1.0\n",
      "beta[3]   0.04  2.3e-3   0.14  -0.24  -0.06   0.03   0.13   0.32   4000    1.0\n",
      "beta[4]   0.47  2.3e-3   0.15   0.19   0.38   0.48   0.57   0.76   4000    1.0\n",
      "beta[5]   0.44  1.9e-3   0.12   0.21   0.36   0.45   0.53   0.69   4000    1.0\n",
      "beta[6]   0.23  2.5e-3   0.15  -0.06   0.12   0.23   0.33   0.54   3594    1.0\n",
      "lp__    -275.6    0.04   1.88 -280.2 -276.6 -275.3 -274.3 -272.9   1813    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Wed May 23 04:02:46 2018.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "%run -i \"newtestxhmc_logit.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
